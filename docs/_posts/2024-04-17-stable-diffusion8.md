---
layout: post
title: stable-diffusion中 k-sampling的不同版本
categories:
  - deeplearning
tags:
  - content
last_modified_at: 2024-06-25T02:07:04-08:00
---

|                                                                                               | 步骤                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                              |
| --------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Euler<br><br>和SDE的[Euler–Maruyama](https://en.wikipedia.org/wiki/Euler–Maruyama_method) 的解法不同 | noise injection:<br>- increased noise $\hat \sigma$  : $\hat \sigma\leftarrow \sigma_i + \gamma\sigma_i$ <br>-  sample x with increased noise: $\hat x \leftarrow x_i + \sqrt{\hat \sigma^2-\sigma_i^2}\cdot\epsilon$ <br>Take Euler Step: <br>- $dt=\sigma_{i+1}-\hat \sigma$<br>- $denoised=model(\hat x,\hat \sigma)$ <br>- gradient: $d=(\hat x-denoised)/{\hat \sigma}$ <br>- Euler step: $x_{i+1}=\hat x+dt \cdot d$                                               | 采用SMLD, $\alpha_t=1$ <br><br>$f(t)\rightarrow 0$ <br>$g(t)^2\rightarrow 2\dot\sigma_t\sigma_t$ <br><br>$d\rightarrow-\dot\sigma_t\sigma_t\nabla_x\log p(x;\sigma_t)=\frac{\dot \sigma_t}{\sigma_t}\cdot\sigma_t\frac{x-D(x,t)}{\sigma_t}$   <br><br>令 $\sigma_t=t$ , 此时$\dot \sigma_t=1$ <br>$d \rightarrow\frac{x-D(x;\sigma_t)}{\sigma_t}$ |
| [heun](https://en.wikipedia.org/wiki/Heun%27s_method)<br>Euler方法的改进                           | noise injection:  <br>得到$\hat\sigma, \hat x, denoised$ <br> Left tangent prediction: <br>- $x_2=\hat x + dt\cdot d$<br>Right tangent prediction:<br>- $d_2=(x_2-model(x_2,\sigma_{i+1}))/\sigma_{i+1}$ <br>结果: <br>- $d^\prime=\frac{d+d_2}{2}$ <br>- $x_{i+1}=\hat x+d^\prime\cdot dt$                                                                                                                                                                                  |                                                                                                                                                                                                                                                                                                                                              |
| Euler Ancestral                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                              |
| Euler Ancestral                                                                               | Take Euler Step to $\sigma_{down}$:  <br>- $dt=\sigma_{down}-\sigma_i$ <br>- $denoised=model(x,\sigma_i)$ <br>- numerical derivative: $d=(x-denoised)/{\sigma_i}$ <br>- Euler step: $x_{down}=x+dt \cdot d$ <br>Add ancestral noise:<br>- $x_{i+1}=x_{down}+noise*\sigma_{up}$ <br>                                                                                                                                                                                      | <br>$\sigma_{up}=\min(\sigma_{i+1},\eta\cdot\sqrt{(\frac{\sigma_{i+1}^2}{\sigma_i^2}(\sigma_i^2-\sigma_{i+1}^2))})$ <br>$\sigma_{down}=\sqrt{\sigma_{i+1}^2-\sigma_{up}^2}$                                                                                                                                                                  |
| DDPM                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                              |
| DDIM                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                              |
| DPM-Solver                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 根据probability ODE: <br>$\dot x=f(t)\cdot x-\frac{1}{2}g^2(t)\nabla_x\log p(x,t)$<br><br>令, $\alpha_t=1$ <br><br>                                                                                                                                                                                                                             |
| dpm_2                                                                                         | noise injection: <br>得到$\hat\sigma, \hat x, denoised$ <br>DPM-Solver-2: <br>- 在$\sigma_{i+1},\hat \sigma$ 之间取: $\sigma_{mid}=e^{\frac{\log \hat\sigma+\log \sigma_{i+1}}{2}}$ <br>- $dt_1=\sigma_{mid}-\hat \sigma$ <br>- $dt_2=\sigma_{i+1}-\hat \sigma$ <br>- $x_{mid}=\hat x+dt_1\cdot(\hat x-model(\hat x,\hat \sigma))/\hat \sigma$  <br>用$\sigma_{mid}$ 处的numerial derivative<br>- $x=\hat x+dt_2\cdot(x_{mid}-model(x_{mid},\sigma_{mid}))/\sigma_{mid}$ <br><br> |                                                                                                                                                                                                                                                                                                                                              |
| dpmpp_2m                                                                                      | - $t=-\log(\sigma_i)$ , $t_{next}=-\log(\sigma_{i+1})$ , $t_{last}=-\log(\sigma_{i-1})$ <br>- $h=t_{next}-t$, $h_{last}=t-t_{last}$ <br>- $r=h_{last}/h$ <br>- $denoised_d=(1+\frac{1}{2r})\cdot denoised-\frac{1}{2r}\cdot denoised_{old}$  <br>- $x_{i+1}=\frac{\sigma_{i+1}}{\sigma_i}\cdot x_i-(e^{-h}-1)\cdot denoised_d$ <br>                                                                                                                                      |                                                                                                                                                                                                                                                                                                                                              |
| lcm                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                              |

Euler: 


## reference

[1 ] Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine. “Elucidating the Design Space of Diffusion-Based Generative Models.” arXiv, October 11, 2022. [https://doi.org/10.48550/arXiv.2206.00364](https://doi.org/10.48550/arXiv.2206.00364).   **Euler, Heun method** 

[2] Lu, Cheng, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. “**DPM-Solver**: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps.” arXiv, October 13, 2022. [https://doi.org/10.48550/arXiv.2206.00927](https://doi.org/10.48550/arXiv.2206.00927).

[3] Lu, Cheng, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. “**DPM-Solver++**: Fast Solver for Guided Sampling of Diffusion Probabilistic Models.” arXiv, May 6, 2023. [https://doi.org/10.48550/arXiv.2211.01095](https://doi.org/10.48550/arXiv.2211.01095).


[3] Song, Yang, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. “Score-Based Generative Modeling through Stochastic Differential Equations.” arXiv, February 10, 2021. [https://doi.org/10.48550/arXiv.2011.13456](https://doi.org/10.48550/arXiv.2011.13456).  **DDPM,  SMLD, SDE, ODE** 

[4] Ho, Jonathan, Ajay Jain, and Pieter Abbeel. “Denoising Diffusion Probabilistic Models.” _arXiv:2006.11239 [Cs, Stat]_, December 16, 2020. [http://arxiv.org/abs/2006.11239](http://arxiv.org/abs/2006.11239). **DDPM原作者版本** 

[5] Song, Jiaming, Chenlin Meng, and Stefano Ermon. “Denoising Diffusion Implicit Models.” arXiv, October 5, 2022. [https://doi.org/10.48550/arXiv.2010.02502](https://doi.org/10.48550/arXiv.2010.02502). **DDIM** 

[5] 苏剑林. (Aug. 03, 2022). 《生成扩散模型漫谈（五）：一般框架之SDE篇 》[Blog post]. Retrieved from [https://spaces.ac.cn/archives/9209](https://spaces.ac.cn/archives/9209)

[6] 代码: https://github.com/lllyasviel/Fooocus/blob/1c999be8c8134fe01a75723ea933858435856950/ldm_patched/k_diffusion/sampling.py#L571