var store = [{
        "title": "Edge Case: Nested and Mixed Lists",
        "excerpt":"Nested and mixed lists are an interesting beast. It’s a corner case to make sure that lists within lists do not break the ordered list numbering order and list styles go deep enough. Ordered – Unordered – Ordered ordered item ordered item unordered unordered ordered item ordered item ordered item...","categories": ["docs","Edge Case"],
        "tags": ["content","css","edge case","lists","markup"],
        "url": "https://roshameow.github.io//personal_homepage/docs/edge%20case/edge-case-nested-and-mixed-lists/"
      },{
        "title": "Edge Case: Many Tags",
        "excerpt":"This post has many tags. ","categories": ["docs","Edge Case"],
        "tags": ["8BIT","alignment","Articles","captions","categories","chat","comments","content","css","dowork","edge case","embeds","excerpt","Fail","featured image","FTW","Fun","gallery","html","image","Jekyll","layout","link","Love","markup","Mothership","Must Read","Nailed It","Pictures","Post Formats","quote","standard","Success","Swagger","Tags","template","title","twitter","Unseen","video","YouTube"],
        "url": "https://roshameow.github.io//personal_homepage/docs/edge%20case/edge-case-many-tags/"
      },{
        "title": "Edge Case: Many Categories",
        "excerpt":"This post has many categories. ","categories": ["docs","aciform","antiquarianism","arrangement","asmodeus","broder","buying","championship","chastening","disinclination","disinfection"],
        "tags": ["categories","edge case"],
        "url": "https://roshameow.github.io//personal_homepage/docs/aciform/antiquarianism/arrangement/asmodeus/broder/buying/championship/chastening/disinclination/disinfection/edge-case-many-categories/"
      },{
        "title": "Edge Case: No Body Content",
        "excerpt":"","categories": ["docs","Edge Case"],
        "tags": ["content","edge case","layout"],
        "url": "https://roshameow.github.io//personal_homepage/docs/edge%20case/edge-case-no-body-content/"
      },{
        "title": "Edge Case No Yaml Title",
        "excerpt":"This post has no title specified in the YAML Front Matter. Jekyll should auto-generate a title from the filename. For example 2009-09-05-edge-case-no-yaml-title.md becomes Edge Case No Yaml Title. ","categories": ["docs","Edge Case"],
        "tags": ["edge case","layout","title"],
        "url": "https://roshameow.github.io//personal_homepage/docs/edge%20case/edge-case-no-yaml-title/"
      },{
        "title": "Antidisestablishmentarianism",
        "excerpt":"This post title has a long word that could potentially overflow the content area. A few things to check for: Non-breaking text in the title should have no adverse effects on layout or functionality. Check the browser window / tab title.The following CSS property will help you support non-breaking text....","categories": ["docs","Edge Case"],
        "tags": ["content","css","edge case","html","layout","title"],
        "url": "https://roshameow.github.io//personal_homepage/docs/edge%20case/edge-case-title-should-not-overflow-the-content-area/"
      },{
        "title": "Suspicio? Bene ... tunc ibimus? Quis uh ... CONEXUS locus his diebus? Quisque semper aliquid videtur, in volutpat mauris. Nolo enim dicere. Vobis neque ab aliis. Ego feci memetipsum explicans. Gus mortuus est. Lorem opus habeo. Jackson Isai? Tu quoque ... A te quidem a ante. Vos scitis quod blinking res Ive 'been vocans super vos? Et conteram illud, et conteram hoc. Maledicant druggie excors. Iam hoc tu facere conatus sum ad te in omni tempore? Ludum mutavit. Verbum est ex. Et ... sunt occid",
        "excerpt":"Check for long titles and how they might break layouts. ","categories": ["docs","Edge Case"],
        "tags": ["content","css","edge case","html","layout","title"],
        "url": "https://roshameow.github.io//personal_homepage/docs/edge%20case/edge-case-very-long-title/"
      },{
        "title": "Post: Modified Date",
        "excerpt":"This post has been updated and should show a modified date if last_modified_at is used in the layout. Plugins like jekyll-sitemap use this field to add a &lt;lastmod&gt; tag your sitemap.xml. ","categories": ["docs","Post Formats"],
        "tags": ["Post Formats","readability","standard"],
        "url": "https://roshameow.github.io//personal_homepage/docs/post%20formats/post-modified/"
      },{
        "title": "Post: Standard",
        "excerpt":"All children, except one, grow up. They soon know that they will grow up, and the way Wendy knew was this. One day when she was two years old she was playing in a garden, and she plucked another flower and ran with it to her mother. I suppose she...","categories": ["docs","Post Formats"],
        "tags": ["Post Formats","readability","standard"],
        "url": "https://roshameow.github.io//personal_homepage/docs/post%20formats/post-standard/"
      },{
        "title": "Post: Quote",
        "excerpt":"  Only one thing is impossible for God: To find any sense in any copyright law on the planet.   Mark Twain ","categories": ["docs","Post Formats"],
        "tags": ["Post Formats","quote"],
        "url": "https://roshameow.github.io//personal_homepage/docs/post%20formats/post-quote/"
      },{
        "title": "Post: Link",
        "excerpt":"This theme supports link posts, made famous by John Gruber. To use, just add link: http://url-you-want-linked to the post’s YAML front matter and you’re done.   And this is how a quote looks. Some link can also be shown. ","categories": ["docs","Post Formats"],
        "tags": ["link","Post Formats"],
        "url": "https://roshameow.github.io//personal_homepage/docs/post%20formats/post-link/"
      },{
        "title": "Post: Video (YouTube)",
        "excerpt":"This post tests YouTube video embeds. Simply use the responsive-embed helper include like so: {% include responsive-embed url=\"https://www.youtube.com/watch?v=-PVofD2A9t8\" ratio=\"16:9\" %}Or wrap embeds with a &lt;div&gt; element and the appropriate classes: &lt;!-- 21:9 aspect ratio --&gt;&lt;div class=\"responsive-embed responsive-embed-21by9\"&gt; &lt;iframe class=\"responsive-embed-item\" src=\"...\"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;!-- 16:9 aspect ratio --&gt;&lt;div class=\"responsive-embed responsive-embed-16by9\"&gt; &lt;iframe class=\"responsive-embed-item\" src=\"...\"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;!-- 4:3...","categories": ["docs","Post Formats"],
        "tags": ["Post Formats"],
        "url": "https://roshameow.github.io//personal_homepage/docs/post%20formats/post-video-youtube/"
      },{
        "title": "Post: Twitter Embed",
        "excerpt":"Oh I dunno. It&#39;s probably been over 15 years since I smudged out a face with a pencil and kneaded eraser. #WIP #Sktchy pic.twitter.com/PwqbMddyVK &mdash; Michael Rose (@mmistakes) February 1, 2017This post tests Twitter Embeds. ","categories": ["docs","Media"],
        "tags": ["content","embeds","media","twitter"],
        "url": "https://roshameow.github.io//personal_homepage/docs/media/post-twitter-embeds/"
      },{
        "title": "Layout: Post with Table Of Contents",
        "excerpt":"Enable table of contents on post or page by adding {% include toc %} where you’d like it to appear. Table of Contents HTML Elements Below is are some HTML elements. Check the source code to see the many embedded elements within paragraphs. Body text Lorem ipsum dolor sit amet,...","categories": ["docs","Layout"],
        "tags": ["table of contents"],
        "url": "https://roshameow.github.io//personal_homepage/docs/layout/layout-table-of-contents/"
      },{
        "title": "Layout: Author Override",
        "excerpt":"Sites that may have content authored from various individuals can be accommodated by using data files. To attribute an author to a post or page that is different from the site author specified in _config.yml: Step 1. Create _data/authors.yml and add authors using the following format. Anything variables found under...","categories": ["docs"],
        "tags": [],
        "url": "https://roshameow.github.io//personal_homepage/docs/layout-author-override/"
      },{
        "title": "Layout: Excerpt (Defined)",
        "excerpt":"This is the start of the post content. This paragraph should be absent from an index page where post.excerpt is shown. ","categories": ["docs","Layout","Uncategorized"],
        "tags": ["content","excerpt","layout"],
        "url": "https://roshameow.github.io//personal_homepage/docs/layout/uncategorized/layout-excerpt-defined/"
      },{
        "title": "Layout: Excerpt (Generated with Separator Tag)",
        "excerpt":"This is the post content. Archive-index pages should display an auto-generated excerpt of all the content preceding the excerpt_separator, as defined in the YAML Front Matter or globally in _config.yml. Be sure to test the formatting of the auto-generated excerpt, to ensure that it doesn’t create any layout problems. Lorem...","categories": ["docs","Layout","Uncategorized"],
        "tags": ["content","excerpt","layout"],
        "url": "https://roshameow.github.io//personal_homepage/docs/layout/uncategorized/layout-excerpt-generated/"
      },{
        "title": "Layout: Hero Image",
        "excerpt":"This post should display a large hero image at the top of a page. This post tests a horizontal image using the following YAML Front Matter: image: path: /images/eder-oliveira-180877.jpgHero images can also be assigned more succinctly when thumbnail or caption are not used. image: /images/eder-oliveira-180877.jpgTall images will push content down...","categories": ["docs","Layout"],
        "tags": ["content","image","layout"],
        "url": "https://roshameow.github.io//personal_homepage/docs/layout/layout-hero-image/"
      },{
        "title": "Markup: Text Readability Test",
        "excerpt":"Portland in shoreditch Vice, labore typewriter pariatur hoodie fap sartorial Austin. Pinterest literally occupy Schlitz forage. Odio ad blue bottle vinyl, 90’s narwhal commodo bitters pour-over nostrud. Ugh est hashtag in, fingerstache adipisicing laboris esse Pinterest shabby chic Portland. Shoreditch bicycle rights anim, flexitarian laboris put a bird on it...","categories": ["docs"],
        "tags": ["sample post","readability","test"],
        "url": "https://roshameow.github.io//personal_homepage/docs/markup-text-readability/"
      },{
        "title": "Markup: Title *with* **Markdown**",
        "excerpt":"Using Markdown in the title should have no adverse effect on the layout or functionality. page.title example: title: \"Markup: Title *with* **Markdown**\"\"","categories": ["docs","Markdown"],
        "tags": ["css","html","title"],
        "url": "https://roshameow.github.io//personal_homepage/docs/markdown/markup-title-with-markdown/"
      },{
        "title": "Markup: Title with Special&nbsp;---&nbsp;Characters",
        "excerpt":"Putting special characters in the title should have no adverse effect on the layout or functionality. The title above has none-breaking spaces before and after the m-dash. &amp;nbsp;---&amp;nbsp;Latin Character Tests This is a test to see if the fonts used in this theme support basic Latin characters. ! &#8220; #...","categories": ["docs","Markup"],
        "tags": ["html","markup","post","title"],
        "url": "https://roshameow.github.io//personal_homepage/docs/markup/markup-title-with-special-characters/"
      },{
        "title": "Markup: Text Alignment and Transformations",
        "excerpt":"Sample text to demonstrate alignment and transformation classes. Easily realign text with alignment classes via HTML: &lt;p class=\"text-left\"&gt;Left aligned text.&lt;/p&gt;&lt;p class=\"text-center\"&gt;Center aligned text.&lt;/p&gt;&lt;p class=\"text-right\"&gt;Right aligned text.&lt;/p&gt;&lt;p class=\"text-justify\"&gt;Justified text.&lt;/p&gt;&lt;p class=\"text-nowrap\"&gt;No wrap text.&lt;/p&gt;Or with Kramdown and inline attribute lists: Left aligned text.{: .text-left}Center aligned text.{: .text-center}Right aligned text.{: .text-right}Justified text.{: .text-justify}No wrap...","categories": ["docs","Markup"],
        "tags": ["alignment","content","css","markup"],
        "url": "https://roshameow.github.io//personal_homepage/docs/markup/markup-text-alignment/"
      },{
        "title": "Markup: Image Alignment",
        "excerpt":"The best way to demonstrate the ebb and flow of the various image positioning options is to nestle them snuggly among an ocean of words. Grab a paddle and let’s get started. Assign classes with HTML: &lt;img src=\"image.jpg\" class=\"align-left\" alt=\"\"&gt;&lt;img src=\"image.jpg\" class=\"align-center\" alt=\"\"&gt;&lt;img src=\"image.jpg\" class=\"align-right\" alt=\"\"&gt;Or use Kramdown and inline...","categories": ["docs","Markup"],
        "tags": ["alignment","captions","content","css","image","markup"],
        "url": "https://roshameow.github.io//personal_homepage/docs/markup/markup-image-alignment/"
      },{
        "title": "Markup: HTML Elements and Formatting",
        "excerpt":"A variety of common HTML elements to demonstrate the theme’s stylesheet and verify they have been styled appropriately. Header one Header two Header three Header four Header five Header six Blockquotes Single line blockquote: Stay hungry. Stay foolish. Multi line blockquote with a cite reference: People think focus means saying...","categories": ["docs","Markup"],
        "tags": [],
        "url": "https://roshameow.github.io//personal_homepage/docs/markup/markup-html-elements-and-formatting/"
      },{
        "title": "Markup: Syntax Highlighting",
        "excerpt":"Syntax highlighting is a feature that displays source code, in different colors and fonts according to the category of terms. This feature facilitates writing in a structured language such as a programming language or a markup language as both structures and syntax errors are visually distinct. Highlighting does not affect...","categories": ["docs"],
        "tags": ["code","syntax highlighting"],
        "url": "https://roshameow.github.io//personal_homepage/docs/markup-syntax-highlighting/"
      },{
        "title": "MathJax Example",
        "excerpt":"MathJax is a simple, yet powerful, way ofincluding Tex/LaTex/MathML based mathematics in HTML webpages. Usage To enable MathJax support configure your _config.xml to: Set kramdown as the Markdown parser. Enable MathJax.The version of MathJax enabled is v3. An example setting for _config.xml is shown below: markdown: kramdownmathjax: enable: true combo:...","categories": ["docs"],
        "tags": [],
        "url": "https://roshameow.github.io//personal_homepage/docs/mathjax-example/"
      },{
        "title": "Hidden Post",
        "excerpt":"This post has YAML Front Matter of hidden: true and should not appear in paginator.posts. ","categories": ["docs"],
        "tags": [],
        "url": "https://roshameow.github.io//personal_homepage/docs/hidden-post/"
      },{
        "title": "用 jekyll+obsidian生成个人主页并部署到 github pages的工作流",
        "excerpt":"用jekyll的原因无需多说。这样配置好工作流之后，除了编写内容基本没有什么麻烦的操作(登录在线网页，换编辑器，按照统一格式改文件名之类在我看来都很麻烦。。)。 Ruby的环境管理，包管理方式 管理顺序： churby -&gt; ruby -&gt; bundle -&gt; gem -&gt; jekyll ruby： 是经常在 web 开发中使用的一种动态语言。 churby： Ruby 的环境管理工具，用于管理不同版本的 Ruby。 gem： Ruby 编写的软件包的统称，Jekyll 也是一个 gem。 bundler： 用于管理项目 gem 的工具，根据 Gemfile 管理不同版本的 gem。bundler自己本身也是gem。 如果用 Python 来类比，关系大概是这样： ruby python churby 版本号 conda create -n my_env python=版本号; conda activate my_env gem install 某个包...","categories": ["docs","WebPage"],
        "tags": ["content","jekyll","markdown","obsidian","raycast"],
        "url": "https://roshameow.github.io//personal_homepage/docs/webpage/jekyll-blog-deploy/"
      },{
        "title": "小红书学到的几种图片调色",
        "excerpt":"感觉共同点是：为了追求画面简洁有冲击力，不约而同的压缩了亮度和颜色的动态范围。 版画滤镜      醒图4个滤镜依次叠加，透明度依次减小          千禧-&gt;幻想蝴蝶      新中式-&gt;空谷      千禧-&gt;数字彩虹      新中式-&gt;烟霞        实际实验结果                调整亮度曲线如图，暗部切断，亮部反色，压缩动态范围      添加噪声      去掉图片原有颜色      按照亮暗调节新的颜色      白夜之树                  方法：           醒图滤镜：千禧-&gt;午夜 把照片变成蓝色，就是为了伪造天空部分吧？      曲线反色：画面要避开一些常见的物品，不然很容易看出其实是反色，就感觉出戏了      光感-100：作用是，把有颜色的部分变暗？      单色涂鸦       方法：          醒图特效：单色填充：可能是根据饱和度？把饱和度高的部分填充了粉色。因为图片里红色和蓝色都被填充了，所以不是根据主体色识别。其他位置变为灰度图      醒图特效：单色涂鸦：检测边缘，设置白边                  可能是检测闭合的部分，处理成涂鸦的斜线          检测线条少的位置加文字                    ","categories": ["docs","photo"],
        "tags": ["content","醒图"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/photo-color/"
      },{
        "title": "双十二装机",
        "excerpt":"趁着双十二激情下单，前后不到一天，选的配件都没什么性价比。 配置：   不想再等了，买了4080  cpu实际换了7900x3d  外观：   买完发现灯光处于一个过饱和状态，显卡还带屏幕。不过再增加发光的东西就怎么都看不顺眼了，暂时只能保持这样的状态。   \t","categories": ["docs","photo"],
        "tags": ["content","device","life"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/new-computer/"
      },{
        "title": "传感器颜色调制 (一)",
        "excerpt":"调制 一般把信号区分出来的过程叫调制。现在一般的传感器只能感应2d的光学信号强度(就是灰度图)，把不同波长的光分离，以获取特定光谱范围的信息的过程，就叫颜色调制。比如信号经过rgb的滤光片，得到彩色图像。 所有调制都是通过牺牲一部分空间精度为代价获得其他层次信息。 通过排布滤光片进行颜色调制 像传统的rggb bayer和quad bayer一样，可以用不同方式排布多光谱的滤光片。如： 几种排布像素的方法 把像素不断二分1 如果不是$2^n$ 个通道，没法保证所有通道的像素密度一样。比如图上5个通道的情况。1，2通道的密度就比3，4，5的密度低。 但是这样做可以让每个相同通道的间距相等。 间隔相等斜向排布2 能保证每个channel的像素相邻的channel一直是一样的 但是这样在各个方向上像素密度极度不均匀：比如图上5个通道情况，横竖方向相隔4个像素，斜向却相隔0个，3个像素 分成primary channel和secondary channel两组 3 把secondary channel穿插在primay channel中 图中a,b,c是primary channel，像素密度高； d,e,f,g 是secondary channel，像素密度低 一个实拍的样例 图中是8个通道的sensor实拍图做了伪彩变换之后的样例 filter不同channel之间贴了黑胶阻挡(除了阻挡更多光线进入sensor以外，没什么积极意义) 排布像素的规则 根据不同通道的功能先确定需要的像素密度采用滤光片排布调制的问题： 技术本身的问题： 现在一般用FP-干涉技术来制作多光谱sensor需要的窄波段，FP-干涉需要使用多层透镜实现，相当于严重降低光线透过率 mask均匀排布，会导致MTF有些地方的傅立叶系数是0(rect pulse的Fourier transform是sinc)，不利于做reconstruction 工厂生产的问题： 生产的一个filter的尺寸最小在10um左右，但是目前的手机用的单像素尺寸在0.6～2.4um(单像素2.4um已经是非常好的CMOS了)，不得不用类似quad bayer的做法让一个filter对应多个像素，无疑会影响调制的精度 透镜部分和成像部分不贴合：透镜距离sensor的感光区域有大约3um的垂直距离，会导致像素中有效信息进一步降低 透镜偏移，没有和像素的位置对应：导致传感器之间的差异很大 [1] Lidan Miao and Hairong Qi. “The Design...","categories": ["docs","algorithm"],
        "tags": ["content","sensor"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate/"
      },{
        "title": "传感器颜色调制 (二)",
        "excerpt":"其他方法进行颜色调制: coded-aperture, dispenser coded-aperture的优点 有利于deblur PSF是scene到image的kernel: $\\text{image}=PSF*\\text{scene}$ 如果对image做deblur, $\\text{scene}=F^{-1}(\\frac{F(\\text{image})}{F(PSF)})=F^{-1}(\\frac{F(\\text{image})}{MTF})$ 传统的MTF(即$F(J_1)$ )存在cutoff点, 即在cutoff之上的的高频部分是0, 而coded-aperture可以保留部分高频信息, 使MTF没有完全为0的点 进行颜色调制 不同的波长的PSF不同, aperture缩小后, 这个不同在成像上变得更明显, coded-aperture可以看成是很多小的aperture的组合 coded-aperture可以让不同波长的PSF形成不同的pattern CASSI coded_apeture+dispenser 1 设备: 代码仿真过程: 3d multichannel image( C x H x W ) -&gt; 2d perception image( H x (W+2*C-2) ) 把coded_apeture mask应用于所有通道 dispenser依次给mask的通道图像y-axis 2pixel的shift 把所有通道叠加 加入shot noise: $Y_{sim}=B(Y/QE,QE)$...","categories": ["docs","algorithm"],
        "tags": ["content","sensor"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate1/"
      },{
        "title": "blender学习:  Toon BSDF的硬阴影效果",
        "excerpt":"导入模型 用glTF格式的模型 glTF格式介绍：https://github.com/KhronosGroup/glTF 在vscode安装glTF tools 插件： 可以跳转到具体accessor，直接查看数据 可以查看渲染之后的结果(包括背景和动画) 下载gltf模型: https://github.com/GPUOpen-LibrariesAndSDKs/Cauldron-Media/tree/v1.0.4/buster_drone步骤 参考b站的教学视频 修改： world property: surface: 选background, strength 0 直接把surface的shader直接关掉应该也是一样的效果？ 光源： blender代码： https://github.com/blender/cycles/blob/main/src/scene/light.cpp https://github.com/blender/cycles/blob/main/src/kernel/light/spot.h https://github.com/blender/cycles/blob/main/src/kernel/sample/mapping.h#L114 改成spot light radius改成0：影响光锥的软硬 blend改成0 rendering 用cycles: 引擎改成cycles：cycles是基于光追的，更符合现实情况 noise threshold改成0， sample改成64 Light Paths里面反弹次数(Total, Diffuse, Glossy, Transmission)都改成0 防止出现明亮表面和柔和边缘？ 用eevee: eevee的效果看起来不太一样.. 因为压缩色阶的效果相当于blur+量化吧? 所以和没有blur过的结果不一致 Film里面filter size改成0 在shader和material output中间,加Shader to RGB-&gt;ColorRamp...","categories": ["docs","blender"],
        "tags": ["content","BSDF","render"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning/"
      },{
        "title": "用六边形构成半球",
        "excerpt":"刷到关于《葬送的芙莉莲》里面六边形魔法防御结界的讨论，根据多面体欧拉公式，仅仅用正六边形是没法组成球体形状结界。我也非常理解制作组为什么不画个足球：毕竟是魔法阵，六边形画的又比较大，弄个五边形也不好看也不好解释。 但是如果不是球，而是半球，不考虑边界是否完整，变形，肯定是可行的。因为半球$S^+$ 和disk $\\mathbb{D}^1$， 和六边形边界的平面都是 topological isomorphism 的，在平面上能实现的密铺，变形到半球上当然也能实现。 另外，为了保证在3维上看起来不难看。用Malley’s Method, 把disk看成半球的投影，实行$(r,\\phi)=(\\sin\\theta,\\phi)\\rightarrow (\\theta,\\phi)$ 的变换，让六边形在$(\\theta,\\phi)$ 的坐标上是均匀的。 画一个密铺六边形半球的步骤 用python画一个密铺的六边形：  , 画上辅助线： 做变换    这一步得到的是我们设想的半球面的投影, 看起来确实给人一种六边形能组成球形的错觉。。  另外，Photoshop里面球面化的滤镜，看起来效果差不多，可能也是用了这个变换。                    又对比了一下原图，嗯？费伦的结界难道也是这么画的？把得到的投影映射到半球 转到侧面看下：   看起来确实挺正常的，当然，这样的两个半球也合不成一个全是六边形的球，因为如图上边界的地方： 展开会变成5边形，7边形，8边形 代码 hex.py 其他讨论这个的链接： [1] https://zhuanlan.zhihu.com/p/673051340 [2] https://www.163.com/dy/article/IMH50ITS0526FP3N.html 动画另一个地方 其实还是有半球法阵的  ","categories": ["docs","geometry"],
        "tags": ["content","idea","动漫"],
        "url": "https://roshameow.github.io//personal_homepage/docs/geometry/hexigon-hemisphere/"
      },{
        "title": "aperture衍射模型 (一)",
        "excerpt":"光的传播理论 Huygens–Fresnel principle理论： 假设光源在$(x^\\prime,y^\\prime,0)$ , 方向是$z$ 方向，能量是$E$ 传播到$(x,y,z)$ 的electric field是$E(x,y,z)=\\frac{1}{i\\lambda}\\cdot E \\cdot\\frac{e^{ikr}}{r}\\cdot \\frac{z}{r}$ $r$ 是$(x,y,z)$ 到光源的距离 $\\lambda$ 是波长 $k$ 是wavenumber: $\\frac{2\\pi}{\\lambda}$ diffraction 考虑由光圈所在平面到sensor这一段, 假设$z$ 固定为aperture和sensor的距离，光源为从aperture向sensor方向的平行光 从aperture $A$ 透过的能量是 $E(x,y,z)= \\int\\int_A \\frac{z}{i\\lambda r^2} E(x^\\prime,y^\\prime,0)\\cdot e^{ikr}\\cdot dx^\\prime dy^\\prime$ ，形成的pattern主要受$e^{ikr}$ 这个高频项的影响,主要能观测到的pattern可以用下面两类衍射模型近似 Fresnel diffraction(菲涅耳衍射) 假设 : $r\\approx z+\\frac{(x-x^\\prime)^2+(y-y^\\prime)^2}{2z}$ $r=\\sqrt{z^2+\\rho^2}=z\\sqrt{1+\\frac{\\rho^2}{z^2}}$ , 其中$\\rho^2=(x-x^\\prime)^2+(y-y^\\prime)^2$ 展开为 $r=z(1+\\frac{\\rho^2}{2z^2}-\\frac{1}{8}(\\frac{\\rho^2}{z^2})^2+\\cdots)\\approx z+\\frac{\\rho^2}{2z}$...","categories": ["docs","simulation"],
        "tags": ["content","simulation","sensor","physics"],
        "url": "https://roshameow.github.io//personal_homepage/docs/simulation/diffraction/"
      },{
        "title": "aperture衍射模型 (二)",
        "excerpt":"仿真 在aperture区域均匀采样，发现Frensel pattern是很难出现的，在每个像素对应sample数不足1000的时候，基本观测不到。。应该是因为在那个范围内结果受$(x^\\prime,y^\\prime)$ 的位置影响更大, 也就表现出更大的随机性。 确实可以看到sensor到aperture距离增大后, pattern变化的全过程。 在一个网上找的Frensel diffraction仿真 java代码里面，作者也是通过先把部分积分形式通过公式运算先化简之后做的仿真1，没有用原始的传播公式。 如果用全光谱的光源，Fraunhofer衍射中因为波长影响, 看起来的效果像是从中间不同颜色的光被diffuse了，我看一些3d建模制作里说的衍射，一般是指这种效果，可以看b站上一个用blender仿这种效果的视频 另外判断天然珍珠和人造珍珠的区别的一种方法，也是看天然珍珠里面有微小的结构可以把不同波长的光区分出来的效果 blender的cycles用的是粒子模型, 没有相位变化，可能没法直接得到衍射 应用 在相机系统中，我们关心成像的分辨率：用Fraunhofer的模型估算相机的resolution 相机aperture参数：这两个都是dimensionless版本的aperture f-number: $N=\\frac{f}{D}=\\frac{f}{2a}$ 相机焦距$f=z$, 光圈直径$D=2a$ numerical aperture $NA=\\frac{a}{\\sqrt{f^2+a^2}}=\\frac{1}{\\sqrt{4N^2+1}}\\approx \\frac{1}{2N}$ 第一圈黑环处距中心距离，认为是相机的optical resolution: 此时是$J_1(x)$ 的第一个0点， $J_1(ka\\sin\\theta)=0$，$ka\\sin\\theta\\approx 3.83$ ，即$\\sin\\theta\\approx \\frac{3.83}{ka}=\\frac{3.83\\lambda}{2\\pi a}=1.22\\frac{\\lambda}{D}$ 得到optical resolution $q=r_1\\sin\\theta\\approx \\sqrt{f^2+a^2}\\sin\\theta=\\frac{a}{NA}\\sin\\theta\\approx \\frac{a}{NA}\\frac{1.22\\lambda}{2a}=\\frac{0.61\\lambda}{NA}$ 理论上，numberical aperture越大，optical resolution越小，分辨率越高(也就是衍射更不明显) 相机的成像清晰度指标：MTF PSF(intensity function): $PSF=|G(p,q)|^2=|F(g(x^\\prime,y^\\prime))|^2$ PSF的单位是 (distance(mm),intesity) 对于圆形aperture：$PSF=\\frac{J_1^2(ka\\sin\\theta)}{(ka\\sin\\theta)^2}$...","categories": ["docs","simulation"],
        "tags": ["content","simulation","sensor","physics"],
        "url": "https://roshameow.github.io//personal_homepage/docs/simulation/diffraction1/"
      },{
        "title": "传感器颜色调制 (三) -- 数据",
        "excerpt":"各种颜色调制的数据对难以采集, 所以现在大部分颜色调制还是用多光谱数据仿真得到. 多光谱数据集 数据集$\\downarrow$ size bands 格式 数量 拍摄场景 发布时间 大小 条件 拍摄条件 CAVE 512x512 400-700nm10nm steps31bands .png每个通道分别存 32 实验室:真假人脸真假水果 2008 419.9MB     CAVE1024 1024x1024     205     13.06GB     KAIST 2704x3376 420-720nm10nm steps31bands .exr每个图片单独下载 30 实验室 2017 8.67GB     TSA 660x660 28通道特殊 .mat 10(simu)5(real)...","categories": ["docs","data"],
        "tags": ["content","dataset","pytorch","script"],
        "url": "https://roshameow.github.io//personal_homepage/docs/data/color-moderate2/"
      },{
        "title": "电子产品的频闪讨论",
        "excerpt":"频闪就是亮度随时间周期性变化的情况. b站影视飓风关于频闪的介绍: 频闪的分类 种类 原因 频率 形态 可能解决方式 光源 交流电产生的 100hz或120hz $|\\cos x|$ 调整拍摄频率和交流电保持一致调整快门时间, 让快门覆盖整数个周期 LED屏幕 PWM调光 都有 rectangular pulse由duty cycle(占空比)决定 除了增加快门时间, 让条纹不明显目前没有什么好的解决方式 我手里的电子设备观测 按照模型, 影响拍到的pattern的有: 相机的频率$f$, 快门时间(&lt;$\\frac{1}{f}$), 相位(快门扫描速度), pwm的频率, 占空比, 每行的相位. 我们用相机去拍屏幕的时候,拍到的理论上亮, 暗的部分都是由于相位的不同, 不会相差超过一个周期, 所以$\\frac{最亮}{最暗}&lt;\\frac{ceil(\\frac{快门时间}{pwm周期})}{floor(\\frac{快门时间}{pwm周期})}$ 条件: 用我的iphone11拍摄, 240fps的慢镜头, 快门时间不知道, 但是大概有1/500s左右? iphone12手机: 另一个方向: 在同一帧内, 在一个方向是横条纹, 把镜头换了一个方向却出现了斜向的条纹: 合理的解释是可能屏幕上不同行的led灯相位不同. 考虑到相机每行是同时曝光的, 相机和屏幕垂直拍摄就会出现在一行拍到了多个相位的情况, 也就是斜向的条纹...","categories": ["docs","camera"],
        "tags": ["content","test","sci-pop"],
        "url": "https://roshameow.github.io//personal_homepage/docs/camera/flicker/"
      },{
        "title": "blender学习: 用displacement做动态鸟群",
        "excerpt":"步骤 参考RuiHuang_art在b站的教学视频 world property: background改成黑色 加入鸟群所在的mesh 加入鸟群贴图: 在material property里修改 把贴图连到alpha通道 blend mode改为alpha blend 加入displacement: 在modifier property里修改 加入subdivision surface: 用Catmull-Clark 的方法细分(迭代进行, 每次加入新的点后, 会移动顶点位置, 让整体更平滑) levels viewport 增加到5: 对应编辑时, 看到的细分的迭代次数, 可以调的比render低一些 render增加到5: 对应最终渲染时, 看到的细分的迭代次数 加入displace: 根据texture的灰度值变换顶点的coordinate 代码可能在: https://github.com/blender/blender/blob/main/source/blender/modifiers/intern/MOD_volume_displace.cc 加入texture-&gt;调整texture的属性 type用Clouds, 也就是Perlin noise : 多个不同粒度的随机叠加 Depth参数控制模糊程度: 应该是Perlin noise生成时的粒度有几层 其中nabla($\\nabla$ ) 参数好像对Perlin noise没影响.. coordinate设置成global:...","categories": ["docs","blender"],
        "tags": ["content"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning2/"
      },{
        "title": "blender学习: 用volume shader做气态行星",
        "excerpt":"步骤 参考RuiHuang_art在b站的教学视频 world property: 加入一个太空背景的贴图 光源：改成sun light strength改成12: 单位是 $W/m^2$ volume改成3: 控制在volume shader时的影响? render: 用eevee 设置volumetrics参数 打开volumetric shadows start, end: 相对相机的体积效果范围, 设为(3.3m-&gt;200m) tile size: volume块大小 shader: 用principled volume : 把mesh包含的部分看成volume块 color: 用texture Coordinate 生成volume的坐标 Image Texture 把2d的木星贴图映射到3d的volume上 用Hue/Saturation/Value Node 调颜色 density: 一个从里到外逐渐稀薄的球形+被纹理的影响 用texture Coordinate 生成volume的坐标 object生成一个在中心的坐标系 用 Image Texture 生成一个按照贴图纹理亮度的scale,...","categories": ["docs","blender"],
        "tags": ["content","render","shader"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning3/"
      },{
        "title": "blender学习: 用graph editor做赛博车流",
        "excerpt":"步骤 参考RuiHuang_art在b站的教学视频 world property: 加入一个CyberPunk背景的贴图 texture Coordinate 选择camera坐标 制做车流: 添加一个Plane mesh 在Edit编辑模式下, 按A选中, S+X, S+Y 沿X,Y轴双向拉伸, 拉成长条形 shader: 目的是把车流改成带纹理, 自发光, 透明的效果 color: 下载一个灯火通明的城市俯瞰图 我们只想要图中亮的地方 emission: 把贴图纹理连到bsdf的emission 需要调整strength: 把strength调大之后好像发的都是白光? alpha(调整车流的透明度): 除了贴图本身暗的地方转成透明, 我们还想要一个两端完全透明-&gt;中心的渐变 根据原图亮度设置透明: 暗处透明, 亮处不透明 给贴图连接一个Color Ramp 设置两端完全透明-&gt;中心的渐变 用texture Coordinate 的uv生成平面的坐标 用Gradient Texture 提取x方向 用 Color Ramp 做一个 暗-&gt;亮-&gt;暗 的渐变 用Mix...","categories": ["docs","blender"],
        "tags": ["content","render","shader"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning4/"
      },{
        "title": "龙年春联",
        "excerpt":"上联是“查找，回退，终止，定义，返回，格式化，删除”下联是“启动，切换，上一级，根目录，查找，替换，退出”横批是“全部历史” 本以为会简单的制作过程, 居然感触挺多的 制作时间轴 看到小红书上这个ps春联的帖子 最开始是想做vscode和obsidian的图标 做着做着, 感觉快捷键更有分享欲; 而且, 图标截图下来有清晰度和大小不一的问题 直接写在红底黑字的春联底色上, 看起来太单调了 想用stable diffusion生成个华丽的背景, 但是… 放弃 基于v1.5的模型没法理解春联, 也没法理解龙 生成的这种看起来挺奇怪的东西: canny的controlnet没法保证文字的细节一致: 生成的龙😮‍💨: SDXL可以生成不错的龙, 虽然细节不对 ComfyUI的工作流我用的不太熟练, 而且, 我不太了解各种风格的prompt 在小红书上搜索春联的版式, 看到了这个帖子 模仿失败: 卖家秀$\\rightarrow$ 买家秀$\\rightarrow$ 我的图看起来像东南亚黑帮, 又像个祭坛 当然我的颜色调的不对, 但是我也明白了这个排版不适合龙(你的内容是现代的, 但是排版却相当古老, 你究竟是什么人😂) 又回归了黑白红配色, 改了版式, 感觉能看了, 蛮喜庆的, 有种过年的气氛了工具 pinterest搜索, 然后推荐相似风格的图片 eagle存图 Freeform排版 可惜Freeform里面没法改图片整体的颜色, 也没法旋转 preview的魔棒工具 中间想用photoshop,...","categories": ["docs","design"],
        "tags": ["content"],
        "url": "https://roshameow.github.io//personal_homepage/docs/design/spring-couplets/"
      },{
        "title": "常用的图像 reconstruction loss",
        "excerpt":"输出为图像的任务, 比如enhance, deblur, super-resolution, generation等用到的loss, 主要分为以下几类 output和label相近 loss 公式 目的 特点 L1 loss $||I_1-I_2||_1$ 大体相近 最常用的loss L2 loss(MSE) $||I_1-I_2||_2$或$MSE=\\overline{(I_1-I_2)^2}$   因为导数是线性所以计算最快 SSIM (stuctural similarity index measure) $\\frac{2\\mu_1\\mu_2+C_1}{\\mu_1^2+\\mu_2^2+C_1}\\cdot \\frac{2\\sigma_{12}+C_2}{\\sigma_1^2+\\sigma_2^2+C_2}$ $\\mu, \\sigma$ 分别为mean, variance$\\sigma_{12}$是covariance$C_1, C_2$ 是常数 纹理相近 要分patch计算$C_1, C_2$ 的值要根据图像的范围调整 PSNR(Peak signal-to-noise ratio) $-10\\log_{10}(MSE(I_1,I_2))$   经常是用来验证 PerceptualLoss 一个分类网络 语义相近 一般用vgg16, 输入RGB图像一般会用后几层的语义特征对比 LPIPS...","categories": ["docs","deeplearning"],
        "tags": ["content","loss","image"],
        "url": "https://roshameow.github.io//personal_homepage/docs/deeplearning/restruction-loss/"
      },{
        "title": "神经网络attention结构理解",
        "excerpt":"在网络中, block是把input信息转换成output信息的过程: 一般, output(position, vector)是input(token, embedding vector)的线性组合, 组合的weight (position, token) 由input和output两方关系确定. 把着重强调这种信息交互的模块叫attention. convolution convolution在神经网络流行之前就已经在图像任务里广泛使用了 目的: 对spatial information进行特征的提取和转换 特点: pixel的weight只和(input, output)的相对位置有关, 因此也是平移不变的. 对每个输出像素有影响的只有input里kernel覆盖到的区域, 也就是response field 每个不同的相对位置对应vector mapping不同 这个符合图像处理的直观, 左边有条线和右边有条线当然要映射成不同的结果 有时也会把卷积拆分成1x1 conv和spatial conv(通道无关) 的形式 gate attention 目的: 提取channel1或spatial的权重, 让网络关注更重要的信息 特点: spatial 信息对人类来说更有可读性, 所以可以把spatial weight可视化, 看看图片什么位置更加重要 self-attention &amp; cross-attention 目的: 信息的交互: 在我的图示中, 是把文字信息加入视觉信息...","categories": ["docs","deeplearning"],
        "tags": ["content","network","attention","block"],
        "url": "https://roshameow.github.io//personal_homepage/docs/deeplearning/attention/"
      },{
        "title": "stable-diffusion的用法: 用 ipadatper+controlnet canny做风格转换",
        "excerpt":"用ipadapter和canny做风格转换 ComfyUI使用 调用ComfyUI中default的工作流 下载sdxl模型 连上IPAdapter节点 安装IPAdapter_plus插件 下载需要的ipadater微调模型和clip vision编码器: 把图像用clip vision编码后输入base model的cross-attention层 ComfyUI里连接顺序是: Checkpoint: model-&gt; IPAdapter: model -&gt; KSampler: model weigt设为1, text prompt都空着, latent prompt也空着 连上Controlnet节点 下载canny模型 找不到其他适合sdxl的controlnet模型因为我们的原图是个线稿适合用canny ComfyUI里连接顺序是: Checkpoint-&gt;prompt-&gt;controlnet-&gt;Ksampler: text prompt controlnet最后是作用在condition(positive, negative)上的, 和text promt一样 调整controlnet权重和影响步数: stength=0.5, start_percent=0, end_percent=0.6 如果设置过大就只能得到一张有颜色的线稿图 结果 原图: + 合成图: 竟然可以识别龙的眼睛啊…有好几幅图都把猫眼替换到了龙眼上 如果两种图有同样的元素(眼睛之类的), 可能可以比较好的替换 最后的龙和人, 龙和山, 都不能对应起来...","categories": ["docs","photo"],
        "tags": ["content","ComfyUI","ipadapter","controlnet","canny","sdxl"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion1/"
      },{
        "title": "blender学习: 做火焰效果",
        "excerpt":"火焰的形状用圆形变形一半获得. 用Perlin noise使坐标变形制作随机抖动. 用Emission node渲染发光效果. 用graph editor和noise texture -&gt; 飞行器火焰 步骤 参考RuiHuang_art在b站的教学视频 , 和做车流用到的功能差不多 world property: 加入一个背景的贴图 制做一个平面的火焰: 添加一个Plane mesh 分成两半: 在Edit编辑模式下, 按Ctrl+R加loop cut , 在edge中间添加新的顶点, 把一半拉长: 选中顶点后按G+Y在Y轴拉伸 shader: 目的是制作一个自发光, 半透明, 抖动的效果 颜色效果: 用texture Coordinate 生成uv坐标 在mapping里把x,y的location调到-2, scale调到4 uv坐标系好像范围是(-scale/2, scale/2) 用Gradient Texture 的spherical: 制作从外到内的渐变 自发光: 用Color Ramp 做一个 蓝-&gt;白-&gt;红-&gt;黄 的渐变...","categories": ["docs","blender"],
        "tags": ["content","render","shader","粒子系统"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning5/"
      },{
        "title": "stable-diffusion的用法: 用 lora+controlnet做风格转换",
        "excerpt":"尝试只用ipadapter做猫的风格转换, 非常不成功, ipadapter还是无法控制输入的元素. 必须要用多张图片训练的LoRA才能固定ip.另外, 猫脸上颜色分布的特征, 没有controlnet可以直接表示. ComfyUI步骤 训练Lora 用kohya_ss 的gui训练 network rank设置64 打开Gradient checkpoint, 不然我16G的显存不够用 另外, 我的wsl2需要解决一下找不到cuda toolkit的问题 检查发现是ubuntu的requirement里面指定的torch和bitsandbytes版本不匹配 在虚拟环境里, 升级到最新版2.2后代码又出问题 最后参考windows版本的requirement.txt, 改成torch=2.1.0+cu118解决了 连上Lora节点 ComfyUI里连接顺序是: Checkpoint: model, clip -&gt; Lora 多个Lora顺序连接就行 ip的lora的weigt设为1.22, 风格化lora的weight不用设那么大 写text prompt 写了包括描述内容的, lora配套的, 描述想要风格的positive prompt 连上Controlnet节点 用到了canny模型, depth模型 下载Marigold的深度识别模型节点 结果 -&gt; -&gt; (ipadapter控制风格) 风格: 3种方法都可以 text...","categories": ["docs","photo"],
        "tags": ["content","ComfyUI","ipadapter","controlnet","canny","sdxl"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion2/"
      },{
        "title": "blender学习: 玻璃杯",
        "excerpt":"由cylinder变形得到水杯. 用cycles渲染玻璃材质. 步骤 参考这个b站的教学视频 制作水杯: 添加一个cylinder 删除上下两个底: 在Edit Mode, 开启透视, 按3选中面删除 把下底缩小一点: 按1选中顶点 填充底面: 用Ctrl+F填充, 选择Grid Fill, 调节Offset 做出玻璃杯的厚度: 选中上面的顶点, 用E+S向内 做出玻璃杯的内层: 继续E+Y向下, S向内 做出玻璃杯的内底: Ctrl+F填充, 选择Grid Fill , 调节Offset 把杯子变光滑: 在边缘处添加loop cut(卡线): Ctrl+R 增加loop cut, Ctrl+B向上下拉伸 添加loop cut是为了之后把杯子边缘变成弧形, 而不影响杯壁和杯底平的部分 Shift+option 长按出现选项, 选中loop, 按G移动loop进行微调 改成shade smooth 加一个subdivision modifier 制作拍摄场景: 添加一个plane...","categories": ["docs","blender"],
        "tags": ["content","shader","3d_model","shortcut"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6/"
      },{
        "title": "photoshop: 酸性风格海报",
        "excerpt":"酸性(acid)风格 迷幻感 . 设计元素包含: 高饱和, 流动性, 未来复古元素, 格纹, 镭射金属, 霓虹色. 这个链接解释的比较详细 制作液态效果, 流动感, 金属感 在网上看到的两个简易教程$\\downarrow$ 物体只保留纹理 选取素材变成gray image: 图像-&gt; 调整 -&gt; 黑白 制作物体中间类似流动金属的效果 教程1的做法: 复制物体 gaussian滤波 不想有显得特别不光滑的地方 反色 下层用铬黄渐变, 细节,平滑度调到最高 上层混合模式改成正片叠底(multiply): $I_1*I_2$ 保留原物体的细节 上下两个图层合并 混合模式改为滤色(screen): 是$clip(I_1+I_2,0,1)$ 吗? 因为看到结果有全白部分 仿玻璃的质感: 透明, 并比原图层亮 教程2的做法: 复制物体 上层反色, 用差值模式(difference): $abs(I_1-I_2)$ 这个结果是越偏离中间值128的像素越亮 上下两个图层合并 重复2-3次 这个的结果可能是在0-255范围内设置了几个量化点,...","categories": ["docs","photo"],
        "tags": ["content","photoshop","filter","design"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/photoshop1/"
      },{
        "title": "stable-diffusion的用法: 常用的作图功能-抠图, inpainting, 引导图",
        "excerpt":"用SAM抠图 以下两种方式都是对segment-anything二次封装 在ComfyUI里用segment anything节点 特点: 任何shape都可以, 输入text prompt, 但是没法输入位置 步骤: groundingDINO模型: image, text prompt-&gt;目标检测box SAM模型: image, box-&gt; mask SAM模型本体可以接受多种形式的prompt SAM模式的特点是对image只encode一次, 这里box是作为prompt形式输入的, 不是在图像上crop然后处理cropped image 🤔️: SAM本来就可以输入text prompt, 加入groundingDINO模型是因为SAM的text promt效果不好吗? inpaint-anything 特点: 输入point prompt和text prompt(optional), 对输入图像大小有要求, 还接入了一个stable-diffusion的inpaint模块 inpainting &amp; outpainting &amp; guided 图生图功能: 利用stable-diffusion的sampler流程, noise mask之外的部分网络就不会去更改, 利用VAE decoder的填补能力 VAE encode成latent: 根据情况选择图像输入 输入原图:...","categories": ["docs","photo"],
        "tags": ["content","ComfyUI","sdxl","inpaint"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion3/"
      },{
        "title": "stable-diffusion的用法: 常用的作图功能-提升细节",
        "excerpt":"和inpaint一样要利用stable-diffusion的图生图功能, 想让图像忠于原图的情况下提升图像细节, 解决图像模糊, 扭曲, 不合理的部分. 使用 模型: 一般模型: 对于模糊的图, encode+ksample+decode就可以提升细节 StableSR: 基于sd2.1, 关于细节修复任务重新训练的模型 sdxl refiner模型: 输入latent image, 官方建议接在sdxl base模型的后面用 sdxl refiner一般只能配和sdxl base模型, 不能配合其他风格的sdxl模型, 所以不是很实用 控制: 更像原图: 风格控制: 和inpaint一样, 可以用text promt和ipadpater控制 微调模型控制: controlnet tile(配合v1.5模型): 这是个非常好用的模型👍, 可以在分块(输入的不是一整张图)的时候, 更倾向理解图像部分而不是text prompt 关于sdxl模型没有一个tile模型的讨论 提升细节: 从流程上控制: Self-attention Guidance(SAG) 和cfg(class free guidance)类似, 是更改reverse diffusion process的过程 让图片变清晰原理: 认为self-attention值更大的位置是更重要的位置,...","categories": ["docs","photo"],
        "tags": ["content","ComfyUI","sdxl","refine"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion4/"
      },{
        "title": "stable-diffusion的用法: 常用插件",
        "excerpt":"ComfyUI使用时用到的插件 插件 用途 类型 必须? ComfyUI-Manager - 查找和安装插件和模型- 可以识别工作流中的missing node 功能 ✔️ rgthree-comfy - 显示一个node执行进度条- 优化节点执行graph- 提供Image Comparer节点- Lora Loader Stack 节点 功能   Resize resize图片 功能 ✔️ image-saver Save Image w/Metadata节点把图片生成的信息写到图片metadata里(webui有类似功能) 功能   Impact-Pack 很多功能, 但是有些感觉封装的太复杂了 功能   Comfyroll_CustomNodes CR开头的一堆节点 功能   UltimateSDUpscale - 分块图生图- 改变tile的一些融合方式 功能   comfyui-mixlab-nodes...","categories": ["docs","tool"],
        "tags": ["content","ComfyUI"],
        "url": "https://roshameow.github.io//personal_homepage/docs/tool/stable-diffusion5/"
      },{
        "title": "stable-diffusion的结构和微调模型",
        "excerpt":"stable-diffusion结构和controlnet插件 controlnet保持和stable-diffusion u-net上半部分相同的结构 controlnet输入是和原图一样的hint图像 比如controlnet-openpose输入的不是关节坐标数据, 而是彩色的人体坐标图 这也是像controlnet-tile, controlnet-inpaint等从任务角度明明不需要hint image还是要输入一个的原因 Resnetblock, SpatialTransfomer 结构和插件 lora可以应用在网络的任何线性结构上, 比如: attention里面的q,k,v,out层 feedforward里面的linear层 clip里面的mlp, fc层 这几种模型的作用的粒度不一样, 从小到大是: lora(线性层) &lt; Gligen=IpAdapter(SpatialTransformer层) &lt; Controlnet(U-net的block) 模型的size也是依次变大 各种embedding编码方式 类型 输入 编码 公式   图像 可训练的hint block网络(controlnet)或clip vision(ipadapter)     文字 clip   一维特征 $\\mathbb R$ time Sinusoidal Embedding 三角编码 $[\\sin\\frac{t}{10000^{2n/d}},\\cdots,\\cos\\frac{t}{10000^{2n/d}},\\cdots]\\in \\mathbb...","categories": ["docs","deeplearning"],
        "tags": ["content","attention","stable-diffusion","lora","controlnet","ipadapter","gligen"],
        "url": "https://roshameow.github.io//personal_homepage/docs/deeplearning/stable-diffusion6/"
      },{
        "title": "blender学习: 做卡通描边",
        "excerpt":"用solidify+背面剔除+法线翻转 给mesh增加厚度, 让描边材质只在厚度边缘生效 步骤: 参考这个教学视频   shader:          选择一个主material的效果(Slot 1): 用Diffuse BSDF-&gt;shader to RGB-&gt;Color Ramp-&gt;Emission      添加一个描边材质(Slot 2): 用Emission, 选择我们描边的颜色                  对这个材质开启Backface Culling(背面剔除)                      在Modifier添加solidify: 给mesh表面增加厚度                 调整thickness=-0.02m                  offset默认是-1, 要让thickness和offset同方向(让增加的厚度mesh朝外凸)                    Materials-&gt;Material Offset=1 :让solidify的厚度mesh采用我们的描边材质, 即下一个slot的material      开启Normals-&gt;flip: 让颜色上到厚度mesh的内表面        结果: 对三维的模型描边有种新鲜的观感.                描边的前提是提取边缘. 如果是二维图像有很多做法, 比如自动提取图像的边缘合并. 对于我们自己建的模型当然也有办法提取边缘. 但是如果其他方式得到的模型(比如扫描得到的模型), 我们怎么识别边缘, 然后edit呢?      blender使用技巧   复制material和modifier:          按这个方法 可以复制到全部, 但是没法选择materail的单个slot😠, 只能全部复制过去?      其他描边效果 [1] https://svg-animation-booklet.vercel.app/chapter5.html#实现动画 svg描边动画 ","categories": ["docs","blender"],
        "tags": ["content","material","stoke","modifier","solidify"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning7/"
      },{
        "title": "attention的优化-- 引进时序结构",
        "excerpt":"在token很多(大模型用的超长文本), 或者本身数据是时间序列(比如语音, 视频流)的情况下, attention里面的weight会带来$O(token^2)$ 的内存消耗. state space model可以解决这个问题. 基本结构 SSM(state space model) 状态空间(state space) : 用state vector记录历史的input, 而不是记录所有的历史token 连续表示: linear state space model的一般形式: $\\dot x(t)=A(t)x(t)+B(t)u(t)$ (用input u更新状态 x) $y(t)=C(t)x(t)+D(t)u(t)$ (用状态x, 生成output y) 如果A,B,C是time invariant, 以及省略D, 得到, $\\dot x(t)=Ax(t)+Bu(t)$ 解得 $x(t)=e^{At}x(0)+\\int^t_0 e^{A(t-\\tau)}Bu(\\tau)d\\tau$ , $x(t)$ 是$u(t)$ 的卷积形式: $x(t)=K(t)*u(t)$, $K(t)=e^{At}B$ $y(t)=Cx(t)$ 离散表示: 迭代的表示:...","categories": ["docs","deeplearning"],
        "tags": ["content","SSM","state space model","state","linear attention","time series","Mamba","attention"],
        "url": "https://roshameow.github.io//personal_homepage/docs/deeplearning/attention2/"
      },{
        "title": "blender学习: 做流光效果",
        "excerpt":"用金属材质反射world背景的流动 步骤: 参考这个教学视频   制作物体:          添加curve      调整Data-&gt;Geometry-&gt;Bevel(倒角)-&gt;Round-&gt; Depth: 把曲线变成软管      加modifier-&gt;subdivisor        shader:          object: 用principled BSDF, 把metallic调到1, roughness 调整到0.1      world:                  在background添加流动材质                          设置texture Coordinate  generate-&gt;Mapping(Y=#frame/40)-&gt;background图片                                得到黑色背景                          添加一个黑色背景, 用Light Path的Is Camera Ray控制混合 : 背景和物体分开的原理?                                            light: 改成sun, 给物体增加反光  结果:                ","categories": ["docs","blender"],
        "tags": ["content","shader","curve"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning8/"
      },{
        "title": "blender学习: 镜头推移",
        "excerpt":"前向推镜头 参考这个教学视频, 用array modifier复制多个模型 , 得到一种穿梭效果  模型资源 [1] https://sketchfab.com/feed ","categories": ["docs","blender"],
        "tags": ["content","camera"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning9/"
      },{
        "title": "attention的优化-- flash attention加速",
        "excerpt":"flash-attention是一种算子合并(kernel fusion)的优化. 把self-attention分块, 直接在SRAM里计算, 省去了HBM来回搬运中间结果S和P的时间(如下图). self-attention由两层矩阵乘法, softmax, 和其他eltwise计算(mask, dropout)构成. attention分块计算 forward计算: Q,K,V -&gt; O 矩阵分块如上图: 都是在token的维度分块 i iteration循环(黄色部分) 每次i iteration需要load不同位置的 Q, O j iteration循环(浅色部分) 每次j iteration需要load不同位置的 K, V softmax计算: $softmax(x)=\\frac{e^{x}}{\\sum_j e^{x_j}}$ , 其中$\\sum_j$ 是rowsum safe softmax: $softmax(x)=\\frac{e^{x-m}}{\\sum_j e^{x_j-m}}$ 为了避免$\\sum_j e^{x_j}$ 产生特别大的值溢出 softmax分块: 对于relation S的每个分块的patch $P$, 记: 局部最大值 $m_p=\\max_{x\\in P}(x)$, 局部rowsum...","categories": ["docs","algorithm"],
        "tags": ["content","attention","flash attention","speedup","gpu"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/attention3/"
      },{
        "title": "blender学习: 用粒子系统做毛毡效果",
        "excerpt":"步骤: 参考这个教学1 教学2 Paticles添加毛发粒子: Particle type选择hair Emission number=5000 发根的总数量 hair length=0.03 Segments = 5 卷曲? Render -&gt;Path-&gt;Steps=5 对hair做subdivision的次数 Viewport Display-&gt; Strand Step=5 Children 选择simple display amount=100, render amount=100 Radius调整: 影响毛发膨胀度 Roughness Random = 0.08 Size = 0.851 Kink(纽结)选择Curl Amplitude(振幅) = 0.03 Hair shape Diameter Root &gt; Tip shader: 给Particles添加一个Principle Hair...","categories": ["docs","blender"],
        "tags": ["content","粒子系统","hair"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning10/"
      },{
        "title": "pyside6一些功能的用法",
        "excerpt":"pyside是qt的python封装, API的调用方法基本差不多. 用pyside从零开始写一个gui用于标注或测试(调参数或者看中间结果), 每次花费时间都比想象的要少的多. 功能方便而且代码的可读性非常好. 工具 designer和vscode desginer主要用到promote, 加载资源, 配置qss的功能 vscode的PYQT Integration, 配置好uic, rcc路径后, 可以右键编译事例 视频播放 用QTimer和opencv实现 把label提升到自定义可以drop file的LabelImage 用timer设置play, pause功能, 进度条拖动功能 代码: main.py , Ui_LabelImage.py动态折线图 用QtCharts实现 界面画出QWidget并提升到自定义的LineChart, 继承QChartView 定义chart和series 修改QChartView的样式: 在designer里用qss实现 修改QChart的样式: QChart调整和QChartView之间的Margin QChart调整axis和边界之间的Margin QChart设置样式 添加series update代码 代码: update_frame.py , line_chart.py图像标记 选择文件: 在QTreeView上设置model为QFileSystemModel 互动标记图片 用paintEvent和QPainter实现标记 切换label 用QFile替换svg的颜色 显示位置数据: 在QTableView上设置model为自定义的PandasModel...","categories": ["docs","tool"],
        "tags": ["content","pyside6","gui","python"],
        "url": "https://roshameow.github.io//personal_homepage/docs/tool/pyside6-tech/"
      },{
        "title": "EMVA1288 sensor测试",
        "excerpt":"参数: QE $K, \\eta$ 成像模型 input 中间结果 output 参数 参数 变量下标 p e y qe或$\\eta$ $K$ 含义 光子 电子 读数 QE(Quantum Efficiency) System Gain 测量方式 由积分时间+ sensor面积 得出公式: $\\mu_p=\\frac{\\text{辐射能}}{\\text{单个光子的辐射能}}=\\frac{A(sensor面积)\\cdot t(曝光时间)\\cdot E(辐射照度)}{h(\\text{普朗克常数})c(\\text{光速})/\\lambda(\\text{波长})}$   直接测量$y(t)$     分布 Poisson分布         公式关系   $\\mu_e=\\sigma_e^2$ $K\\mu_e=\\mu_y-\\mu_{y.dark}$       统计变量 $\\mu_p,...","categories": ["docs","sensor"],
        "tags": ["content"],
        "url": "https://roshameow.github.io//personal_homepage/docs/sensor/EMVA1288-sensor/"
      },{
        "title": "blender学习: 几何节点做摄像头移动阵列",
        "excerpt":"参考这个教学 建模 直接复制作者的模型和材质 箭头 摄像头步骤: 制作摄像头阵列: 用Instance on Points节点 添加一个Plane mesh, 在modifier添加几何节点 在Points的地方制作一个meshgrid: 用Grid节点调整Grid大小和距离: 相对plane平面 用Vector Rotate节点 批量调整Plane里面顶点的位置 把摄像头主体和摄像机臂分别设置成为Plane顶点的instance: 用Join Geometry节点连接 设置摄像头主体追踪箭头: 分为 箭头在xz平面平移(看向箭头)和箭头在x轴旋转(跟随箭头点头) 两部分 平移-&gt;关于y轴旋转: 计算Plane里面顶点到箭头的vector: 这里面Position节点给出的是Plane每个顶点的location 用Align Euler to Vector节点 设置成关于y轴旋转(因为y轴是摄像机头本来的朝向?) 旋转-&gt; 旋转: 提取箭头Rotation的x轴反向旋转, 用Rotate Euler节点的local模式添加到Plane的Rotation(plane每个顶点的rotation) 制作箭头绕圈和点头动画: 绕圈: 让箭头围绕一个圈移动 添加一个Circle曲线 给箭头添加Constraint-&gt; Follow Path Target选择刚才的Circle Option+G清除位置: 加了follow path constraint之后,...","categories": ["docs","blender"],
        "tags": ["content","geometry_node","track","shortcut","script"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning11/"
      },{
        "title": "画一个环形的重复图样",
        "excerpt":"   公司需要画一个这样的图像, 本来想法是先画一个方形渐变, 复制需要的份数, 极坐标变换.  想全部在photoshop里面完成的, 但是发现不知道怎么复制  转向了python的pil画渐变和复制  用photoshop的极坐标变换和python opencv都可以完成          opencv是图到图的变换        又想到直接画出2d的坐标meshgrid再应用变换好像更容易?代码: ring.py 其他链接 [1] https://zhuanlan.zhihu.com/p/518229060 ps插件 ","categories": ["docs","geometry"],
        "tags": ["content","python","photoshop","opencv"],
        "url": "https://roshameow.github.io//personal_homepage/docs/geometry/ring-pattern/"
      },{
        "title": "小面积光流传感器算法测试 (一)",
        "excerpt":"大概分为: preprocess -&gt; instant flow compute -&gt; filter correct 三个步骤 计算连续两帧的光流 算法 改进 公式 效果 存储占用 LKLucas-Kanade   对图像$I$ 的每个像素, 有 $\\frac{\\partial I}{\\partial x}dx+\\frac{\\partial I}{\\partial y}dy=\\frac{dI}{dt}$ 即, $\\begin{bmatrix}dx \\\\ dy\\end{bmatrix}=\\begin{bmatrix}\\frac{\\partial I}{\\partial x}\\frac{\\partial I}{\\partial x} &amp; \\frac{\\partial I}{\\partial x}\\frac{\\partial I}{\\partial y} \\\\ \\frac{\\partial I}{\\partial x}\\frac{\\partial I}{\\partial y} &amp; \\frac{\\partial I}{\\partial y}\\frac{\\partial...","categories": ["docs","algorithm"],
        "tags": ["content","optical_flow","opencv","test"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/optical-flow-train/"
      },{
        "title": "stable-diffusion中k-sampling的不同版本",
        "excerpt":"Diffusion Process &amp; Reverse Diffusion Process 用Markov chain的表示: $q(x_t x_{t-1})=N(x_t;\\sqrt{1-\\beta_t}x_{t-1},\\beta_tI)$ , $q(x_t x_0)=N(x_t;\\sqrt{\\bar\\alpha_t}x_0,(1-\\bar\\alpha_t)I)$ diffusion收敛到SDE, SDE离散化得到diffusion把DPM表示成SDE(stochastic differential equation): SDE的一般形式: $dx=f(x,t)dt+g(t)dw$ $f(\\cdot,t)$ 是drift coefficients 表示确定的部分 $g(\\cdot)$ 是diffusion coefficients 表示随机部分 $\\omega$ 是Wiener process(布朗运动) SDE的reverse: $dx=(f(x,t)-g^2(t)\\nabla_x\\log p(x,t))dt+g(t)dw$ score function $\\nabla_x\\log p(x,t)$ 指向higher density of data $\\nabla_x\\log p(x;\\sigma)=(D(x;\\sigma)-x)/{\\sigma^2}$ 前半确定部分: Probability flow ODE: $dx=(f(x,t)-g^2(t)\\nabla_x\\log p(x,t))dt$ Variance...","categories": ["docs","algorithm"],
        "tags": ["content"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/stable-diffusion7/"
      },{
        "title": "小面积光流传感器算法测试 (二) -- 特征训练",
        "excerpt":"数据 ① ② : ③ :   采样方式 具体说明 特点 ① 仿真图像+仿真采样Sample 在16x16的图像上随机crop得到8x8的patch, 再随机用grid_sample提取8x8的patch比对正样本: 和patch距离&lt;0.5的patch 从采样方法来说, 当前像素只和周围3x3邻域像素相关 ② 真实图像+仿真采样SampleFromFrame 用实际sensor提供的图片   ③ 真实图像+真实采样SampleFromVideo 筛选实际sensor提供的图片前后帧,用其他算法确定光流已知的图片对,在图片的其他区域采样 这是图像配准特征训练中的一般做法 代码: local_binary.py 结果: 对于究竟学到了哪方面特征, 我很疑惑 出乎我意料的, 是① &gt; ② &gt; ③ 可能是我加噪声的方式和真实情况有差距? 可能是我数据采样中的光流不可靠? 可能是产生了我不清楚的过拟合? adaboost的方法比神经网络训练效果好(或者差不多?) “最好”的训练结果也没比不训练的结果(sad-mean(diff)的版本)好. 可能通过匹配patch计算光流的准确度本来已经达到饱和, 再训练patch的描述也没法提升? 用真实数据的loss比仿真数据要大 说明真实数据更难 用真实图像插值时, 结果变得超差, 改成crop好了一些 torch grid...","categories": ["docs","algorithm"],
        "tags": ["content","optical_flow","deeplearning","adaboost","contrastive_learning","grid_sample"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train2/"
      },{
        "title": "小红书学到的几种图片调色 (二)",
        "excerpt":"人物美白 教程 cameraRaw滤镜 基本: 色温, + 色调 曝光, + 对比度, -高光 混色器: 色相: + 红色, -橙色, –蓝色 明亮度: -红色 校准: 绿原色: +色相 蓝原色: +饱和度 我明白了这件事的难度, 肤色和环境光的作用太subtle了, 美的定义又太多样了. 难怪现在无论什么滤镜都没法把所有人统一的变漂亮. 梦幻发光 教程 调整画面颜色(增加绿色): 可选颜色, 在 CMYK 颜色 调整 黄色: + 青色,黄色,黑色 -洋红 绿色: + 青色,黄色 -洋红,黑色 给高光部分做高斯模糊 混合模式改为变亮 和blender里面的bloom(辉光) 功能原理一样赛博朋克 教程 增加暗处清晰度...","categories": ["docs","photo"],
        "tags": ["content","photoshop","shortcut","filter","color","camera_raw"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/photo-color1/"
      },{
        "title": "小面积光流传感器算法测试 (三) -- 滤波",
        "excerpt":"在高速场景下, 每次中断收集的数据是光流的累加值, 其实本来就相当于一个滤波…况且在硬件有限的条件下, 复杂的滤波没有什么实用价值. 实验 方法   ConfidenceFilter 输出光流时同时输出一个置信度, 如果置信度较低, 选择历史值而不是测量值 FIR 在临近window上的一个线性filter Kalman 在gain值稳定后, kalman滤波其实相当于一个IIR filter 对于整像素的光流结果, 相当于Kalman的MeasureNoise有一部分量化噪声, 应该加大MeasureNoiseCov参数的设置, 不过实验中看不出区别 Kalman在反应速度和平滑度上都要好于FIR的Kalman滤波原理 SSM(state space model) 状态空间(state space) : 用state vector记录历史的input, 而不是记录所有的历史token 连续表示: linear state space model的一般形式: $\\dot x(t)=A(t)x(t)+B(t)u(t)$ (用input u更新状态 x) $y(t)=C(t)x(t)+D(t)u(t)$ (用状态x, 生成output y) 滤波步骤 变量 input predict correct...","categories": ["docs","algorithm"],
        "tags": ["content","kalman","optical_flow","filter","norm"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train3/"
      },{
        "title": "各种 moving function",
        "excerpt":"场景 moving mean leetcode 239 用一个queue保存window里面的数据 每次+新进的数据-出去的数据moving median leetcode 480 naive: 保存window里的所有数据,排序, 找出median 每次更新进出data的顺序 优化1: 当进出的data在median同一侧时, 不需要更新median 优化2: 不需要严格的排序, 只需要维护median两边堆的结构, 就可以找到left的最大值, 和right的最小值 用window记录进出的data 同样的data只存一个位置, 通过一个counter记录data的重复次数, 次数=0就是待删除的data 记录left_heap, right_heap的实际size, 当两边size偏离的时候移动heap 如果删除/移动的data在堆顶, 需要更新堆(把堆顶待删除的data全部删除) 错误方向: 本来想像moving max一样只保留时间近的, median附近的data. 但是moving median中, 所有的元素都可能在之后变得重要, 所以要全部保留的 如果window_size=k, 需要&lt;2/k个更新的data, 或&gt;2/k个更新的data, 才能确定这个data不可能成为median, 这个条件达成的概率很小 moving min/max leetcode 239 以max为例 naive:...","categories": ["docs","algorithm"],
        "tags": ["content","leetcode","basic","data_structure"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/moving_function/"
      },{
        "title": "给网页添加 logo",
        "excerpt":" 用照片制作svg 这次只描了轮廓    用钢笔工具和选择工具画路径:          在最凸，最凹的地方加锚点      添加锚点时拉拽得到切线      按command 单独调整锚点和切线的端点      option调整切线      用直接选择工具(白色箭头)调整锚点位置      用路径选择工具(黑色箭头)复制路径      用颜色填充功能实时查看路径闭包        导出:          选中填充图层复制svg      设置网页的favicon   在对应html设置icon:  &lt;link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/personal_homepage/docs/images/logo.ico\"&gt;          我的路径是head.html-&gt;head-custom.html      资源 [1]  https://www.bilibili.com/video/BV1pP4y1R7r6 钢笔工具使用 [2]  https://www.taoxuemei.com/chuli/ps/754.html 钢笔工具画的形状-&gt;svg [3]  https://zhuanlan.zhihu.com/p/446194623 路径转形状 [4]  https://stackoverflow.com/questions/30551501/unable-to-set-favicon-using-jekyll-and-github-pages  关于icon路径的讨论 [5]  https://convertio.co/download/9dceab468ba01473f3d49fc765b6f73f983c7f/ svg转ico ","categories": ["docs","photo"],
        "tags": ["content","jekyll","photoshop","logo"],
        "url": "https://roshameow.github.io//personal_homepage/docs/photo/jekyll-add-logo/"
      },{
        "title": "blender学习: 用布料系统做膨胀效果",
        "excerpt":"参考这个教学 建模 球和boundary两部分 新建一个Ico Sphere(棱角球) 在Edit Mode选中一些顶点作为boundary, 设为顶点组 给棱角球做一个表面细分并应用 在Edit Mode里用Bevel把boundary拉出一点宽度, 把顶点组改为新的boundary 要先应用表面细分再Bevel? 不然boundary的mesh会变得很复杂 在原位把boundary复制一份(Shift+D), 和球分离(P), 稍微拉大一点(S) 给boundary添加一个2的表面细分 设置shade smooth制作膨胀效果: 选择Physics-&gt;Cloth Pressure = 25 Shape选择boundary的顶点组 Shrinking Factor = -0.3 负数表示要cloth膨胀 Field Weights-&gt;Gravity=0 结果: 用到的blender的一些快捷键 Command+A(应用modifier) Shift+D(Duplication): 复制物体 RMB(右键): 保留在原来的位置 P(分离) 把选中的顶点建一个新的object Command+P(Parent) 把后选中的object设置为先选中的object的parent  Ctrl+B( Bevel, 拉伸, 倒角): 把一个edge变成多个edge, 使物体边缘光滑 按Shift微调:...","categories": ["docs","blender"],
        "tags": ["content","physics","shortcut"],
        "url": "https://roshameow.github.io//personal_homepage/docs/blender/blender-learning12/"
      },{
        "title": "劳动仲裁流程和资料整理",
        "excerpt":"材料 信息: 身份证复印件 公司注册信息: 在国家企业信用信息公示系统 查找公司信息并打印 证据清单 社保缴费记录: 一网通办 登陆打印 参保人员城镇职工基本养老保险缴费情况 银行流水: 在银行app里就可以打印 劳动合同 在企业微信里: 企业微信里的内容很难作为证据, 1. 都是聊天格式, 自己重新整理是没有法律效力的, 2. 而且企业微信被人事踢出后backup也没法恢复 工资条 聊天记录 打卡记录: 企业微信可以导出2个月的, 很麻烦 工时统计表: 没用到, 没研究怎么导出 周报邮件: 没用到 申请书 申请人信息: (姓名、性别、出生日期、身份证号码、住址、联系方式） 被申请人信息: (单位名称、统一社会信用代码、法定代表人、单位地址、联系方式） 仲裁请求(需要计算赔偿) 裁决劳动关系 请求被申请人支付拖欠的工资和年终奖 x元（截至申请仲裁之日）； 请求支付被动解除劳动合同的经济补偿金x元。 事实与理由 按照模版写 地址送达确认书我遇到的情况: 1. 续签劳动合同没给是按照签订了劳动合同处理, 不能索要赔偿, 用社保记录证明劳动关系即可 2. 除了社保记录和银行流水,...","categories": ["docs","affair"],
        "tags": ["content"],
        "url": "https://roshameow.github.io//personal_homepage/docs/affair/labor-disputes-arbitration/"
      },{
        "title": "FFT计算",
        "excerpt":"  fourier Series 定义:          $F(f)(u)=\\int_{-\\infty}^{\\infty} f(x)e^{-2\\pi i x u} dx$      2维：$G(p,q)=F(g(x,y)) = \\int\\int^\\infty_\\infty g(x,y)e^{-i2\\pi(px+qy)}dxdy$        离散形式: 信号$x$ 的FFT 信号$X$          $X_k=\\sum_{m=0}^{N-1}x_m\\cdot e^{-i\\cdot 2\\pi km/N}=\\sum_{m=0}^{N-1}x_m\\cdot TW(N,k)^m$                  $N$ 是信号长度          $TW(N,k) = e^{-i*2k\\pi/N}$ 是FFT 的twiddle factor(旋转因子)                          $TW(N,k)=\\cos(-2k\\pi/N)+i\\cdot \\sin(-2k\\pi/N)=TW_r(N,k)+i\\cdot TW_i(N,k)$                                          butterfly diagram 利用fft的对称性和周期性 ","categories": ["docs","algorithm"],
        "tags": ["content"],
        "url": "https://roshameow.github.io//personal_homepage/docs/algorithm/fft/"
      }]
