<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://roshameow.github.io//personal_homepage/atom.xml" rel="self" type="application/atom+xml" /><link href="https://roshameow.github.io//personal_homepage/" rel="alternate" type="text/html" /><updated>2024-01-23T04:48:49+00:00</updated><id>https://roshameow.github.io//personal_homepage/atom.xml</id><title type="html">Liu, Wen’s Home Page</title><subtitle>Work, Experiments and Ideas.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><entry><title type="html">电子产品的频闪讨论</title><link href="https://roshameow.github.io//personal_homepage/docs/flicker/" rel="alternate" type="text/html" title="电子产品的频闪讨论" /><published>2024-01-19T00:00:00+00:00</published><updated>2024-01-23T20:30:03+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/flicker</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/flicker/"><![CDATA[<p>频闪就是亮度随时间周期性变化的情况.</p>

<p>b站影视飓风关于频闪的介绍:</p>
<iframe src="//player.bilibili.com/player.html?aid=666304538&amp;bvid=BV1ua4y127pk&amp;cid=1408505034&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<h2 id="频闪的分类">频闪的分类</h2>

<table>
  <thead>
    <tr>
      <th>种类</th>
      <th>原因</th>
      <th>频率</th>
      <th>形态</th>
      <th>可能解决方式</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>光源</td>
      <td>交流电产生的</td>
      <td>100hz或120hz</td>
      <td>$|\cos x|$</td>
      <td>调整拍摄频率和交流电保持一致<br />调整快门时间, 让快门覆盖整数个周期</td>
    </tr>
    <tr>
      <td>LED屏幕</td>
      <td>PWM调光</td>
      <td>都有</td>
      <td>rectangular pulse<br />由占空比决定</td>
      <td>除了增加快门时间, 让条纹不明显<br />目前没有什么好的解决方式</td>
    </tr>
  </tbody>
</table>

<h2 id="我手里的电子设备观测">我手里的电子设备观测</h2>

<p>按照模型, 影响拍到的pattern的有: 相机的频率$f$, 快门时间(&lt;$\frac{1}{f}$), 相位, pwm的频率, 占空比, 每行的相位.</p>

<p>我们用相机去拍屏幕的时候,拍到的理论上亮, 暗的部分都是由于相位的不同, 不会相差超过一个周期, 所以$\frac{最亮}{最暗}&lt;\frac{ceil(\frac{快门时间}{pwm周期})}{floor(\frac{快门时间}{pwm周期})}$</p>

<p><strong>条件:</strong> 用我的iphone11拍摄, 240fps的慢镜头, 快门时间不知道, 但是大概有1/500s左右?</p>

<p><strong>iphone12手机:</strong></p>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240122233401.png" alt="Pasted image 20240122233401.png" width="100" />  另一个方向: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240122233636.png" alt="Pasted image 20240122233636.png" width="200" /></p>

<ol>
  <li>在同一帧内, 在一个方向是横条纹, 把镜头换了一个方向却出现了斜向的条纹:
    <ul>
      <li>合理的解释是可能屏幕上不同行的led灯相位不同. 考虑到相机每行是同时曝光的, 相机和屏幕垂直拍摄就会出现在一行拍到了多个相位的情况, 也就是斜向的条纹</li>
    </ul>
  </li>
  <li>出现黑色和白色: 看起来亮度就只有两档, 白色比例远高于黑色
    <ul>
      <li>从黑色的清晰度来看, pwm的周期可能比快门时间要长…</li>
      <li>在最暗的情况下, 可能低位完全覆盖快门时间, 所以看到的黑色是纯黑的, 而白色是在高位时间积分得到的
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240123112400.png" alt="Pasted image 20240123112400.png" width="200" /></li>
        </ul>
      </li>
      <li>在网上看到的<a href="#其他手机的效果">另一个手机测试视频里</a>, 黑白的比例能看出变化</li>
    </ul>
  </li>
  <li>出现一紫三白的规律:
    <ul>
      <li>绿色灯的规律好像没法用我们的模型解释. 似乎出现了两个周期?</li>
    </ul>
  </li>
  <li>随着调亮屏幕: pattern的样子没有变, 但是渐渐不那么黑白分明了, 暗条纹变宽, 屏幕的整体亮度也有所提高:
    <ul>
      <li>pwm低位的时间在减少</li>
      <li>当高位完全覆盖快门时间, 其亮度比例大约为 $\frac{暗}{亮}\approx \frac{快门时间\% pwm周期-低位时间}{快门时间\% pwm周期}$</li>
    </ul>
  </li>
  <li>在视频中, 条纹随时间变化:
    <ul>
      <li>有评论说iphone12的屏幕频率是240, 从实验结果来说, 和240fps的镜头并不匹配, 说明频率不是240. 从条纹的清晰度推测频率在几百量级</li>
    </ul>
  </li>
</ol>

<p><strong>MacbookPro:</strong></p>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240122233738.png" alt="Pasted image 20240122233738.png" width="150" /></p>
<ul>
  <li>网上有说法是mac的pwm频率为11800, 那么, 亮-暗/亮 对比不会超过 $\approx 500/11800\approx 1/23$ , 从图像的亮暗清晰度来看, 也不能算是和我拍摄的图像矛盾吧.  另外, 改用60fps的视频模式去拍, 这个图案也是可见的. 这个数字是否可信不好判断呢…但是能肯定频率至少是上千的</li>
</ul>

<h2 id="strobe-light-control"><a href="https://www.urvision-tw.com/article_detail/17/4.htm">Strobe Light Control</a></h2>

<p>闪频控制提供了一个和相机曝光同时控制的光源, 可以解决高速摄影(即频率高, 快门时间短) 的频闪问题. 
奇怪的是, 有些手机CIS产品(<a href="https://www.gcoreinc.com/products/index?cid=2&amp;subcid=5">比如格科微的GC02M1B</a>), 一般工作频率是30fps, 也提供一个闪频控制的灯光, 想不通应用场景是什么.</p>

<h2 id="频闪的检测">频闪的检测</h2>

<p>在淘宝上看到的几种频闪检测仪器</p>

<p><img src="/personal_homepage/docs/attachment/IMG_8267.jpg" alt="IMG_8267.jpg" width="100" /> <img src="/personal_homepage/docs/attachment/IMG_8268.jpg" alt="IMG_8268.jpg" width="100" /> <img src="/personal_homepage/docs/attachment/IMG_8265.jpg" alt="IMG_8265.jpg" width="100" /> <img src="/personal_homepage/docs/attachment/IMG_8266.jpg" alt="IMG_8266.jpg" width="100" /></p>

<h2 id="频闪对人眼的风险">频闪对人眼的风险</h2>

<table>
  <thead>
    <tr>
      <th>参数</th>
      <th>公式</th>
      <th>含义</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>频闪百分比(波动深度, percent filcker, FPF)</td>
      <td>$\frac{A\text{(最大值)}-B\text{(最小值)}}{A+B}\cdot$ 100%</td>
      <td>表示波动的剧烈程度</td>
    </tr>
    <tr>
      <td>频闪指数(Filcker index)</td>
      <td>$\frac{A_1\text{(平均值上面积)}}{A_1+A_2\text{(平均值下面积)}}$</td>
      <td>表示频闪的不稳定程度?<br />pwm调光时降低占空比,<br /> 平均值降低, <br />频闪指数会变高</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><strong>几种频闪的标准</strong>
    <ul>
      <li>IEEE std 1789-2015
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240122105434.png" alt="Pasted image 20240122105434.png" width="300" /></li>
        </ul>
      </li>
      <li>GB/T31831《LED室内照明技术应用要求》</li>
      <li><a href="http://222.66.64.153:8080/sdzg_admin/upload/myupload_3674.pdf">CQC1601 2016《视觉作业台灯认证技术规范》</a>: 和IEEE std 1789-2015规定相似</li>
    </ul>
  </li>
  <li><strong>理解</strong>
    <ul>
      <li>规定里只提及了频闪百分比, 没有提及频闪指数. PWM调光的频闪百分比理论上应该都是100%? 感觉这个标准考虑的只有灯光, 根本没有考虑oled屏幕</li>
      <li>规定里认为只要是&gt;3125hz的高频, 怎么样的波形都无风险</li>
    </ul>
  </li>
</ul>

<h2 id="reference">reference</h2>
<p><span id="ref"></span></p>

<p>[1] https://www.hangjianet.com/topic/15627339606370002 标准</p>

<p>[2] https://post.smzdm.com/p/ag8lgep6/ 手机测评</p>

<p>[3] https://zhuanlan.zhihu.com/p/30939047 用测量仪测试 手机上不同行的led可能相位并不同, 所以这种直接对着屏幕的测量方式应该是有问题的..</p>

<p>[4] https://discussions.apple.com/thread/254350073?sortBy=best 评论了iphone和mac的频率</p>

<p>[5] https://spectrum.ieee.org/the-iphone-12-mini-makes-me-sick-literally 评论说制造商可能让pwm频率约等于屏幕刷新率的4倍</p>

<p>[6] https://www.hangjianet.com/topic/14734042955300000 一些从硬件上处理灯光频闪的方案</p>
<h2 id="其他手机的效果">其他手机的效果</h2>

<p><a href="https://zhuanlan.zhihu.com/p/41421658">这个知乎帖子看到的</a> 明显占空比变化</p>

<p><img src="https://vdn3.vzuu.com/SD/c53acdce-1ea2-11ec-b4fa-421c7066376d.mp4?disable_local_cache=1&amp;bu=078babd7&amp;c=avc.0.0&amp;f=mp4&amp;expiration=1705987673&amp;auth_key=1705987673-0-0-9aff69184a2eabc38cabc1cd7a5321d6&amp;v=tx&amp;pu=078babd7" alt="其他手机测试" /></p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="content" /><category term="jekyll" /><summary type="html"><![CDATA[频闪就是亮度随时间周期性变化的情况.]]></summary></entry><entry><title type="html">传感器颜色调制 (三) – 数据</title><link href="https://roshameow.github.io//personal_homepage/docs/data/color-moderate2/" rel="alternate" type="text/html" title="传感器颜色调制 (三) – 数据" /><published>2024-01-15T00:00:00+00:00</published><updated>2024-01-21T00:32:13+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/data/color-moderate2</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/data/color-moderate2/"><![CDATA[<p>各种颜色调制的数据对难以采集, 所以现在大部分颜色调制还是用多光谱数据仿真得到.</p>
<h2 id="多光谱数据集">多光谱数据集</h2>

<table>
  <thead>
    <tr>
      <th>数据集$\downarrow$</th>
      <th>size</th>
      <th>bands</th>
      <th>格式</th>
      <th>数量</th>
      <th>拍摄场景</th>
      <th>发布时间</th>
      <th>大小</th>
      <th>条件</th>
      <th>拍摄条件</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://www1.cs.columbia.edu/CAVE/databases/multispectral/">CAVE</a></td>
      <td>512x512</td>
      <td>400-700nm<br />10nm steps<br />31bands</td>
      <td>.png<br />每个通道<br />分别存</td>
      <td>32</td>
      <td>实验室:<br />真假人脸<br />真假水果</td>
      <td>2008</td>
      <td>419.9MB</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://cave.cs.columbia.edu/projects/categories/project?cid=Computational+Imaging&amp;pid=Multispectral+Imaging+Using+Multiplexed+Illumination">CAVE1024</a></td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td>13.06GB</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="http://vclab.kaist.ac.kr/siggraphasia2017p1/kaistdataset.html">KAIST</a></td>
      <td>2704x3376</td>
      <td>420-720nm<br />10nm steps<br />31bands</td>
      <td>.exr<br />每个图片<br />单独下载</td>
      <td>30</td>
      <td>实验室</td>
      <td>2017</td>
      <td>8.67GB</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/mengziyi64/TSA-Net">TSA</a></td>
      <td>660x660</td>
      <td>28通道<br />特殊</td>
      <td>.mat</td>
      <td>10(simu)<br />5(real)</td>
      <td>实验室</td>
      <td>2020</td>
      <td> </td>
      <td>simu是从<br />KAIST的数据<br />中截取的</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://vision.seas.harvard.edu/hyperspec/download.html">harvard</a></td>
      <td>1040x1392</td>
      <td>420-720nm<br />10nm steps<br />31bands</td>
      <td>.mat</td>
      <td>50(自然光)<br />27(人工光)</td>
      <td>场景丰富</td>
      <td>2011</td>
      <td>约7GB</td>
      <td>research-only</td>
      <td>商业相机:<br />Nuance FX, CRI Inc<br />liquid crystal tunable filter</td>
    </tr>
    <tr>
      <td><a href="https://github.com/boazarad/ARAD_1K">ARAD 1K</a></td>
      <td> </td>
      <td>400-700nm<br />10nm steps<br />31bands</td>
      <td> </td>
      <td> </td>
      <td>场景丰富</td>
      <td>2022</td>
      <td> </td>
      <td>需要注册</td>
      <td> </td>
    </tr>
    <tr>
      <td>TokyoTech<br /><a href="http://www.ok.sc.e.titech.ac.jp/res/MSI/MSIdata31.html">31-band</a></td>
      <td>不固定<br />500~2k<br />左右</td>
      <td>420-720nm<br />10nm steps<br />31bands</td>
      <td>.mat</td>
      <td>30</td>
      <td>色卡(齐全)<br />布料,<br />蝴蝶<br />局部特写</td>
      <td>2015</td>
      <td>2.97GB</td>
      <td>research-only<br />redistribute-<br />prevent</td>
      <td> </td>
    </tr>
    <tr>
      <td>TokyoTech<br /><a href="http://www.ok.sc.e.titech.ac.jp/res/MSI/MSIdata59.html">59-band</a></td>
      <td>512x512</td>
      <td>420-1000nm<br />10nm steps<br />59bands</td>
      <td>.mat-v7.3</td>
      <td>16</td>
      <td>类似<br /></td>
      <td>2019</td>
      <td>1.7GB</td>
      <td>research-only<br />redistribute-<br />prevent</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="http://www2.cmp.uea.ac.uk/Research/compvis/MultiSpectralDB.htm">CMP_UEA</a></td>
      <td>不固定<br />200~400<br />左右</td>
      <td>400-700nm<br />10nm steps<br />31bands</td>
      <td>.mat<br />每个图片<br />单独下载</td>
      <td>23</td>
      <td>色卡,<br />广告包装</td>
      <td>2004</td>
      <td>566.6MB</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="格式读取和注意事项">格式读取和注意事项</h2>

<ol>
  <li><strong>从网页抓数据</strong>
    <ul>
      <li>因为数据是分散在网页上的, 需要用python从网页上抓.exr图片
        <ul>
          <li>问题: 用<code class="language-plaintext highlighter-rouge">requests.get(absolute_url).content</code> , 这么下载下来的文件可能会有不全
            <ul>
              <li>我批量下载kaist数据时, 就有一张图片错误, 还好.exr可以预览, 发现不正常的图片再单独下载下来就好</li>
              <li>在批量下载CMP_UEA网页上的.mat文件时, 也出错了, 但是.mat文件没法预览, 等到读数据才发现</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>读.exr数据</strong>
    <ul>
      <li>网上的<a href="https://github.com/jamesbowman/openexrpython.git">读exr的python包</a>都有些问题, 而尴尬的是OpenEXR的官方放出了要做官方python binding的消息, 截止目前还没发布. 需要我们自己按如下流程操作: 写调用OpenEXR的C++代码-&gt;用pybind11编成.so库-&gt;在python里面调用
        <ul>
          <li>参考<a href="https://openexr.com/en/latest/API.html#the-openexr-api">OpenEXR的API文档</a> : 一定要把所有channel都在datawindow 里面排好一次性读</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>读.mat数据</strong>
    <ul>
      <li>.mat数据有两种: 老版的.mat和新的v7.3格式的.mat, 不实际读的话, 没法知道究竟是哪种. 我还没找到可以先提取.mat的metadata的方法</li>
      <li>老版的.mat可以用<code class="language-plaintext highlighter-rouge">scipy.io.loadmat</code> 读</li>
      <li>v7.3其实就是H5DF格式, 和.h5文件一样, 可以用<code class="language-plaintext highlighter-rouge">h5py</code> 读. 看到一些地方是建议用 <a href="https://pypi.python.org/pypi/hdf5storage">hdf5storage</a> 这个包(不光可以读, 还可以存成v7.3格式).</li>
      <li>.mat数据好像没法看数据类型..</li>
    </ul>
  </li>
  <li><strong>怎么正确的在pytorch里加载</strong>
    <ul>
      <li>目前是存在dataset的一个list里面
        <ul>
          <li>一定不能把所有image存在一个大的<code class="language-plaintext highlighter-rouge">ndarray</code>里面, 我们的数据都比较大, 很有可能会内存不够</li>
          <li>存在list里面是不受内存的限制吗?在训练过程中可以及时的动态加载吗? 还没有研究</li>
          <li>我们的图片大, 而训练需要的crop_size比较小, 一个想法是先把图片切分成多个小的patch, 这样是否就不用加载一整张图片了?</li>
        </ul>
      </li>
      <li>在第一次读数据时存成.h5文件的cache, 之后从.h5文件读取
        <ul>
          <li>因为数据集中的波长和我们要的channel可能不一样, 我们的channel是用<code class="language-plaintext highlighter-rouge">interp1d</code> 插值得到的, 这个插值的过程比较浪费时间, 所以至少需要把插值后的结果存下来</li>
          <li>.h5文件读出来是<code class="language-plaintext highlighter-rouge">ndarray</code> 格式, 要转成tensor使用, 不过这个过程是很快的</li>
          <li><strong>为什么不存成.pkl</strong>
            <ul>
              <li>.pkl读起来比.h5慢, 在我的mac M1上速度慢了一倍.  .pkl 倒是可以直接存tensor的, 而且存数据更快.</li>
              <li><a href="https://docs.python.org/3/library/pickle.html">.pkl</a>可以做的操作比较多, 如果在网上把.pkl发给别人, 对方可能不敢打开.. 所以一般不会用.pkl分发大文件</li>
              <li>.pkl适合自己开发时存一些中间结果</li>
            </ul>
          </li>
          <li>为什么不是一张图片一个文件而是把全部list存在一起? 没有测试, 可能速度是差不多的吧?</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="其他有用的资源">其他有用的资源</h2>

<ul>
  <li><a href="https://github.com/caiyuanhao1998/BiSCI">BiSCI的repo</a> 里提供了CAVE512, CAVE1024, KAIST, TSA的下载链接, 是已经转成28通道的, .mat格式
    <ul>
      <li>其中kaist的数据load超慢.. 可能是因为把原本的16bit的half长度存成了64bit的complex?</li>
      <li>我想kaist里面存half格式的exr可能也是出于缩小空间的考虑.. OpenEXR本身读起来挺快的</li>
    </ul>
  </li>
  <li><a href="https://github.com/colour-science/colour">color-science</a> : 里面包含各种光学方面的标准, 对各种色彩空间转换, 可视化很有用</li>
</ul>

<h2 id="代码">代码</h2>

<ul>
  <li>exr: <a href="https://gist.github.com/roshameow/c2710dedf5ab067517d622b2a7ed4679#file-readexr-cpp"><strong>readexr.cpp</strong></a></li>
  <li>网页抓图片: <a href="https://gist.github.com/roshameow/30aae94815c6b8ddb2253191d4f86649#file-download_kaist-py"><strong>download_kaist.py</strong></a></li>
  <li>读数据集: <a href="https://gist.github.com/roshameow/30aae94815c6b8ddb2253191d4f86649#file-multisepc_load-py"><strong>multisepc_load.py</strong></a></li>
  <li>多光谱图片转成RGB显示: <a href="https://gist.github.com/roshameow/30aae94815c6b8ddb2253191d4f86649#file-multispec2rgb-py"><strong>multispec2rgb.py</strong></a>
    <ul>
      <li>用TSA的图片测试, 转出的RGB有偏色, 可能是因为只对应了channel的主波长的XYZ, 没有在光谱上积分吗?</li>
    </ul>
  </li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="data" /><category term="content" /><category term="dataset" /><category term="pytorch" /><category term="script" /><summary type="html"><![CDATA[各种颜色调制的数据对难以采集, 所以现在大部分颜色调制还是用多光谱数据仿真得到. 多光谱数据集]]></summary></entry><entry><title type="html">aperture衍射模型 (二)</title><link href="https://roshameow.github.io//personal_homepage/docs/simulation/diffraction1/" rel="alternate" type="text/html" title="aperture衍射模型 (二)" /><published>2024-01-11T00:00:00+00:00</published><updated>2024-01-15T01:10:47+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/simulation/diffraction1</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/simulation/diffraction1/"><![CDATA[<h2 id="仿真">仿真</h2>

<p><img src="/personal_homepage/docs/attachment/circle_diffraction.mp4" alt="circle_diffraction.mp4" width="200" /> <img src="/personal_homepage/docs/attachment/square_diffraction.mp4" alt="square_diffraction.mp4" width="200" /></p>
<ol>
  <li>在aperture区域均匀采样，发现Frensel pattern是很难出现的，在每个像素对应sample数不足1000的时候，基本观测不到。。应该是因为在那个范围内结果受$(x^\prime,y^\prime)$ 的位置影响更大, 也就表现出更大的随机性。</li>
  <li>确实可以看到sensor到aperture距离增大后, pattern变化的全过程。</li>
  <li>在一个网上找的<a href="https://www.falstad.com/diffraction/">Frensel diffraction仿真</a> java代码里面，作者也是通过先把部分积分形式通过公式运算先化简之后做的仿真<a href="#ref">1</a>，没有用原始的传播公式。</li>
  <li>如果用全光谱的光源，Fraunhofer衍射中因为波长影响, 看起来的效果像是从中间不同颜色的光被diffuse了，我看一些3d建模制作里说的衍射，一般是指这种效果，可以看<a href="https://www.bilibili.com/video/BV1C5411E78d/">b站上一个用blender仿这种效果的视频</a>
    <ul>
      <li>另外判断天然珍珠和人造珍珠的区别的一种方法，也是看天然珍珠里面有微小的结构可以把不同波长的光区分出来的效果</li>
      <li>blender的cycles用的是粒子模型, 没有相位变化，可能没法直接得到衍射</li>
    </ul>
  </li>
</ol>

<h2 id="应用">应用</h2>

<ol>
  <li><strong>在相机系统中，我们关心成像的分辨率</strong>：用Fraunhofer的模型估算相机的resolution
    <ul>
      <li>相机aperture参数：这两个都是dimensionless版本的aperture
        <ul>
          <li><a href="https://en.wikipedia.org/wiki/F-number">f-number</a>: $N=\frac{f}{D}=\frac{f}{2a}$
            <ul>
              <li>相机焦距$f=z$, 光圈直径$D=2a$</li>
            </ul>
          </li>
          <li><a href="https://en.wikipedia.org/wiki/Numerical_aperture">numerical aperture</a> $NA=\frac{a}{\sqrt{f^2+a^2}}=\frac{1}{\sqrt{4N^2+1}}\approx \frac{1}{2N}$</li>
        </ul>
      </li>
      <li>第一圈黑环处距中心距离，认为是相机的optical resolution:
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240112160824.png" alt="Pasted image 20240112160824.png" width="300" /></li>
          <li>此时是$J_1(x)$ 的第一个0点， $J_1(ka\sin\theta)=0$，$ka\sin\theta\approx 3.83$ ，即$\sin\theta\approx \frac{3.83}{ka}=\frac{3.83\lambda}{2\pi a}=1.22\frac{\lambda}{D}$</li>
          <li>得到optical resolution $q=r_1\sin\theta\approx \sqrt{f^2+a^2}\sin\theta=\frac{a}{NA}\sin\theta\approx \frac{a}{NA}\frac{1.22\lambda}{2a}=\frac{0.61\lambda}{NA}$</li>
          <li>理论上，numberical aperture越大，optical resolution越小，分辨率越高(也就是衍射更不明显)</li>
        </ul>
      </li>
      <li>相机的成像清晰度指标：MTF
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240112154649.png" alt="Pasted image 20240112154649.png" width="400" /></li>
          <li><a href="https://en.wikipedia.org/wiki/Point_spread_function">PSF</a>(intensity function): $PSF=|G(p,q)|^2=|F(g(x^\prime,y^\prime))|^2$
            <ul>
              <li>PSF的单位是 (distance(mm),intesity)</li>
              <li>对于圆形aperture：$PSF=\frac{J_1^2(ka\sin\theta)}{(ka\sin\theta)^2}$ , PSF的零点也就是$J_1$ 的零点</li>
              <li>生成图像的image: $I=PSF*\text{scene}$ 是场景和PSF的卷积</li>
            </ul>
          </li>
          <li><a href="https://en.wikipedia.org/wiki/Optical_transfer_function">MTF</a>: $MTF=F(PSF)$
            <ul>
              <li>MTF的单位是（frequency(lines/mm),response(%)）</li>
              <li>$\frac{J_1^2(x)}{x^2}$ 的Fourier变化是个连续下降函数</li>
              <li>根据 <a href="https://en.wikipedia.org/wiki/Fourier_transform#Applications">Fourier transform</a> time scaling的性质：因为PSF的零点$PSF_0\propto \frac{\lambda}{NA}$ , 得到MTF的cutoff点 $c(MTF)\propto \frac{NA}{\lambda}$  (即频率更高的物体就看不清了)</li>
              <li>MTF是个衡量成像系统分辨率的常用指标，不光衍射，所有成像过程，包括软件做的deblur等操作都可以用这个指标衡量。</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>用PSF做图像调制</strong> 
    <ul>
      <li>从PSF的表达式可以看出, PSF受距离, 波长(光的颜色), 位置影响, 可以在相机系统中主动利用这些信息</li>
    </ul>
  </li>
</ol>

<h2 id="代码">代码</h2>

<p><a href="https://gist.github.com/roshameow/7d44196b703ade645b34b164d779cdfe#file-diffraction_simulation-py"><strong>diffraction_simulation.py</strong></a></p>

<p><a href="https://gist.github.com/roshameow/7d44196b703ade645b34b164d779cdfe#file-pst_bessel-py"><strong>pst_bessel.py</strong></a></p>

<h2 id="其他讨论这个的链接">其他讨论这个的链接：</h2>
<p><span id="ref"></span>
仿真</p>

<p>[5] http://www.dauger.com/fresnel/</p>

<p>[6] Dauger, Dean E. “Simulation and Study of Fresnel Diffraction for Arbitrary Two-Dimensional Apertures.” <em>Computers in Physics</em> 10 (November 1, 1996): 591–604. <a href="https://doi.org/10.1063/1.168584">https://doi.org/10.1063/1.168584</a>.</p>

<p>相机resolution</p>

<p>[7] https://www.microscopyu.com/tutorials/imageformation-airyna (包含一个<a href="https://en.wikipedia.org/wiki/Airy_disk">Airy disk</a> 影响清晰度的演示)</p>

<p>[8] https://www.iasj.net/iasj/download/8ab5ecbce0ead154</p>

<p>[9] https://micro.magnet.fsu.edu/primer/java/mtf/airydisksize/index.html</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="simulation" /><category term="content" /><category term="simulation" /><category term="sensor" /><category term="physics" /><summary type="html"><![CDATA[仿真]]></summary></entry><entry><title type="html">aperture衍射模型 (一)</title><link href="https://roshameow.github.io//personal_homepage/docs/simulation/diffraction/" rel="alternate" type="text/html" title="aperture衍射模型 (一)" /><published>2024-01-03T00:00:00+00:00</published><updated>2024-01-12T17:22:46+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/simulation/diffraction</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/simulation/diffraction/"><![CDATA[<h2 id="光的传播理论">光的传播理论</h2>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/4/48/Diffraction_geometry_2.svg" alt="image" /></p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Huygens–Fresnel_principle">Huygens–Fresnel principle理论</a>：
    <ul>
      <li>假设光源在$(x^\prime,y^\prime,0)$ , 方向是$z$ 方向，能量是$E$</li>
      <li>传播到$(x,y,z)$ 的electric field是$E(x,y,z)=\frac{1}{i\lambda}\cdot E \cdot\frac{e^{ikr}}{r}\cdot \frac{z}{r}$
        <ul>
          <li>$r$ 是$(x,y,z)$ 到光源的距离</li>
          <li>$\lambda$ 是波长</li>
          <li>$k$ 是wavenumber: $\frac{2\pi}{\lambda}$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<!--more-->
<h2 id="diffraction">diffraction</h2>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/b/b8/Wavelength%3Dslitwidth.gif" alt="image1" /></p>

<p>考虑由光圈所在平面到sensor这一段, 假设$z$ 固定为aperture和sensor的距离，光源为从aperture向sensor方向的平行光</p>

<p>从aperture $A$ 透过的能量是 $E(x,y,z)= \int\int_A \frac{z}{i\lambda r^2} E(x^\prime,y^\prime,0)\cdot e^{ikr}\cdot dx^\prime dy^\prime$  ，形成的pattern主要<strong>受$e^{ikr}$ 这个高频项的影响</strong>,主要能观测到的pattern可以用下面两类衍射模型近似</p>

<!--more-->
<h3 id="fresnel-diffraction菲涅耳衍射">Fresnel diffraction(<a href="https://en.wikipedia.org/wiki/Fresnel_diffraction">菲涅耳衍射</a>)</h3>

<ul>
  <li><strong>假设</strong> : $r\approx z+\frac{(x-x^\prime)^2+(y-y^\prime)^2}{2z}$
    <ul>
      <li>$r=\sqrt{z^2+\rho^2}=z\sqrt{1+\frac{\rho^2}{z^2}}$ , 其中$\rho^2=(x-x^\prime)^2+(y-y^\prime)^2$
        <ul>
          <li>展开为 $r=z(1+\frac{\rho^2}{2z^2}-\frac{1}{8}(\frac{\rho^2}{z^2})^2+\cdots)\approx z+\frac{\rho^2}{2z}$</li>
          <li>近似条件为$z\frac{1}{8}(\frac{\rho^2}{z^2})^2=o(2\pi/k)$ , 即$\frac{\rho^4}{z^3\lambda}=o(1)$, 因为我们主要关注的是$e^{ikr}$ 这个高频项的周期</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>化简成Fourier变换的格式</strong>：
    <ul>
      <li>$\begin{align}E(x,y,z)&amp;=\frac{e^{ikz}}{i\lambda z} \int\int_A E(x^\prime,y^\prime,0)\cdot e^{\frac{ik}{2z}((x-x^\prime)^2+(y-y^\prime)^2)} dx^\prime dy^\prime \\ &amp;=\frac{e^{ikz}}{i\lambda z} \int\int_A E(x^\prime,y^\prime,0)\cdot e^{\frac{i\pi}{\lambda z}(x^2+y^2+{x^\prime}^2+{y^\prime}^2-2xx^\prime-2yy^\prime)} dx^\prime dy^\prime\ (k\text{还原成 }\frac{2\pi}{\lambda}) \\ &amp; =\frac{e^{ikz}}{i\lambda z}e^{\frac{i\pi}{\lambda z}(x^2+y^2)} \int\int_A E(x^\prime,y^\prime,0)e^{\frac{i\pi}{\lambda z}({x^\prime}^2+{y^\prime}^2)}\cdot e^{\frac{i\pi}{\lambda z}(-2xx^\prime-2yy^\prime)} dx^\prime dy^\prime \\ &amp;=\frac{e^{ikz}}{i\lambda z}e^{\frac{i\pi}{\lambda z}(x^2+y^2)} \int\int \mathbb 1_A(x^\prime,y^\prime)\cdot E(x^\prime,y^\prime,0)e^{\frac{i\pi}{\lambda z}({x^\prime}^2+{y^\prime}^2)}\cdot e^{\frac{i\pi}{\lambda}(px^\prime+py^\prime)} dx^\prime dy^\prime\ (\text{ 带入 }p=\frac{x}{\lambda z}, q=\frac{y}{\lambda z})\end{align}$</li>
      <li>记 impulse response: $h(x,y,z)= \frac{e^{ikz}}{i\lambda z}\cdot e^{\frac{ik}{2z}(x^2+y^2)}$</li>
      <li>记aperture function: $g(x^\prime,y^\prime)=\mathbb 1_A(x^\prime,y^\prime)\cdot E(x^\prime,y^\prime,0)e^{\frac{i\pi}{\lambda z}({x^\prime}^2+{y^\prime}^2)}$</li>
      <li><a href="https://en.wikipedia.org/wiki/Fourier_transform#Applications">Fourier transform</a> : $G(p,q)=F(g(x^\prime,y^\prime))$</li>
      <li>得到$E(x,y,z)=h(x,y,z)\cdot G(p,q)$ 的形式</li>
    </ul>
  </li>
</ul>

<h3 id="fraunhofer-diffraction夫琅禾费衍射">Fraunhofer diffraction(<a href="https://en.wikipedia.org/wiki/Fraunhofer_diffraction">夫琅禾费衍射</a>)</h3>

<ul>
  <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240110160604.png" alt="Pasted image 20240110160604.png" width="500" /></li>
  <li><strong>假设1</strong>：$r\approx r_1-b\cdot\cos(\phi-\Phi)\cdot\sin\theta$  (有如图几何直观，对于圆形aperture有个简便的表达方法)
    <ul>
      <li>近似条件：图中红线 $\approx$ 图中绿线部分
        <ul>
          <li>$r_1$ 是aperture中心到观测点$(x,y)$ 的距离</li>
          <li>光源点$(x^\prime,y^\prime)$ 到中心距离为$b$ ,角度为$\phi$, 观测点$(x,y)$ 的角度为$\Phi$, $b$ 往$(x,y)$ 所在角度投影为$b\cos(\phi-\Phi)$ , 图中蓝色三角形的短边</li>
          <li>对图中蓝色三角形$(b\cos(\phi-\Phi),\pi/2-\theta,r_1)$  用<a href="https://en.wikipedia.org/wiki/Law_of_cosines">余弦公式</a> 得到图上蓝色$r_2$ 的距离：$r_2=\sqrt{r_1^2+b^2\cos^2(\phi-\Phi)-2br_1(\cos(\pi/2-\theta)\cos(\phi-\Phi))}$</li>
          <li>则 $r=\sqrt{r_2^2+b^2\sin^2(\phi-\Phi)}=\sqrt{r_1^2+b^2-2br_1\sin(\theta)\cos(\phi-\Phi)}$</li>
          <li>展开为：$r=r_1(1-\frac{b}{r_1}\sin(\theta)\cos(\phi-\Phi)+\frac{b^2}{2r_1^2}\cos^2(\theta)\cos^2(\phi-\Phi)+\cdots)$</li>
          <li>在$\frac{b^2}{2r_1}\cos^2(\theta)=o(2\pi/k)$ 条件下，即$\frac{b^2}{\lambda r_1}\cos^2\theta=o(1)$ 的情况下，得到我们的假设</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>假设2</strong>: $r\approx z+\frac{x^2+y^2-2xx^\prime-2yy^\prime}{2z}$ (和Fresnel的形式更统一，也方便写成Fourier变换的形式)
    <ul>
      <li>近似条件：
        <ul>
          <li>和Frensel一样假设$\frac{\rho^4}{z^3\lambda}=o(1)$ ，另外，假设$\frac{b^2}{z\lambda}=o(1)$</li>
        </ul>
      </li>
      <li>和假设1的关系：其实把假设1形式变换一下就能得到相似的形式
        <ul>
          <li>$r\approx r_1-b\cdot(\cos\phi\cos\Phi+\sin\phi\sin\Phi)\cdot\sin\theta$</li>
          <li>带入： $\cos\phi=\frac{x^\prime}{b},\sin\phi=\frac{y^\prime}{b},\cos\Phi=\frac{x}{\sqrt{x^2+y^2}},\sin\Phi=\frac{y}{\sqrt{x^2+y^2}},\sin\theta=\frac{\sqrt{x^2+y^2}}{r_1}$</li>
          <li>得到$r\approx r_1-\frac{xx^\prime+yy^\prime}{r_1}=\sqrt{z^2+x^2+y^2}-\frac{xx^\prime+yy^\prime}{r_1}\approx z+\frac{x^2+y^2}{2z}-\frac{xx^\prime+yy^\prime}{z}$ (不过这样需要进一步的假设。。)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>化简成Fourier变换的格式</strong>：
    <ul>
      <li>根据假设2，其他部分都和Fresnel相同, 只有$g(x^\prime,y^\prime)=\mathbb 1_A(x^\prime,y^\prime)\cdot E(x^\prime,y^\prime,0)$ 更简单了</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>[!example]</p>

  <ul>
    <li><strong>圆形aperture</strong>, 并假设光源在aperture均匀分布，即$E(x^\prime,y^\prime,0)=const$ :
      <ul>
        <li>把$(x^\prime,y^\prime)$ 转为$(b,\phi)$ 极坐标，$\int\int_A …dx^\prime dy^\prime=\int_0^a\int_0^{2\pi}… bdbd\phi$</li>
        <li>根据假设1，参考<a href="https://en.wikipedia.org/wiki/Bessel_function">Bessel公式</a></li>
        <li>$\begin{align}E(x,y,z)&amp;=\frac{e^{ikr_1}}{i\lambda r_1} \int_{b=0}^a\int_{\phi=0}^{2\pi}  e^{-ikb\cdot\cos(\phi-\Phi)\cdot\sin\theta}b db d\phi\text{ (根据假设1)}\\ &amp; =\frac{e^{ikr_1}}{i\lambda r_1} \int_{b=0}^a\int_{\phi=0}^{2\pi}  e^{-ikb\cdot\cos\phi\cdot\sin\theta}b db d\phi\text{ (关于}\Phi\text{对称,可以假设=0)}\\ &amp; =\frac{e^{ikr_1}2\pi}{i\lambda r_1} \int_{b=0}^a J_0(kb\sin\theta)b db \text{ (根据Bessel公式) }\\ &amp; =e^{ikr_1}\frac{k}{i r_1} \frac{J_1(ka\sin\theta)}{ka\sin\theta}\end{align}$</li>
        <li>另外，根据假设2，也能得到circ函数的Fourier变换是$J_1$</li>
      </ul>
    </li>
    <li><strong>方形aperture</strong>, 并假设光源在aperture均匀分布：
      <ul>
        <li>x,y可以拆开成两个rectangular pulse, 其Fourier变换是sinc函数</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="两种diffraction的区别--">两种diffraction的区别  　</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Frensel</th>
      <th>Fraunhofer</th>
      <th>diffraction不明显</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>apeture function/<a href="https://en.wikipedia.org/wiki/Pupil_function">pupil function</a></td>
      <td>$g(x^\prime,y^\prime)=\mathbb 1_A(x^\prime,y^\prime)\cdot E(x^\prime,y^\prime,0)e^{\frac{i\pi}{\lambda z}({x^\prime}^2+{y^\prime}^2)}$ <br />和aperture到observer的距离$z$ 有关；<br />改变距离，或把aperture平移，<br />都会使pattern看起来剧烈变化</td>
      <td>$g(x^\prime,y^\prime)=\mathbb 1_A(x^\prime,y^\prime)\cdot E(x^\prime,y^\prime,0)$<br />和距离$z$ 无关; <br />结果只和观察角度$p=\frac{x}{\lambda z}, q=\frac{y}{\lambda z}$ 有关;<br />只改变$z$的情况，<br />形成的pattern看起来形状相似</td>
      <td> </td>
    </tr>
    <tr>
      <td>形成条件假设</td>
      <td>$\frac{\rho^4}{z^3\lambda}=o(1),\frac{\rho^2}{z\lambda}=O(1)$ <br />当距离$z$ 再增加的时候，<br />相对aperture更大，<br />会趋近Fraunhofer的假设2 <br /><br />带入$N_f$, <br />有时写成$N_f (a/z)^2\ll 1, N_f\sim 1$</td>
      <td>假设1: $\frac{b^2}{\lambda r_1}\cos^2\theta=o(1)$ <br />假设2: $\frac{\rho^4}{z^3\lambda}=o(1)$ ，$\frac{b^2}{z\lambda}=o(1)$</td>
      <td> </td>
    </tr>
    <tr>
      <td>Fresnel number: <br />$N_F=\frac{a(\text{aperture radius})^2}{z \lambda}$<br />$N_F$ 是实际场景中,<br />diffraction种类的一个粗略的判断方法</td>
      <td>$N_F\sim 1$<br />一般叫”near field” diffraction</td>
      <td>$N_F\ll 1$<br />一般叫 far field diffraction</td>
      <td>$N_f\gg 1$</td>
    </tr>
    <tr>
      <td>pattern</td>
      <td><a href="https://en.wikipedia.org/wiki/Arago_spot">泊松光斑实验</a> <br />不过实验里用的不是aperture而是中心的遮挡</td>
      <td><a href="https://en.wikipedia.org/wiki/Airy_disk">Airy disk</a></td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="其他讨论这个的链接">其他讨论这个的链接：</h2>
<p><span id="ref"></span>
公式推导</p>

<p>[1] https://en.wikipedia.org/wiki/Fraunhofer_diffraction_equation#CITEREFHecht2002</p>

<p>[2] https://phys.libretexts.org/Bookshelves/Optics/BSc_Optics_(Konijnenberg_Adam_and_Urbach)/06%3A_Scalar_diffraction_optics/6.07%3A_Fresnel_and_Fraunhofer_Approximations</p>

<p>[3] http://www.erbion.com/index_files/Modern_Optics/Ch11.pdf</p>

<p>[4] https://zhuanlan.zhihu.com/p/339379109</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="simulation" /><category term="content" /><category term="simulation" /><category term="sensor" /><category term="physics" /><summary type="html"><![CDATA[光的传播理论]]></summary></entry><entry><title type="html">用六边形构成半球</title><link href="https://roshameow.github.io//personal_homepage/docs/geometry/hexigon-hemisphere/" rel="alternate" type="text/html" title="用六边形构成半球" /><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-14T01:51:32+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/geometry/hexigon-hemisphere</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/geometry/hexigon-hemisphere/"><![CDATA[<p>刷到关于《葬送的芙莉莲》里面六边形魔法防御结界的讨论，根据<a href="https://en.wikipedia.org/wiki/Euler_characteristic">多面体欧拉公式</a>，仅仅用正六边形是没法组成球体形状结界。我也非常理解制作组为什么不画个足球：毕竟是魔法阵，六边形画的又比较大，弄个五边形也不好看也不好解释。
<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102192929.png" alt="Pasted image 20240102192929.png" width="500" /></p>

<p>但是如果不是球，而是半球，不考虑边界是否完整，变形，肯定是可行的。因为半球$S^+$ 和disk $\mathbb{D}^1$， 和六边形边界的平面都是 <a href="https://en.wikipedia.org/wiki/Homeomorphism">topological isomorphism</a> 的，在平面上能实现的密铺，变形到半球上当然也能实现。</p>

<p>另外，为了保证在3维上看起来不难看。用<a href="https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/2D_Sampling_with_Multidimensional_Transformations#:~:text=The%20idea%20behind%20Malley%27s%20method,Figure%2013.14%3A%20Malley%27s%20Method.">Malley’s Method</a>, 把disk看成半球的投影，实行$(r,\phi)=(\sin\theta,\phi)\rightarrow (\theta,\phi)$ 的变换，让六边形在$(\theta,\phi)$ 的坐标上是均匀的。
<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102191540.png" alt="Pasted image 20240102191540.png" width="300" /></p>

<h2 id="画一个密铺六边形半球的步骤">画一个密铺六边形半球的步骤</h2>

<h3 id="用python画一个密铺的六边形">用python画一个密铺的六边形：</h3>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102191646.png" alt="Pasted image 20240102191646.png" width="200" /> , 画上辅助线：<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102191705.png" alt="Pasted image 20240102191705.png" width="200" /></p>

<h3 id="做变换">做变换</h3>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102191731.png" alt="Pasted image 20240102191731.png" width="200" /></p>

<ul>
  <li>这一步得到的是我们设想的半球面的投影, 看起来确实给人一种六边形能组成球形的错觉。。</li>
  <li>另外，Photoshop里面球面化的滤镜，看起来效果差不多，可能也是用了这个变换。
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102191855.png" alt="Pasted image 20240102191855.png" width="400" />  </li>
    </ul>
  </li>
  <li>又对比了一下原图，嗯？费伦的结界难道也是这么画的？</li>
</ul>

<h3 id="把得到的投影映射到半球">把得到的投影映射到半球</h3>

<p>转到侧面看下：<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102192405.png" alt="Pasted image 20240102192405.png" width="200" />  </p>

<p>看起来确实挺正常的，当然，这样的两个半球也合不成一个全是六边形的球，因为如图上边界的地方：<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240102195111.png" alt="Pasted image 20240102195111.png" width="200" /> 展开会变成5边形，7边形，8边形</p>

<h2 id="代码">代码</h2>

<p><a href="https://gist.github.com/roshameow/b9838c17a65f17f8f775585f24d34d64#file-hex-py"><strong>hex.py</strong></a></p>
<h2 id="其他讨论这个的链接">其他讨论这个的链接：</h2>

<p>[1] https://zhuanlan.zhihu.com/p/673051340</p>

<p>[2] https://www.163.com/dy/article/IMH50ITS0526FP3N.html</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="geometry" /><category term="content" /><category term="idea" /><category term="动漫" /><summary type="html"><![CDATA[刷到关于《葬送的芙莉莲》里面六边形魔法防御结界的讨论，根据多面体欧拉公式，仅仅用正六边形是没法组成球体形状结界。我也非常理解制作组为什么不画个足球：毕竟是魔法阵，六边形画的又比较大，弄个五边形也不好看也不好解释。]]></summary></entry><entry><title type="html">blender学习: Toon BSDF的硬阴影效果</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning/" rel="alternate" type="text/html" title="blender学习: Toon BSDF的硬阴影效果" /><published>2023-12-29T00:00:00+00:00</published><updated>2024-01-15T22:33:25+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning/"><![CDATA[<h3 id="导入模型">导入模型</h3>

<p>用glTF格式的模型</p>

<ul>
  <li>glTF格式介绍：<a href="https://github.com/KhronosGroup/glTF">https://github.com/KhronosGroup/glTF</a></li>
  <li>在vscode安装glTF tools 插件：
    <ul>
      <li>可以跳转到具体accessor，直接查看数据</li>
      <li>可以查看渲染之后的结果(包括背景和动画)</li>
    </ul>
  </li>
  <li>下载gltf模型: <a href="https://github.com/GPUOpen-LibrariesAndSDKs/Cauldron-Media/tree/v1.0.4/buster_drone">https://github.com/GPUOpen-LibrariesAndSDKs/Cauldron-Media/tree/v1.0.4/buster_drone</a></li>
</ul>

<h3 id="步骤">步骤</h3>

<ul>
  <li>参考<a href="https://www.bilibili.com/video/BV1ck4y1W7am/">b站的教学视频</a> 修改：
    <ul>
      <li>world property:
        <ul>
          <li>surface: 选background, strength 0
            <ul>
              <li>直接把surface的shader直接关掉应该也是一样的效果？</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>光源：
        <ul>
          <li>blender代码：
            <ul>
              <li>https://github.com/blender/cycles/blob/main/src/scene/light.cpp</li>
              <li>https://github.com/blender/cycles/blob/main/src/kernel/light/spot.h</li>
              <li>https://github.com/blender/cycles/blob/main/src/kernel/sample/mapping.h#L114</li>
            </ul>
          </li>
          <li>改成spot light</li>
          <li>radius改成0：影响光锥的软硬</li>
          <li>blend改成0</li>
        </ul>
      </li>
      <li>rendering
        <ul>
          <li>用cycles:
            <ul>
              <li>引擎改成cycles：cycles是基于光追的，更符合现实情况</li>
              <li>noise threshold改成0， sample改成64</li>
              <li>Light Paths里面反弹次数(Total, Diffuse, Glossy, Transmission)都改成0
                <ul>
                  <li>防止出现明亮表面和柔和边缘？</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>用eevee: eevee的效果看起来不太一样..
            <ul>
              <li>Film里面filter size改成0</li>
              <li>在shader和material output中间,加Shader to RGB-&gt;ColorRamp</li>
              <li>再把ColorRamp改成Constant, 只有黑白2个色阶</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>shader
        <ul>
          <li>改成Toon BSDF</li>
          <li>把反光的部分BSDF从diffuse改成glossy</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>加入运镜，参考教学视频 <a href="https://www.bilibili.com/video/BV1eq4y1y7D2/?vd_source=9cd152be6fbc1b9ad36a33604a13fb6e">https://www.bilibili.com/video/BV1eq4y1y7D2</a>
    <ul>
      <li>在animation界面删除本来的animation</li>
      <li>在layout界面开启auto key之后，点击播放：这个时候鼠标只能移动，需要按快捷键配合移动。</li>
    </ul>
  </li>
  <li>输出视频
    <ul>
      <li><img src="/personal_homepage/docs/attachment/output.mp4" alt="output.mp4" width="400" /></li>
    </ul>
  </li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="BSDF" /><category term="render" /><summary type="html"><![CDATA[导入模型]]></summary></entry><entry><title type="html">传感器颜色调制 (二)</title><link href="https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate1/" rel="alternate" type="text/html" title="传感器颜色调制 (二)" /><published>2023-12-26T00:00:00+00:00</published><updated>2024-01-22T19:41:46+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate1</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate1/"><![CDATA[<h2 id="通过coded-aperture-和-dispenser进行颜色调制">通过coded-aperture 和 dispenser进行颜色调制</h2>

<h3 id="coded-aperture的优点">coded-aperture的优点</h3>

<ol>
  <li><strong>有利于deblur</strong>
    <ol>
      <li>PSF是scene到image的kernel: $\text{image}=PSF*\text{scene}$</li>
      <li>如果对image做deblur, $\text{scene}=F^{-1}(\frac{F(\text{image})}{F(PSF)})=F^{-1}(\frac{F(\text{image})}{MTF})$</li>
      <li>传统的MTF存在cutoff点, 即在cutoff之上的的高频部分是0, 而coded-aperture可以保留部分高频信息, 使MTF没有完全为0的点</li>
    </ol>
  </li>
  <li>我不能确定coded aperture是否必要, 看起来颜色调制主要还是通过dispenser完成的</li>
</ol>

<ul>
  <li>仿真数据：
    <ul>
      <li>
        <p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240114142241.png" alt="Pasted image 20240114142241.png" width="300" /> <a href="#ref">1</a></p>
      </li>
      <li>
        <p>CASSI: coded_apeture+dispenser</p>

        <ul>
          <li>
            <p>coded_apeture把mask应用于所有通道</p>
          </li>
          <li>
            <p>dispenser依次给mask的通道图像y-axis 2pixel的shift</p>
          </li>
          <li>
            <p>所有通道叠加(一个像素是同行28x2=56个不同通道像素的叠加，出来的图像是很模糊的)</p>
          </li>
          <li>
            <p>仿真通过shot noise: $Y_{sim}=B(Y/QE,QE)$</p>

            <ul>
              <li>
                <p>本来读数是Y, qe是quantum efficiency</p>
              </li>
              <li>
                <p>B是binomial 分布</p>
              </li>
              <li>
                <p>这段其实没懂为什么要用binomial分布，而不是poisson分布$P(Y)$ , 大概Y/QE是平均光子数，所以sample这么多次，每次都有qe的概率转换为电子；但是仍然不理解为什么要在光电转换的部分随机</p>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>仿真:
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240117165405.png" alt="Pasted image 20240117165405.png" width="200" />   <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240117165253.png" alt="Pasted image 20240117165253.png" width="220" /></li>
    </ul>
  </li>
  <li>实际拍摄:
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240117165603.png" alt="Pasted image 20240117165603.png" width="200" />   <img src="/personal_homepage/docs/attachment/Pasted%20image%2020231226120247.png" alt="Pasted image 20231226120247.png" width="220" />  recon: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240122114048.png" alt="Pasted image 20240122114048.png" width="200" /></li>
    </ul>
  </li>
</ul>

<p>看起来仿真和实际拍摄的情况并不太一样啊?仿真的y方向距离更大</p>

<p>数据集使用：</p>
<ul>
  <li>simulation:
    <ul>
      <li>训练：
        <ul>
          <li>data: cave_1024_28</li>
          <li>crop_size: 随机crop到256x256, 和mask做simulation
            <ul>
              <li>shift3d mask: 28x256x310</li>
            </ul>
          </li>
          <li>mask: TSA_simu_data/mask.mat</li>
          <li>test:  TSA_simu_data/Truth/</li>
        </ul>
      </li>
      <li>测试：
        <ul>
          <li>mask: TSA_simu_data/mask.mat</li>
          <li>test: TSA_simu_data/Truth/</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>real:
    <ul>
      <li>训练:
        <ul>
          <li>size: 96</li>
          <li>data: CAVE_512_28 and KAIST_CVPR2021
            <ul>
              <li>CAVE_512_28 ：原数据集512x512x28 30个图片</li>
              <li>KAIST_CVPR2021： 2704x3376x28 30个图片</li>
            </ul>
          </li>
          <li>mask: TSA_real_data/mask.mat
            <ul>
              <li>660x660 0-1的数据</li>
              <li><img src="/personal_homepage/docs/attachment/mask.png" alt="mask.png" width="200" /></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>测试
        <ul>
          <li>size: 714x660</li>
          <li>data: TSA_real_data/Measurements/
            <ul>
              <li></li>
            </ul>
          </li>
          <li>mask: TSA_real_data/mask.mat</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><span id="ref"></span>
[1]  Zhao, Ruixuan, Chengshuai Yang, R. Theodore Smith, and Liang Gao. “Coded Aperture Snapshot Spectral Imaging Fundus Camera.” <em>Scientific Reports</em> 13, no. 1 (July 25, 2023): 12007. <a href="https://doi.org/10.1038/s41598-023-39117-2">https://doi.org/10.1038/s41598-023-39117-2</a>.</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="algorithm" /><category term="content" /><category term="sensor" /><summary type="html"><![CDATA[通过coded-aperture 和 dispenser进行颜色调制]]></summary></entry><entry><title type="html">传感器颜色调制 (一)</title><link href="https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate/" rel="alternate" type="text/html" title="传感器颜色调制 (一)" /><published>2023-12-23T00:00:00+00:00</published><updated>2023-12-27T23:14:21+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/algorithm/color-moderate/"><![CDATA[<h2 id="调制">调制</h2>

<p>一般把信号区分出来的过程叫调制。现在一般的传感器只能感应2d的光学信号强度(就是灰度图)，把不同波长的光分离，以获取特定光谱范围的信息的过程，就叫颜色调制。比如信号经过rgb的滤光片，得到彩色图像。</p>

<p>所有调制都是通过牺牲一部分空间精度为代价获得其他层次信息。</p>

<h2 id="通过排布滤光片进行颜色调制">通过排布滤光片进行颜色调制</h2>

<p>像传统的rggb bayer和quad bayer一样，可以用不同方式排布多光谱的滤光片。如：</p>
<h3 id="几种排布像素的方法">几种排布像素的方法</h3>

<ol>
  <li><strong>把像素不断二分<a href="#ref">1</a></strong>
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231227093202.png" alt="Pasted image 20231227093202.png" width="400" /></li>
      <li>如果不是$2^n$ 个通道，没法保证所有通道的像素密度一样。比如图上5个通道的情况。1，2通道的密度就比3，4，5的密度低。</li>
      <li>但是这样做可以让每个相同通道的间距相等。</li>
    </ul>
  </li>
  <li><strong>间隔相等斜向排布<a href="#ref">2</a></strong>
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231227093439.png" alt="Pasted image 20231227093439.png" width="200" /></li>
      <li>能保证每个channel的像素相邻的channel一直是一样的</li>
      <li>但是这样在各个方向上像素密度极度不均匀：比如图上5个通道情况，横竖方向相隔4个像素，斜向却相隔0个，3个像素</li>
    </ul>
  </li>
  <li><strong>分成primary channel和secondary channel两组 <a href="#ref">3</a></strong>
    <ul>
      <li>把secondary channel穿插在primay channel中</li>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231227100416.png" alt="Pasted image 20231227100416.png" width="200" /></li>
      <li>图中a,b,c是primary channel，像素密度高； d,e,f,g 是secondary channel，像素密度低</li>
    </ul>
  </li>
  <li><strong>一个实拍的样例</strong>
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231227114816.png" alt="Pasted image 20231227114816.png" width="300" /></li>
      <li>图中是8个通道的sensor实拍图做了伪彩变换之后的样例</li>
      <li>filter不同channel之间贴了黑胶阻挡(除了阻挡更多光线进入sensor以外，没什么积极意义)</li>
    </ul>
  </li>
</ol>

<h3 id="排布像素的规则">排布像素的规则</h3>

<ul>
  <li>根据不同通道的功能先确定需要的像素密度</li>
</ul>

<h3 id="采用滤光片排布调制的问题">采用滤光片排布调制的问题：</h3>

<ul>
  <li>技术本身的问题：
    <ul>
      <li>现在一般用<a href="https://en.wikipedia.org/wiki/Fabry–Pérot_interferometer">FP-干涉</a>技术来制作多光谱sensor需要的窄波段，FP-干涉需要使用多层透镜实现，相当于严重降低光线透过率</li>
      <li>mask均匀排布，会导致有些地方的傅立叶系数是0，不利于做reconstruction</li>
    </ul>
  </li>
  <li>工厂生产的问题：
    <ul>
      <li>生产的一个filter的尺寸最小在10um左右，但是目前的手机用的单像素尺寸在<a href="https://www.igao7.com/news/202204/Xo2jTjWP67ayPtIA.html">0.6～2.4um</a>(单像素2.4um已经是非常好的CMOS了)，不得不用类似quad bayer的做法让一个filter对应多个像素，无疑会影响调制的精度</li>
      <li>透镜部分和成像部分不贴合：透镜距离sensor的感光区域有大约3um的垂直距离，会导致像素中有效信息进一步降低</li>
      <li>透镜偏移，没有和像素的位置对应：导致传感器之间的差异很大</li>
    </ul>
  </li>
</ul>

<p><span id="ref"></span>
[1]  Lidan Miao and Hairong Qi. “The Design and Evaluation of a Generic Method for Generating Mosaicked Multispectral Filter Arrays.” <em>IEEE Transactions on Image Processing</em> 15, no. 9 (September 2006): 2780–91. <a href="https://doi.org/10.1109/TIP.2006.877315">https://doi.org/10.1109/TIP.2006.877315</a>.</p>

<p>[2] Aggarwal, Hemant Kumar, and Angshul Majumdar. “Single-Sensor Multi-Spectral Image Demosaicing Algorithm Using Learned Interpolation Weights.” In <em>2014 IEEE Geoscience and Remote Sensing Symposium</em>, 2011–14. Quebec City, QC: IEEE, 2014. <a href="https://doi.org/10.1109/IGARSS.2014.6946857">https://doi.org/10.1109/IGARSS.2014.6946857</a>.</p>

<p>[3] Yasuma, Fumihito, Tomoo Mitsunaga, Daisuke Iso, and Shree K. Nayar. “Generalized Assorted Pixel Camera: Postcapture Control of Resolution, Dynamic Range, and Spectrum.” <em>IEEE Transactions on Image Processing</em> 19, no. 9 (September 2010): 2241–53. <a href="https://doi.org/10.1109/TIP.2010.2046811">https://doi.org/10.1109/TIP.2010.2046811</a>.</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="algorithm" /><category term="content" /><category term="sensor" /><summary type="html"><![CDATA[调制]]></summary></entry><entry><title type="html">双十二装机</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/new-computer/" rel="alternate" type="text/html" title="双十二装机" /><published>2023-12-22T00:00:00+00:00</published><updated>2023-12-22T16:21:32+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/new-computer</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/new-computer/"><![CDATA[<p>趁着双十二激情下单，前后不到一天，选的配件都没什么性价比。</p>

<h3 id="配置">配置：</h3>
<ul>
  <li>不想再等了，买了4080</li>
  <li>cpu实际换了7900x3d</li>
  <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231222024142.png" alt="Pasted image 20231222024142.png" width="400" /></li>
</ul>

<h3 id="外观">外观：</h3>
<ul>
  <li>买完发现灯光处于一个过饱和状态，显卡还带屏幕。不过再增加发光的东西就怎么都看不顺眼了，暂时只能保持这样的状态。</li>
  <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231222072754.png" alt="Pasted image 20231222072754.png" width="300" /> 	<img src="/personal_homepage/docs/attachment/Pasted%20image%2020231222071842.png" alt="Pasted image 20231222071842.png" width="250" /></li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="device" /><category term="life" /><summary type="html"><![CDATA[趁着双十二激情下单，前后不到一天，选的配件都没什么性价比。]]></summary></entry><entry><title type="html">小红书学到的几种图片调色</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/photo-color/" rel="alternate" type="text/html" title="小红书学到的几种图片调色" /><published>2023-12-21T00:00:00+00:00</published><updated>2023-12-22T15:10:39+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/photo-color</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/photo-color/"><![CDATA[<p>感觉共同点是：为了追求画面简洁有冲击力，不约而同的压缩了亮度和颜色的动态范围。</p>
<h2 id="版画滤镜">版画滤镜</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231221113525.png" alt="Pasted image 20231221113525.png" width="300" />  <img src="/personal_homepage/docs/attachment/Pasted%20image%2020231221113539.png" alt="Pasted image 20231221113539.png" width="300" /></p>
<ul>
  <li>醒图4个滤镜依次叠加，透明度依次减小
    <ul>
      <li>千禧-&gt;幻想蝴蝶</li>
      <li>新中式-&gt;空谷</li>
      <li>千禧-&gt;数字彩虹</li>
      <li>新中式-&gt;烟霞</li>
    </ul>
  </li>
  <li>实际实验结果
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231221114420.png" alt="Pasted image 20231221114420.png" width="300" /></li>
      <li>调整亮度曲线如图，暗部切断，亮部反色，压缩动态范围</li>
      <li>添加噪声</li>
      <li>去掉图片原有颜色</li>
      <li>按照亮暗调节新的颜色</li>
    </ul>
  </li>
</ul>

<h2 id="白夜之树">白夜之树</h2>

<ul>
  <li>
    <p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020231221121648.png" alt="Pasted image 20231221121648.png" width="300" />  <img src="/personal_homepage/docs/attachment/Pasted%20image%2020231221121655.png" alt="Pasted image 20231221121655.png" width="300" /></p>
  </li>
  <li>
    <p>方法：</p>
    <ul>
      <li>醒图滤镜：千禧-&gt;午夜 把照片变成蓝色，就是为了伪造天空部分吧？</li>
      <li>曲线反色：画面要避开一些常见的物品，不然很容易看出其实是反色，就感觉出戏了</li>
      <li>光感-100：作用是，把有颜色的部分变暗？</li>
    </ul>
  </li>
</ul>

<h2 id="单色涂鸦">单色涂鸦</h2>

<p><img src="/personal_homepage/docs/attachment/IMG_8192.jpg" alt="IMG_8192.jpg" width="300" />   <img src="/personal_homepage/docs/attachment/IMG_8193.jpg" alt="IMG_8193.jpg" width="300" /></p>

<ul>
  <li>方法：
    <ul>
      <li>醒图特效：单色填充：可能是根据饱和度？把饱和度高的部分填充了粉色。因为图片里红色和蓝色都被填充了，所以不是根据主体色识别。其他位置变为灰度图</li>
      <li>醒图特效：单色涂鸦：检测边缘，设置白边
        <ul>
          <li>可能是检测闭合的部分，处理成涂鸦的斜线</li>
          <li>检测线条少的位置加文字</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="醒图" /><summary type="html"><![CDATA[感觉共同点是：为了追求画面简洁有冲击力，不约而同的压缩了亮度和颜色的动态范围。 版画滤镜]]></summary></entry></feed>