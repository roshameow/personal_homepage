<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://roshameow.github.io//personal_homepage/atom.xml" rel="self" type="application/atom+xml" /><link href="https://roshameow.github.io//personal_homepage/" rel="alternate" type="text/html" /><updated>2024-03-12T03:17:51+00:00</updated><id>https://roshameow.github.io//personal_homepage/atom.xml</id><title type="html">Liu, Wen’s Home Page</title><subtitle>Work, Experiments and Ideas.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><entry><title type="html">blender学习: 镜头推移</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning9/" rel="alternate" type="text/html" title="blender学习: 镜头推移" /><published>2024-03-12T00:00:00+00:00</published><updated>2024-03-12T15:32:52+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning9</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning9/"><![CDATA[<h2 id="前向推镜头">前向推镜头</h2>

<p>参考<a href="https://www.xiaohongshu.com/explore/65a2ce0a000000001d037212">这个教学视频</a>, 用array modifier复制多个模型 , 得到一种穿梭效果</p>

<p><img src="/personal_homepage/docs/attachment/camera_move.mp4" alt="camera_move.mp4" width="300" /></p>

<h2 id="模型资源">模型资源</h2>

<p>[1] https://sketchfab.com/feed</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="camera" /><summary type="html"><![CDATA[前向推镜头]]></summary></entry><entry><title type="html">blender学习: 做流光效果</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning8/" rel="alternate" type="text/html" title="blender学习: 做流光效果" /><published>2024-03-11T00:00:00+00:00</published><updated>2024-03-12T14:17:26+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning8</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning8/"><![CDATA[<p>用金属材质反射world背景的流动</p>
<h3 id="步骤">步骤:</h3>

<p>参考<a href="https://www.bilibili.com/video/BV1Ny421q7HM/">这个教学视频</a></p>
<ul>
  <li>制作物体:
    <ul>
      <li>添加curve</li>
      <li>调整Data-&gt;Geometry-&gt;Bevel(倒角)-&gt;Round-&gt; Depth: 把曲线变成软管</li>
      <li>加modifier-&gt;subdivisor</li>
    </ul>
  </li>
  <li>shader:
    <ul>
      <li>object: 用principled BSDF, 把metallic调到1, roughness 调整到0.1</li>
      <li>world:
        <ul>
          <li>在background添加流动材质
            <ul>
              <li>设置<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a>  generate-&gt;Mapping(Y=#frame/40)-&gt;background图片</li>
            </ul>
          </li>
          <li>得到黑色背景
            <ul>
              <li>添加一个黑色背景, <a href="https://blenderartists.org/t/why-use-is-camera-ray-in-the-world/650625/3">用Light Path的Is Camera Ray控制混合</a> : 背景和物体分开的原理?</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>light: 改成sun, 给物体增加反光</li>
  <li>结果:
    <ul>
      <li><img src="/personal_homepage/docs/attachment/color_change.mp4" alt="color_change.mp4" width="300" /></li>
    </ul>
  </li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="shader" /><category term="curve" /><summary type="html"><![CDATA[用金属材质反射world背景的流动 步骤:]]></summary></entry><entry><title type="html">attention的优化</title><link href="https://roshameow.github.io//personal_homepage/docs/attention2/" rel="alternate" type="text/html" title="attention的优化" /><published>2024-03-09T00:00:00+00:00</published><updated>2024-03-11T23:17:24+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/attention2</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/attention2/"><![CDATA[<h3 id="gaugated-attention-unit">GAU(gated attention unit)</h3>

<p>self-attention做为weight, conv做为变换</p>

<h3 id="ssmstate-space-model">SSM(state space model)</h3>

<p><a href="https://en.wikipedia.org/wiki/State-space_representation">状态空间</a> 的表示: 用input更新状态, 用状态生成output</p>

<h3 id="linear-attention">Linear attention</h3>

<h3 id="s4structured-state-space-sequence-结构">S4(Structured state space sequence) 结构</h3>
<h3 id="h3hungry-hungry-hippos-结构">H3(Hungry Hungry Hippos) 结构</h3>

<h3 id="mamba">Mamba</h3>

<h3 id="retnet">RetNet</h3>

<h3 id="rwkv">RWKV</h3>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="content" /><summary type="html"><![CDATA[GAU(gated attention unit)]]></summary></entry><entry><title type="html">blender学习: 做卡通描边</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning7/" rel="alternate" type="text/html" title="blender学习: 做卡通描边" /><published>2024-03-06T00:00:00+00:00</published><updated>2024-03-07T20:14:23+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning7</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning7/"><![CDATA[<h2 id="用solidify背面剔除法线翻转">用solidify+背面剔除+法线翻转</h2>

<p>给mesh增加厚度, 让描边材质只在厚度边缘生效</p>
<h3 id="步骤">步骤:</h3>

<p>参考<a href="https://www.bilibili.com/video/BV1Ju4y197yk">这个教学视频</a></p>

<ul>
  <li>shader:
    <ul>
      <li>选择一个主material的效果(Slot 1): 用Diffuse BSDF-&gt;shader to RGB-&gt;Color Ramp-&gt;Emission</li>
      <li>添加一个描边材质(Slot 2): 用Emission, 选择我们描边的颜色
        <ul>
          <li>对这个材质开启Backface Culling(背面剔除)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>在Modifier添加<a href="https://docs.blender.org/manual/en/latest/modeling/modifiers/generate/solidify.html">solidify</a>: 给mesh表面增加厚度
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240307120524.png" alt="Pasted image 20240307120524.png" width="100" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240307120542.png" alt="Pasted image 20240307120542.png" width="110" /></li>
      <li>调整thickness=-0.02m
        <ul>
          <li>offset默认是-1, 要让thickness和offset同方向(让增加的厚度mesh朝外凸)</li>
        </ul>
      </li>
      <li>Materials-&gt;Material Offset=1 :让solidify的厚度mesh采用我们的描边材质, 即下一个slot的material</li>
      <li>开启Normals-&gt;flip: 让颜色上到厚度mesh的内表面</li>
    </ul>
  </li>
  <li>结果: 对三维的模型描边有种新鲜的观感.
    <ul>
      <li><img src="/personal_homepage/docs/attachment/stoke.mp4" alt="stoke.mp4" width="300" /></li>
      <li>描边的前提是提取边缘. 如果是二维图像有很多做法, 比如自动提取图像的边缘合并. 对于我们自己建的模型当然也有办法提取边缘. 但是如果其他方式得到的模型(比如扫描得到的模型), 我们怎么识别边缘, 然后edit呢?</li>
    </ul>
  </li>
</ul>

<h2 id="blender使用技巧">blender使用技巧</h2>

<ul>
  <li>复制material和modifier:
    <ul>
      <li>按<a href="https://blender.stackexchange.com/questions/7044/copy-material-to-another-object">这个方法</a> 可以复制到全部, 但是没法选择materail的单个slot😠, 只能全部复制过去?</li>
    </ul>
  </li>
</ul>

<h2 id="其他描边效果">其他描边效果</h2>

<p>[1] https://svg-animation-booklet.vercel.app/chapter5.html#实现动画 svg描边动画</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="material" /><category term="stoke" /><category term="modifier" /><summary type="html"><![CDATA[用solidify+背面剔除+法线翻转]]></summary></entry><entry><title type="html">stable-diffusion的结构和微调模型</title><link href="https://roshameow.github.io//personal_homepage/docs/deeplearning/stable-diffusion6/" rel="alternate" type="text/html" title="stable-diffusion的结构和微调模型" /><published>2024-02-29T00:00:00+00:00</published><updated>2024-03-07T03:18:33+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/deeplearning/stable-diffusion6</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/deeplearning/stable-diffusion6/"><![CDATA[<h2 id="stable-diffusion结构和controlnet插件">stable-diffusion结构和controlnet插件</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240306124200.png" alt="Pasted image 20240306124200.png" width="500" /></p>

<ul>
  <li>controlnet保持和stable-diffusion u-net上半部分相同的结构</li>
  <li>controlnet输入是和原图一样的hint图像, 比如controlnet-openpose输入的不是关节坐标数据, 而是彩色的人体坐标图</li>
</ul>

<h2 id="resnetblock-spatialtransfomer-结构和插件">Resnetblock, SpatialTransfomer 结构和插件</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240306123108.png" alt="Pasted image 20240306123108.png" width="300" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240306123128.png" alt="Pasted image 20240306123128.png" width="500" /></p>

<ul>
  <li>lora可以应用在网络的任何线性结构上, 比如:
    <ul>
      <li>attention里面的q,k,v,out层</li>
      <li>feedforward里面的linear层</li>
      <li>clip里面的mlp, fc层</li>
    </ul>
  </li>
  <li>这几种模型的作用的粒度不一样, 从小到大是: lora(线性层) &lt; Gligen=IpAdapter(SpatialTransformer层) &lt; Controlnet(U-net的block)
    <ul>
      <li>模型的size也是依次变大</li>
    </ul>
  </li>
</ul>

<h2 id="reference">reference</h2>
<p><span id="ref"></span>
[1] Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. “<strong>LoRA</strong>: Low-Rank Adaptation of Large Language Models.” arXiv, October 16, 2021. <a href="https://doi.org/10.48550/arXiv.2106.09685">https://doi.org/10.48550/arXiv.2106.09685</a>.</p>

<p>[2] Zhang, Lvmin, and Maneesh Agrawala. “Adding Conditional <strong>Control</strong> to Text-to-Image Diffusion Models.” arXiv, February 10, 2023. <a href="https://doi.org/10.48550/arXiv.2302.05543">https://doi.org/10.48550/arXiv.2302.05543</a>.</p>

<p>[3] Ye, Hu, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang. “<strong>IP-Adapter</strong>: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models.” arXiv.org, August 13, 2023. <a href="https://arxiv.org/abs/2308.06721v1">https://arxiv.org/abs/2308.06721v1</a>.</p>

<p>[4] Li, Yuheng, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong Jae Lee. “<strong>GLIGEN</strong>: Open-Set Grounded Text-to-Image Generation.” arXiv, April 16, 2023. <a href="https://doi.org/10.48550/arXiv.2301.07093">https://doi.org/10.48550/arXiv.2301.07093</a>.</p>

<p>代码: 参考comfyui里<code class="language-plaintext highlighter-rouge">comfy.ldm.modules.diffusionmodules.openaimodel.py</code> 的实现, 除了controlnet是加在<code class="language-plaintext highlighter-rouge">condition</code> 流里面, 其他几种都是通过<code class="language-plaintext highlighter-rouge">model.patches</code> 切换网络分支实现的.</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="deeplearning" /><category term="content" /><category term="attention" /><category term="stable-diffusion" /><category term="lora" /><category term="controlnet" /><category term="ipadapter" /><category term="gligen" /><summary type="html"><![CDATA[stable-diffusion结构和controlnet插件]]></summary></entry><entry><title type="html">stable-diffusion的用法: 常用插件</title><link href="https://roshameow.github.io//personal_homepage/docs/tool/stable-diffusion5/" rel="alternate" type="text/html" title="stable-diffusion的用法: 常用插件" /><published>2024-02-27T00:00:00+00:00</published><updated>2024-02-29T17:53:57+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/tool/stable-diffusion5</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/tool/stable-diffusion5/"><![CDATA[<p>ComfyUI使用时用到的插件</p>

<table>
  <thead>
    <tr>
      <th>插件</th>
      <th>用途</th>
      <th>类型</th>
      <th>必须?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://github.com/ltdrdata/ComfyUI-Manager">ComfyUI-Manager</a></td>
      <td>- 查找和安装插件和模型<br />- 可以识别工作流中的missing node</td>
      <td>功能</td>
      <td>✔️</td>
    </tr>
    <tr>
      <td><a href="https://github.com/rgthree/rgthree-comfy">rgthree-comfy</a></td>
      <td>- 显示一个node执行进度条<br />- 优化节点执行graph<br />- 提供Image Comparer节点<br />- Lora Loader Stack 节点</td>
      <td>功能</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/palant/image-resize-comfyui">Resize</a></td>
      <td>resize图片</td>
      <td>功能<br /></td>
      <td>✔️</td>
    </tr>
    <tr>
      <td><a href="https://github.com/giriss/comfy-image-saver">image-saver</a></td>
      <td>Save Image w/Metadata节点<br />把图片生成的信息写到图片metadata里<br />(webui有类似功能)</td>
      <td>功能</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/ltdrdata/ComfyUI-Impact-Pack">Impact-Pack</a></td>
      <td>很多功能, 但是有些感觉封装的太复杂了</td>
      <td>功能</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes">Comfyroll_CustomNodes</a></td>
      <td>CR开头的一堆节点</td>
      <td>功能</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/ssitu/ComfyUI_UltimateSDUpscale">UltimateSDUpscale</a></td>
      <td>- 分块图生图<br />- 改变tile的一些融合方式</td>
      <td>功能</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/shadowcz007/comfyui-mixlab-nodes?tab=readme-ov-file">comfyui-mixlab-nodes</a></td>
      <td>- clip interrogator 节点: 分析图片信息</td>
      <td>功能<br /></td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/twri/sdxl_prompt_styler">promt styler</a></td>
      <td>- SDXL Prompt Styler: 把一些画风写成prompt</td>
      <td>功能</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/kijai/ComfyUI-Marigold">ComfyUI-Marigold</a></td>
      <td>识别深度图</td>
      <td>模型</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/storyicon/comfyui_segment_anything">comfyui_segment_anything</a></td>
      <td>识别mask</td>
      <td>模型</td>
      <td> </td>
    </tr>
    <tr>
      <td><a href="https://github.com/Acly/comfyui-inpaint-nodes">inpaint-nodes</a></td>
      <td>一系列关于inpaint的节点<br />- Fooocus inapint<br />- Inpaint (using Model) : 用于加载Lama等inpaint模型</td>
      <td>模型</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>很多插件提供重复的功能, 或者没有维护, 生态还挺混乱的</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="tool" /><category term="content" /><category term="ComfyUI" /><summary type="html"><![CDATA[ComfyUI使用时用到的插件]]></summary></entry><entry><title type="html">stable-diffusion的用法: 常用的作图功能-提升细节</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion4/" rel="alternate" type="text/html" title="stable-diffusion的用法: 常用的作图功能-提升细节" /><published>2024-02-24T00:00:00+00:00</published><updated>2024-02-28T20:19:41+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion4</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion4/"><![CDATA[<p>和inpaint一样要利用stable-diffusion的图生图功能, 想让图像忠于原图的情况下提升图像细节, 解决图像模糊, 扭曲, 不合理的部分.</p>

<h2 id="使用">使用</h2>

<ul>
  <li>模型:
    <ul>
      <li>一般模型: 对于模糊的图, encode+ksample+decode就可以提升细节</li>
      <li><a href="https://iceclear.github.io/projects/stablesr/">StableSR</a>: 基于sd2.1, 关于细节修复任务重新训练的模型</li>
      <li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0">sdxl refiner模型</a>: 输入latent image, 官方建议接在sdxl base模型的后面用
        <ul>
          <li>sdxl refiner一般只能配和sdxl base模型, 不能配合其他风格的sdxl模型, 所以不是很实用</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>控制:
    <ul>
      <li>更像原图:
        <ul>
          <li>风格控制: 和inpaint一样, 可以用text promt和ipadpater控制</li>
          <li>微调模型控制:
            <ul>
              <li><a href="[https://github.com/Mikubill/sd-webui-controlnet/discussions/1142](https://github.com/Mikubill/sd-webui-controlnet/discussions/1142)">controlnet tile</a>(配合v1.5模型): 这是个非常好用的模型👍, 可以在分块(输入的不是一整张图)的时候, 更倾向理解图像部分而不是text prompt</li>
              <li><a href="https://huggingface.co/lllyasviel/sd_control_collection/discussions/1">关于sdxl模型没有一个tile模型的讨论</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>提升细节:
        <ul>
          <li>从流程上控制:
            <ul>
              <li><a href="https://ku-cvlab.github.io/Self-Attention-Guidance">Self-attention Guidance(SAG)</a>
                <ul>
                  <li>和cfg(class free guidance)类似, 是更改reverse diffusion process的过程</li>
                  <li>让图片变清晰原理:  认为self-attention值更大的位置是更重要的位置, 让其离blurry的方向更远, 即更清晰
                    <ul>
                      <li>从文章里的例子看, 这种做法达成了一种神奇的自纠正的效果, 可能是因为在reverse diffusion process中重要的地方更快的变清晰, 引导了其他部分的生成</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>方便的节点: stable-diffusion本身的图生图功能input和output等大的, 图像大小和模型不匹配的时候就需要分块处理或放大
    <ul>
      <li>分块: 下面两个功能类似
        <ul>
          <li><a href="https://github.com/ltdrdata/ComfyUI-Impact-Pack/blob/5f73ac55c02b588bf151c355522e8c402723e134/modules/impact/core.py#L329">ComfyUI Impact Pack 提供的detailer节点</a> : 包含一些方便的功能
            <ul>
              <li>可以分块图生图</li>
              <li>可以设置cycle次数, 即图生图的次数 (如果comfyUI本身提供循环功能就好了)</li>
            </ul>
          </li>
          <li><a href="https://github.com/ssitu/ComfyUI_UltimateSDUpscale">UltimateSDUpscale</a>
            <ul>
              <li>支持分块图生图</li>
              <li>改变tile的一些融合方式</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>放大: 放大经常伴随细节损失, 一般是和refine功能接力使用: upscale-&gt;refine-&gt;upscale-&gt;refine-&gt;upscale-&gt;refine…
        <ul>
          <li>我看到有人在latent image上放大, 总感觉这么做不对, latent image的一个点大约对应图像8x8的patch, 放大latent后这个比例关系和放大图像是不一样的</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="效果">效果</h2>

<ul>
  <li>使用时要注意:
    <ul>
      <li>输入图像的尺寸: 如果输入图像太小也是无法生成正常图片的, 尽量用外部的resize和upscale调整到和模型训练的大小相近</li>
      <li>图像包含的语义信息的尺寸</li>
      <li>reverse diffusion process的参数: cfg, denoise, steps等</li>
    </ul>
  </li>
  <li>对一些常见的噪声效果很好, 例如: jpg压缩的高频alias, 摩尔纹
    <ul>
      <li>但是对于其他噪声就不认识, 可能被认作图像本身的风格?
        <ul>
          <li>例如我用其他prior搭配<a href="https://en.wikipedia.org/wiki/Augmented_Lagrangian_method">admm算法</a>恢复图像的中间结果</li>
          <li>汉字也会被改变的看不出形状</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>恢复出的图像风格会受选择的主要模型风格影响, 很难保证细节不变风格还原</li>
  <li>恢复真实人物的效果很差, 可能是本身我们对人脸细节要求就更严格? 可能需要加载专门控制人脸的微调模型</li>
</ul>

<h2 id="comfyui-workflow">ComfyUI workflow</h2>

<p>用sdxl的refiner$\downarrow$ : <a href="https://gist.github.com/roshameow/7a46bcdb4d7bdc5b2c0e758e4aa85a9f#file-refine_sdxl_refiner-json"><strong>refine_sdxl_refiner.json</strong></a></p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-27%20231030.png" alt="屏幕截图 2024-02-27 231030.png" width="800" /></p>

<p>用detailer节点和 <a href="https://github.com/ssitu/ComfyUI_UltimateSDUpscale">UltimateSDUpscale</a> 节点$\downarrow$ : <a href="https://gist.github.com/roshameow/7a46bcdb4d7bdc5b2c0e758e4aa85a9f#file-refine_impact_pack_detailer_sag_ultimatesd-json"><strong>refine_impact_pack_detailer_SAG_UltimateSD.json</strong></a></p>
<ul>
  <li>参考<a href="https://comfyworkflows.com/workflows/f9ed8191-b2e1-4417-ac26-2ecc7ff2a484">这个comfyworkflows上分享的workflow</a></li>
</ul>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-27%20221824.png" alt="屏幕截图 2024-02-27 221824.png" width="800" /></p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="ComfyUI" /><category term="sdxl" /><category term="refine" /><summary type="html"><![CDATA[和inpaint一样要利用stable-diffusion的图生图功能, 想让图像忠于原图的情况下提升图像细节, 解决图像模糊, 扭曲, 不合理的部分.]]></summary></entry><entry><title type="html">stable-diffusion的用法: 常用的作图功能-抠图, inpainting, 引导图</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion3/" rel="alternate" type="text/html" title="stable-diffusion的用法: 常用的作图功能-抠图, inpainting, 引导图" /><published>2024-02-18T00:00:00+00:00</published><updated>2024-03-01T22:58:08+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion3</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion3/"><![CDATA[<h2 id="用sam抠图">用SAM抠图</h2>

<p>以下两种方式都是对segment-anything二次封装</p>
<ul>
  <li>在ComfyUI里用<a href="https://github.com/storyicon/comfyui_segment_anything">segment anything节点</a>
    <ul>
      <li>特点: 任何shape都可以, 输入text prompt, 但是没法输入位置</li>
      <li>步骤:
        <ol>
          <li><a href="https://github.com/IDEA-Research/GroundingDINO">groundingDINO</a>模型: image, text prompt-&gt;目标检测box</li>
          <li><a href="https://github.com/facebookresearch/segment-anything">SAM</a>模型: image, box-&gt; mask
            <ol>
              <li>SAM模型本体可以接受多种形式的prompt</li>
              <li>SAM模式的特点是对image只encode一次, 这里box是作为prompt形式输入的, 不是在图像上crop然后处理cropped image</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>🤔️: SAM本来就可以输入text prompt, 加入groundingDINO模型是因为SAM的text promt效果不好吗?</li>
    </ul>
  </li>
  <li><a href="https://github.com/geekyutao/Inpaint-Anything">inpaint-anything</a>
    <ul>
      <li>特点: 输入point prompt和text prompt(optional), 对输入图像大小有要求, 还接入了一个stable-diffusion的inpaint模块</li>
    </ul>
  </li>
</ul>

<h2 id="inpainting--outpainting--guided">inpainting &amp; outpainting &amp; guided</h2>

<ul>
  <li>图生图功能: 利用stable-diffusion的sampler流程, noise mask之外的部分网络就不会去更改, 利用VAE decoder的填补能力
    <ul>
      <li>VAE encode成latent: 根据情况选择图像输入
        <ol>
          <li>输入原图: 直接用VAE Encode-&gt;latent-&gt;Set Latent Noise Mask-&gt;Ksampler
            <ul>
              <li>适合想保留部分原图元素的</li>
            </ul>
          </li>
          <li>输入用灰色填补mask的图: 用 <a href="https://blenderneko.github.io/ComfyUI-docs/Core%20Nodes/Latent/inpaint/VAEEncodeForInpainting/">VAE Encode(for inpainting)</a> -&gt;latent-&gt;Ksampler
            <ul>
              <li><a href="https://blenderneko.github.io/ComfyUI-docs/Core%20Nodes/Latent/inpaint/VAEEncodeForInpainting/">VAE Encode(for inpainting)</a> 相当于 用灰色mask的图<a href="https://blenderneko.github.io/ComfyUI-docs/Core%20Nodes/Latent/VAEEncode/">VAE Encode</a> + <a href="https://blenderneko.github.io/ComfyUI-docs/Core%20Nodes/Latent/inpaint/SetLatentNoiseMask/">Set Latent Noise Mask</a> 两个节点的效果</li>
              <li>适合想要在mask处新生成物体的</li>
            </ul>
          </li>
          <li>输入自制引导图: 直接用VAE Encode-&gt;latent-&gt;Set Latent Noise Mask-&gt;Ksampler
            <ul>
              <li>适合想要引导图上的一些元素的: 形状, 布局, 颜色等</li>
            </ul>
          </li>
          <li>输入LaMa inpaint的图: 用<a href="https://github.com/Acly/comfyui-inpaint-nodes">fooocus comfyUI版本</a> 提供的inpaint from model节点, 然后再走VAE Encode-&gt;latent-&gt;Set Latent Noise Mask-&gt;Ksampler的流程
            <ul>
              <li><strong>一定要用GrowMask加大mask的范围</strong>(最好把图像中受物体影响的部分全mask掉,例如mask人物的影子, 或是被挡住一半的文字. 不要留下不和谐的部分. <a href="#ref">3</a> )</li>
              <li>适合有重复pattern的场景效果</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>用 <a href="https://blenderneko.github.io/ComfyUI-docs/Core%20Nodes/Latent/inpaint/SetLatentNoiseMask/">Set Latent Noise Mask</a> 在做sampler的流程中对mask以外的地方进行保留
        <ul>
          <li>sdxl模型latent image可以对应到8x8的pixel patch, 输入的mask会resize到latent大小成为latent mask</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>控制: inpainting任务是想让生成的部分风格接近原图, 和原图边界融合的更好
    <ul>
      <li>用ipadapter控制风格
        <ul>
          <li>ipadapter会参考原图物体的位置关系, 使这个控制在outpainting里非常鸡肋, 我们的目的是生成和原图风格一致的新物体, 而不是把原来的物体叠加在图片上
            <ul>
              <li>用合适的text prompt控制+引导图可以有效的减少ipadapter对物体位置的影响, 效果非常好</li>
            </ul>
          </li>
          <li>ipadapter的attention mask输入是 整张图-&gt; 部分 的流程, 而不是我们在inpainting任务想要的 部分 -&gt; 整张图
            <ul>
              <li>attention mask可以用来把两张图融合在同一张图的不同位置, 例如让两个人合影</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>用text prompt控制
        <ul>
          <li><a href="https://github.com/pythongosssss/ComfyUI-WD14-Tagger">WD14 Tagger</a> 推导提示词</li>
          <li>用<a href="https://github.com/ZHO-ZHO-ZHO/ComfyUI-Gemini">Gemini</a> 的API的打标功能</li>
        </ul>
      </li>
      <li>微调模型控制: 如果不加任何模型, 生成出来的结果和原图看起来完全不融合
        <ul>
          <li>controlnet inpaint:(配合v1.5)
            <ul>
              <li>inpaintpreprocessor输入image, mask</li>
              <li>inpaintpreprocessor处理过的图像输入inpaint controlnet</li>
              <li>controlnet连接text prompt</li>
              <li>用controlnet的时候甚至可以用空的latent, 因为controlnet会更改sampler流程为生成整张图?
                <ul>
                  <li>但是一般还是输入image latent 参考, 不然的话颜色风格会变奇怪</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>fooocus inpaint: (配合sdxl)
            <ul>
              <li><a href="https://github.com/lllyasviel/Fooocus/discussions/414">fooocus自己的ui界面做inpaint</a>网上评价很好</li>
              <li><a href="https://github.com/Acly/comfyui-inpaint-nodes">fooocus comfyUI版本</a>的一些使用问题: README里给出的工作流都不太work
                <ul>
                  <li>输入model, patch(包含一个head模型和一个lora模型), latent(必须包含latent image和noise mask)</li>
                  <li>使用时感觉好像一定要配合VAE Encode(for inpainting), 如果输入lama补充后的, 结果会出现奇怪的偏色, 是模型内部对mask部分进行了识别吗?</li>
                  <li>用fooocus 开发的dpmpp sampler方式迭代, 也会出现奇怪的东西, 是comfyui的实现有问题吗?</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>结果: 远没有达到一键生成的效果, 但是比起lama只会填入重复花纹还是有很大进步
    <ul>
      <li>新生成的部分和原图融合的不好
        <ul>
          <li>按这个流程原图mask之外的内容不会重新生成, 融合的不好可以理解, 应该是生成整张图才对. 这个工作流应该是有问题, 没有发挥stable diffusion的全部能力</li>
        </ul>
      </li>
      <li>需要修改seed多次生成(抽卡), 人工选好一点的效果做为图生图VAE部分的输入继续</li>
      <li>尤其是人物, 动物, 补全的地方可以看出很明显的问题, 是多次抽卡解决不了的, 必须要配合人工实时修改</li>
    </ul>
  </li>
</ul>

<h2 id="comfyui-workflow">ComfyUI workflow</h2>
<h3 id="换背景">换背景</h3>

<p>工作流: <a href="https://gist.github.com/roshameow/041450c340e56d39f12c93bd7d2d8606#file-inpainting_background_sam_fooocus-json"><strong>inpainting_background_SAM_fooocus.json</strong></a> $\downarrow$</p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-23%20232215.png" alt="屏幕截图 2024-02-23 232215.png" width="800" /></p>
<h3 id="去掉不想要的人物">去掉不想要的人物</h3>

<p><a href="https://gist.github.com/roshameow/041450c340e56d39f12c93bd7d2d8606#file-inpaint_delete_person_sam_lama_fooocus-json"><strong>inpaint_delete_person_SAM_Lama_fooocus.json</strong></a> $\downarrow$</p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-23%20231325.png" alt="屏幕截图 2024-02-23 231325.png" width="800" /></p>

<h3 id="修改局部">修改局部</h3>

<p><a href="https://gist.github.com/roshameow/041450c340e56d39f12c93bd7d2d8606#file-inpaint_edit_fooocus_ipadapter-json"><strong>inpaint_edit_fooocus_ipadapter.json</strong></a> $\downarrow$</p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-23%20235229.png" alt="屏幕截图 2024-02-23 235229.png" width="800" /></p>

<p>和inpaint类似, 用Pad for Outpainting生成mask和灰色填补的图像</p>

<h3 id="outpaint-更改图片尺寸">outpaint 更改图片尺寸</h3>

<p><a href="https://gist.github.com/roshameow/041450c340e56d39f12c93bd7d2d8606#file-outpainting_lama_fooocus_ipadapter-json"><strong>outpainting_lama_fooocus_ipadapter.json</strong></a> $\downarrow$</p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-23%20230951.png" alt="屏幕截图 2024-02-23 230951.png" width="800" /></p>

<ul>
  <li>想生成简单纯色的背景似乎不可能, 网络总会自己加些东西: 是不是网络认为纯色背景是一种未完成的状态?</li>
</ul>

<h3 id="由引导图生成图片">由引导图生成图片</h3>

<p><a href="https://gist.github.com/roshameow/041450c340e56d39f12c93bd7d2d8606#file-guided_image_ipadapter_attmask-json"><strong>guided_image_ipadapter_attmask.json</strong></a> $\downarrow$</p>
<ul>
  <li><a href="https://www.bilibili.com/video/BV1tU421o7hu/">参考网络上这个做法</a> : 生成一组边框和圆形logo</li>
  <li>用到了inpaint, 图片引导, ipadapter的attmask功能</li>
</ul>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-28%20224350.png" alt="屏幕截图 2024-02-28 224350.png" width="800" /></p>

<ul>
  <li>用引导图控制颜色的例子:
    <ul>
      <li>
        <iframe src="//player.bilibili.com/player.html?aid=623547089&amp;bvid=BV1Jt4y1o7TY&amp;cid=1402072759&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
      </li>
    </ul>
  </li>
  <li>用引导图控制布局的例子:
    <ul>
      <li>
        <iframe src="//player.bilibili.com/player.html?aid=1300455401&amp;bvid=BV1au4m1K7p4&amp;cid=1431479600&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
      </li>
    </ul>
  </li>
</ul>

<h3 id="注意事项">注意事项</h3>

<ul>
  <li>白色是想要网络生成的部分</li>
  <li>如果在一个工作流里同时用SAM, foocus inpaint, ipadapter等模型, 我16G的显存会不够用: 其实SAM在生成mask之后就可以移出显存了, 但是不清楚comfyui怎么操作</li>
</ul>

<h2 id="reference">reference</h2>
<p><span id="ref"></span></p>

<p>[1] https://github.com/Sanster/IOPaint inpaint+outpaint合集</p>

<p>[2] https://github.com/comfyanonymous/ComfyUI/blob/master/nodes.py#L331 ComfyUI 节点代码</p>

<p>[3] https://medium.com/gliacloud/removing-any-object-from-your-photo-with-lama-7e966765fadc lama实际使用感受</p>

<p>[4] https://huggingface.co/blog/TimothyAlexisVass/explaining-the-sdxl-latent-space sdxl的latent image的解释. sdxl的latent image和原图像素对应.</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="ComfyUI" /><category term="sdxl" /><category term="inpaint" /><summary type="html"><![CDATA[用SAM抠图]]></summary></entry><entry><title type="html">photoshop: 酸性风格海报</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/photoshop1/" rel="alternate" type="text/html" title="photoshop: 酸性风格海报" /><published>2024-02-14T00:00:00+00:00</published><updated>2024-02-19T00:21:24+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/photoshop1</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/photoshop1/"><![CDATA[<p><a href="https://aesthetics.fandom.com/wiki/Acid_Design">酸性(acid)风格</a> 迷幻感 . 设计元素包含: 高饱和, 流动性, 未来复古元素, 格纹, 镭射金属, 霓虹色. 
<a href="https://www.bilibili.com/video/BV1gD4y127m1/">这个链接解释的比较详细</a></p>

<h2 id="制作液态效果-流动感-金属感">制作液态效果, 流动感, 金属感</h2>

<p>在网上看到的两个简易教程$\downarrow$</p>
<ol>
  <li>物体只保留纹理
    <ol>
      <li>选取素材变成gray image: 图像-&gt; 调整 -&gt; 黑白</li>
    </ol>
  </li>
  <li>制作物体中间类似流动金属的效果
    <ol>
      <li>教程1的做法:
        <ol>
          <li>复制物体</li>
          <li>gaussian滤波
            <ul>
              <li>不想有显得特别不光滑的地方</li>
            </ul>
          </li>
          <li>反色</li>
          <li>下层用铬黄渐变, 细节,平滑度调到最高</li>
          <li>上层混合模式改成正片叠底(multiply): $I_1*I_2$
            <ul>
              <li>保留原物体的细节</li>
            </ul>
          </li>
          <li>上下两个图层合并</li>
          <li>混合模式改为滤色(screen): 是$clip(I_1+I_2,0,1)$ 吗? 因为看到结果有全白部分
            <ul>
              <li>仿玻璃的质感: 透明, 并比原图层亮</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>教程2的做法:
        <ol>
          <li>复制物体</li>
          <li>上层反色, 用差值模式(difference): $abs(I_1-I_2)$
            <ul>
              <li>这个结果是越偏离中间值128的像素越亮</li>
            </ul>
          </li>
          <li>上下两个图层合并</li>
          <li>重复2-3次
            <ul>
              <li>这个的结果可能是在0-255范围内设置了几个量化点, 越靠近其中一个点就会越亮
                <ul>
                  <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240218142334.png" alt="Pasted image 20240218142334.png" width="400" /></li>
                  <li>所以完全可以直接拉曲线的. 步骤1-4都有点多余. 只要有那种相近的地方明暗变化很快的感觉就可以了.</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>用曲线压缩动态范围</li>
          <li>把一个金属色流动的背景叠加(overlay)在上层
            <ul>
              <li>overlay是screen和multiply的混合</li>
            </ul>
          </li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

<p><a href="https://www.bilibili.com/video/BV18w411B75n/">教程1</a> : <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240217233149.png" alt="Pasted image 20240217233149.png" width="300" />   <a href="https://www.bilibili.com/video/BV1684y1T7t6/">教程2</a> : <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240218102040.png" alt="Pasted image 20240218102040.png" width="300" /></p>

<ul>
  <li>这两个教程看起来都有点随便, 顶多算一种特殊效果滤镜.
    <ul>
      <li>看起来具体的步骤并不重要. 因为里面确实有些操作意义不明可以简化, 奇怪的不是教程里绕了弯路, 而是不明白每一步的动机. 难道是随便试了试发现这样可以?</li>
    </ul>
  </li>
  <li>在<a href="https://www.bilibili.com/video/BV18w411B75n/">教程1</a> 里用铬黄渐变的filter制作金属感,  <a href="https://www.bilibili.com/video/BV1684y1T7t6/">教程2</a> 更是直接叠了一个金属色的图
    <ul>
      <li><a href="https://www.youtube.com/watch?v=RHgT4Q4dDY8">这个教程</a> 很详细的用bevel(倒角)和emboss(浮雕) 制作金属反光效果. 铬黄渐变的滤镜可能也是类似原理的一组滤镜?</li>
    </ul>
  </li>
  <li>photoshop的blending mode有些模式找不到公式…感觉很难理解用法
    <ul>
      <li>比如overlay和screen…</li>
    </ul>
  </li>
</ul>

<h2 id="reference">reference</h2>

<p>[1] http://pigs-blood-cake.blogspot.com/p/photoshop.html ps中英文对照</p>

<p>[2] https://photoshoptrainingchannel.com/blending-modes-explained/#multiply ps图层混合</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="photoshop" /><category term="filter" /><category term="design" /><summary type="html"><![CDATA[酸性(acid)风格 迷幻感 . 设计元素包含: 高饱和, 流动性, 未来复古元素, 格纹, 镭射金属, 霓虹色. 这个链接解释的比较详细]]></summary></entry><entry><title type="html">blender学习: 玻璃杯</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6/" rel="alternate" type="text/html" title="blender学习: 玻璃杯" /><published>2024-02-10T00:00:00+00:00</published><updated>2024-03-07T01:15:02+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6/"><![CDATA[<p>由cylinder变形得到水杯. 用cycles渲染玻璃材质.</p>
<h2 id="步骤">步骤</h2>

<p>参考<a href="https://www.bilibili.com/video/BV1Fg4y127c7/">这个b站的教学视频</a></p>

<ul>
  <li>制作水杯:
    <ol>
      <li>添加一个cylinder</li>
      <li>删除上下两个底: 在Edit Mode, 开启透视, 按3选中面删除</li>
      <li>把下底缩小一点: 按1选中顶点</li>
      <li>填充底面: 用Ctrl+F填充, 选择<a href="https://docs.blender.org/manual/en/latest/modeling/meshes/editing/face/grid_fill.html">Grid Fill</a>, 调节Offset
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212082748.png" alt="Pasted image 20240212082748.png" width="100" /></li>
        </ul>
      </li>
      <li>做出玻璃杯的厚度: 选中上面的顶点, 用E+S向内
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212082705.png" alt="Pasted image 20240212082705.png" width="100" /></li>
        </ul>
      </li>
      <li>做出玻璃杯的内层: 继续E+Y向下, S向内</li>
      <li>做出玻璃杯的内底: Ctrl+F填充, 选择<a href="https://docs.blender.org/manual/en/latest/modeling/meshes/editing/face/grid_fill.html">Grid Fill</a> , 调节Offset</li>
      <li>把杯子变光滑:
        <ol>
          <li>在边缘处添加loop cut(卡线): Ctrl+R 增加loop cut, Ctrl+B向上下拉伸
            <ul>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212133706.png" alt="Pasted image 20240212133706.png" width="100" /></li>
              <li>添加loop cut是为了之后把杯子边缘变成弧形, 而不影响杯壁和杯底平的部分</li>
            </ul>
          </li>
          <li>Shift+option 长按出现选项, 选中loop, 按G移动loop进行微调
            <ol>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212141056.png" alt="Pasted image 20240212141056.png" width="100" /></li>
            </ol>
          </li>
        </ol>
      </li>
      <li>改成shade smooth</li>
      <li>加一个subdivision modifier</li>
    </ol>
  </li>
  <li>制作拍摄场景:
    <ol>
      <li>添加一个plane mesh</li>
      <li>在Edit Mode选中一个边, E+Z复制一份, 向上拉
        <ol>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212141942.png" alt="Pasted image 20240212141942.png" width="100" /></li>
        </ol>
      </li>
      <li>选中中间的edge, 拉成弧线: Shift+Option选中, Ctrl+B拉伸, 按S改变段数
        <ol>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212142443.png" alt="Pasted image 20240212142443.png" width="150" /></li>
        </ol>
      </li>
      <li>选择shade smooth</li>
    </ol>
  </li>
  <li>打光
    <ul>
      <li>一个area light做主光, 另一个area light做辅光: 形状调节成disk
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212143950.png" alt="Pasted image 20240212143950.png" width="150" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212152018.png" alt="Pasted image 20240212152018.png" width="130" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>shader:
    <ul>
      <li>cycles的做法:
        <ul>
          <li>用Refraction和Glossy混合</li>
          <li>用<a href="https://docs.blender.org/manual/en/4.0/render/shader_nodes/input/fresnel.html">Fresnel node</a> 调节折射和反射的比例</li>
          <li>设置IOR(折射率)为1.52</li>
          <li>设置粗糙度为0</li>
        </ul>
      </li>
      <li>eevee的做法: <a href="https://www.bilibili.com/video/BV1Fe411Y7oY/">参考这个教程</a>
        <ul>
          <li>用glass BSDF和Transparent BSDF混合
            <ul>
              <li>设置IOR(折射率)为1.52</li>
              <li>设置粗糙度为0</li>
            </ul>
          </li>
          <li>MixShader的混合参数固定0.5</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>render:
    <ul>
      <li>cycles的参数:
        <ul>
          <li>把light Paths调成Full Global Illumation: 即所有反射次数为32</li>
        </ul>
      </li>
      <li>eevee的参数:
        <ul>
          <li>打开render-&gt;Screen Space Reflections-&gt;refraction</li>
          <li>打开玻璃杯的material-&gt;Screen Space Refraction选项</li>
          <li>把material的Blend Mode和Shadow Mode都改成Alpha Hashed</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>结果:
    <ul>
      <li>cycles: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212152142.png" alt="Pasted image 20240212152142.png" width="400" />  eevee: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240306170629.png" alt="Pasted image 20240306170629.png" width="360" /></li>
    </ul>
  </li>
</ul>

<h2 id="用到的blender的一些快捷键功能">用到的blender的一些快捷键功能</h2>

<ul>
  <li>G/R/S (移动/旋转/放缩) 按了之后会提示方向快捷键</li>
  <li>E (<a href="https://docs.blender.org/manual/en/2.80/modeling/meshes/editing/duplicating/extrude.html">Extrude</a>, 挤出): 保持原顶点不变, 复制一份, 复制的和原来的用edge连接
    <ul>
      <li>selected face: <img src="https://docs.blender.org/manual/en/2.80/_images/modeling_meshes_editing_duplicating_extrude_face-before.png" alt="drawing" width="150" />  During extrude:  <img src="https://docs.blender.org/manual/en/2.80/_images/modeling_meshes_editing_duplicating_extrude_face-after.png" alt="drawing" width="150" />  </li>
    </ul>
  </li>
  <li><a href="https://docs.blender.org/manual/en/latest/modeling/meshes/tools/loop.html">Loop Cut</a>(卡线): 在edge中间添新的顶点
    <ul>
      <li>添加loop cut: Ctrl+R</li>
      <li>选中已有的loop cut: Shift+Option+长按</li>
    </ul>
  </li>
  <li>Ctrl+B( <a href="https://docs.blender.org/manual/en/2.81/modeling/meshes/editing/subdividing/bevel.html#:~:text=The%20Bevel%20tool%20smooths%20the,above%20to%20run%20the%20tool.">Bevel</a>, 拉伸, 倒角): 把一个edge变成多个edge, 使物体边缘光滑
    <ul>
      <li><img src="https://docs.blender.org/manual/zh-hans/2.81/_images/modeling_meshes_editing_subdividing_bevel_example-4.png" alt="drawing" width="150" /></li>
      <li>按S可以改变段数</li>
    </ul>
  </li>
  <li>Edit Mode 1/2/3 (选vertex, edge, face)</li>
</ul>

<h2 id="frensel反射系数">Frensel反射系数</h2>

<p>Frensel node确定折射和反射比例, 从blender的参数看, 受IOR(折射率)和平面法向的影响</p>

<ul>
  <li>推导:
    <ul>
      <li>根据<a href="https://en.wikipedia.org/wiki/Fresnel_equations">Fresnel equation</a> 的dielectric(绝缘体)的版本: $R=0.5*(r_{\perp}^2+r_{\parallel}^2)$
        <ul>
          <li>其中: $r_{\perp}=\frac{n_i\cos\theta_i-n_t\cos\theta_t}{n_i\cos\theta_i+n_t\cos\theta_t}$  , $r_{\parallel}=\frac{n_t\cos\theta_i-n_i\cos\theta_t}{n_t\cos\theta_i+n_i\cos\theta_t}$
            <ul>
              <li>$n_i$ 是入射介质(即空气=1)的折射率</li>
              <li>$n_t$ 是传播介质(即玻璃=1.52)的折射率</li>
              <li>$\cos\theta_i=(n\cdot w_o)$ 表示平面法向和观察方向的夹角：观察方向越平行于平面，$\theta_i$ 越大，折射越少, 反射越强
                <ul>
                  <li>pathtracing的方法里, 观察方向就是入射方向</li>
                </ul>
              </li>
              <li>$\cos\theta_t$ 表示平面法向和传播方向的夹角, 根据<a href="https://en.wikipedia.org/wiki/Snell%27s_law">Snell’s law</a>: $\frac{\sin\theta_t}{\sin\theta_i}=\frac{n_i}{n_t}=\frac{1}{\eta}$
                <ul>
                  <li>$\eta=n_t/n_i$ : ratio of IOR, 正面是$n$, 反面是$1/n$</li>
                  <li>则$\cos\theta_t=\sqrt{1-\sin^2\theta_t}=\sqrt{1-\frac{1}{\eta^2}(1-\cos^2\theta_i)}=\frac{1}{\eta}\sqrt{\eta^2-1+\cos^2\theta_i}$</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>代码中的表达方式:
  \(\begin{align}R &amp;=0.5*((\frac{n_i\cos\theta_i-n_t\cos\theta_t}{n_i\cos\theta_i+n_t\cos\theta_t})^2+(\frac{n_t\cos\theta_i-n_i\cos\theta_t}{n_t\cos\theta_i+n_i\cos\theta_t})^2)\\\\ &amp;=0.5*((\frac{\cos\theta_i-\eta\cos\theta_t}{\cos\theta_i+\eta\cos\theta_t})^2+(\frac{\eta\cos\theta_i-\cos\theta_t}{\eta\cos\theta_i+\cos\theta_t})^2)\; (\eta=n_t/n_i\text{是ratio of IOR, 正面是n, 反面是1/n)}\\\\ &amp;=0.5*((\frac{c-g}{c+g})^2+(\frac{\eta^2c-g}{\eta^2c+g})^2)\;\; (\text{让 }c=\cos\theta_i,\  g=\sqrt{\eta^2-1+\cos^2\theta}=\eta\cos\theta_t, \text{ 这步已经足够化简了, 为什么要把}\eta\text{完全替换掉呢?})\\\\ &amp;=0.5*((\frac{c-g}{c+g})^2+(\frac{(1+g^2-c^2)c-g}{(1+g^2-c^2)c+g})^2)\;\; (\text{根据 }\eta^2=1+g^2-c^2)\\\\  &amp;=0.5*((\frac{c-g}{c+g})^2+(\frac{c-g}{c+g})^2(\frac{1-c(c+g)}{1+c(g-c)})^2)\\\\  &amp;=0.5*(A^2+A^2B^2)=0.5*A^2(1+B^2)\;\; (\text{让 }A=\frac{g-c}{g+c}, B=\frac{c(g+c)-1}{c(g-c)+1})\end{align}\)</li>
    </ul>
  </li>
  <li>blender代码:
    <ul>
      <li><a href="https://projects.blender.org/blender/cycles/src/branch/main/src/kernel/osl/shaders/node_fresnel.osl">cycles/node_fresnel.osl at main</a></li>
      <li><a href="https://projects.blender.org/blender/cycles/src/branch/main/src/kernel/osl/shaders/node_fresnel.h">cycles/node_fresnel.h at main</a></li>
    </ul>
  </li>
</ul>

<h2 id="reference">reference</h2>
<p><span id="ref"></span></p>

<p>[1] https://seblagarde.wordpress.com/2013/04/29/memo-on-fresnel-equations/ 一些版本的公式推导和reference</p>

<p>[2] https://blenderartists.org/t/whats-the-math-behind-fresnel-node/1502809/11 Fensel node讨论</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="shader" /><category term="3d_model" /><category term="shortcut" /><summary type="html"><![CDATA[由cylinder变形得到水杯. 用cycles渲染玻璃材质. 步骤]]></summary></entry></feed>