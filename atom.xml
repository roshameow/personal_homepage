<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://roshameow.github.io//personal_homepage/atom.xml" rel="self" type="application/atom+xml" /><link href="https://roshameow.github.io//personal_homepage/" rel="alternate" type="text/html" /><updated>2024-02-15T17:01:15+00:00</updated><id>https://roshameow.github.io//personal_homepage/atom.xml</id><title type="html">Liu, Wen’s Home Page</title><subtitle>Work, Experiments and Ideas.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><entry><title type="html">photoshop: 酸性海报</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/photoshop-sore/" rel="alternate" type="text/html" title="photoshop: 酸性海报" /><published>2024-02-14T00:00:00+00:00</published><updated>2024-02-16T08:57:10+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/photoshop-sore</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/photoshop-sore/"><![CDATA[]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">blender学习: 玻璃杯</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6/" rel="alternate" type="text/html" title="blender学习: 玻璃杯" /><published>2024-02-10T00:00:00+00:00</published><updated>2024-02-16T08:39:36+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning6/"><![CDATA[<p>由cylinder变形得到水杯. 用cycles渲染玻璃材质.</p>
<h2 id="步骤">步骤</h2>

<p>参考<a href="https://www.bilibili.com/video/BV1Fg4y127c7/">这个b站的教学视频</a></p>

<ul>
  <li>制作水杯:
    <ol>
      <li>添加一个cylinder</li>
      <li>删除上下两个底: 在Edit Mode, 开启透视, 按3选中面删除</li>
      <li>把下底缩小一点: 按1选中顶点</li>
      <li>填充底面: 用Ctrl+F填充, 选择<a href="https://docs.blender.org/manual/en/latest/modeling/meshes/editing/face/grid_fill.html">Grid Fill</a>, 调节Offset
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212082748.png" alt="Pasted image 20240212082748.png" width="100" /></li>
        </ul>
      </li>
      <li>做出玻璃杯的厚度: 选中上面的顶点, 用E+S向内
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212082705.png" alt="Pasted image 20240212082705.png" width="100" /></li>
        </ul>
      </li>
      <li>做出玻璃杯的内层: 继续E+Y向下, S向内</li>
      <li>做出玻璃杯的内底: Ctrl+F填充, 选择<a href="https://docs.blender.org/manual/en/latest/modeling/meshes/editing/face/grid_fill.html">Grid Fill</a> , 调节Offset</li>
      <li>把杯子变光滑:
        <ol>
          <li>在边缘处添加loop cut(卡线): Ctrl+R 增加loop cut, Ctrl+B向上下拉伸
            <ul>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212133706.png" alt="Pasted image 20240212133706.png" width="100" /></li>
              <li>添加loop cut是为了之后把杯子边缘变成弧形, 而不影响杯壁和杯底平的部分</li>
            </ul>
          </li>
          <li>Shift+option 长按出现选项, 选中loop, 按G移动loop进行微调
            <ol>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212141056.png" alt="Pasted image 20240212141056.png" width="100" /></li>
            </ol>
          </li>
        </ol>
      </li>
      <li>改成shade smooth</li>
      <li>加一个subdivision modifier</li>
    </ol>
  </li>
  <li>制作拍摄场景:
    <ol>
      <li>添加一个plane mesh</li>
      <li>在Edit Mode选中一个边, E+Z复制一份, 向上拉
        <ol>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212141942.png" alt="Pasted image 20240212141942.png" width="100" /></li>
        </ol>
      </li>
      <li>选中中间的edge, 拉成弧线: Shift+Option选中, Ctrl+B拉伸, 按S改变段数
        <ol>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212142443.png" alt="Pasted image 20240212142443.png" width="150" /></li>
        </ol>
      </li>
      <li>选择shade smooth</li>
    </ol>
  </li>
  <li>打光
    <ul>
      <li>一个area light做主光, 另一个area light做辅光: 形状调节成disk
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212143950.png" alt="Pasted image 20240212143950.png" width="150" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212152018.png" alt="Pasted image 20240212152018.png" width="130" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>shader:
    <ul>
      <li>用Refraction和Glossy混合</li>
      <li>用<a href="https://docs.blender.org/manual/en/4.0/render/shader_nodes/input/fresnel.html">Fresnel node</a> 调节折射和反射的比例</li>
      <li>设置IOR(折射率)为1.52</li>
      <li>设置粗糙度为0</li>
    </ul>
  </li>
  <li>render:
    <ul>
      <li>用cycles, 把light Paths调成Full Global Illumation: 即所有反射次数为32</li>
    </ul>
  </li>
  <li>结果:
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240212152142.png" alt="Pasted image 20240212152142.png" width="400" /></li>
    </ul>
  </li>
</ul>

<h2 id="用到的blender的一些快捷键功能">用到的blender的一些快捷键功能</h2>

<ul>
  <li>G/R/S (移动/旋转/放缩) 按了之后会提示方向快捷键</li>
  <li>E (<a href="https://docs.blender.org/manual/en/2.80/modeling/meshes/editing/duplicating/extrude.html">Extrude</a>, 挤出): 保持原顶点不变, 复制一份, 复制的和原来的用edge连接
    <ul>
      <li>selected face: <img src="https://docs.blender.org/manual/en/2.80/_images/modeling_meshes_editing_duplicating_extrude_face-before.png" alt="drawing" width="150" />  During extrude:  <img src="https://docs.blender.org/manual/en/2.80/_images/modeling_meshes_editing_duplicating_extrude_face-after.png" alt="drawing" width="150" />  </li>
    </ul>
  </li>
  <li><a href="https://docs.blender.org/manual/en/latest/modeling/meshes/tools/loop.html">Loop Cut</a>(卡线): 在edge中间添新的顶点
    <ul>
      <li>添加loop cut: Ctrl+R</li>
      <li>选中已有的loop cut: Shift+Option+长按</li>
    </ul>
  </li>
  <li>Ctrl+B( <a href="https://docs.blender.org/manual/en/2.81/modeling/meshes/editing/subdividing/bevel.html#:~:text=The%20Bevel%20tool%20smooths%20the,above%20to%20run%20the%20tool.">Bevel</a>, 拉伸, 倒角): 把一个edge变成多个edge, 使物体边缘光滑
    <ul>
      <li><img src="https://docs.blender.org/manual/zh-hans/2.81/_images/modeling_meshes_editing_subdividing_bevel_example-4.png" alt="drawing" width="150" /></li>
      <li>按S可以改变段数</li>
    </ul>
  </li>
  <li>Edit Mode 1/2/3 (选vertex, edge, face)</li>
</ul>

<h2 id="frensel反射系数">Frensel反射系数</h2>

<p>Frensel node确定折射和反射比例, 从blender的参数看, 受IOR(折射率)和平面法向的影响</p>

<ul>
  <li>推导:
    <ul>
      <li>根据<a href="https://en.wikipedia.org/wiki/Fresnel_equations">Fresnel equation</a> 的dielectric(绝缘体)的版本: $R=0.5*(r_{\perp}^2+r_{\parallel}^2)$
        <ul>
          <li>其中: $r_{\perp}=\frac{n_i\cos\theta_i-n_t\cos\theta_t}{n_i\cos\theta_i+n_t\cos\theta_t}$  , $r_{\parallel}=\frac{n_t\cos\theta_i-n_i\cos\theta_t}{n_t\cos\theta_i+n_i\cos\theta_t}$
            <ul>
              <li>$n_i$ 是入射介质(即空气=1)的折射率</li>
              <li>$n_t$ 是传播介质(即玻璃=1.52)的折射率</li>
              <li>$\cos\theta_i=(n\cdot w_o)$ 表示平面法向和观察方向的夹角：观察方向越平行于平面，$\theta_i$ 越大，折射越少, 反射越强
                <ul>
                  <li>pathtracing的方法里, 观察方向就是入射方向</li>
                </ul>
              </li>
              <li>$\cos\theta_t$ 表示平面法向和传播方向的夹角, 根据<a href="https://en.wikipedia.org/wiki/Snell%27s_law">Snell’s law</a>: $\frac{\sin\theta_t}{\sin\theta_i}=\frac{n_i}{n_t}=\frac{1}{\eta}$
                <ul>
                  <li>$\eta=n_t/n_i$ : ratio of IOR, 正面是$n$, 反面是$1/n$</li>
                  <li>则$\cos\theta_t=\sqrt{1-\sin^2\theta_t}=\sqrt{1-\frac{1}{\eta^2}(1-\cos^2\theta_i)}=\frac{1}{\eta}\sqrt{\eta^2-1+\cos^2\theta_i}$</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>代码中的表达方式:
  \(\begin{align}R &amp;=0.5*((\frac{n_i\cos\theta_i-n_t\cos\theta_t}{n_i\cos\theta_i+n_t\cos\theta_t})^2+(\frac{n_t\cos\theta_i-n_i\cos\theta_t}{n_t\cos\theta_i+n_i\cos\theta_t})^2)\\\\ &amp;=0.5*((\frac{\cos\theta_i-\eta\cos\theta_t}{\cos\theta_i+\eta\cos\theta_t})^2+(\frac{\eta\cos\theta_i-\cos\theta_t}{\eta\cos\theta_i+\cos\theta_t})^2)\; (\eta=n_t/n_i\text{是ratio of IOR, 正面是n, 反面是1/n)}\\\\ &amp;=0.5*((\frac{c-g}{c+g})^2+(\frac{\eta^2c-g}{\eta^2c+g})^2)\;\; (\text{让 }c=\cos\theta_i,\  g=\sqrt{\eta^2-1+\cos^2\theta}=\eta\cos\theta_t)\\\\ &amp;=0.5*((\frac{c-g}{c+g})^2+(\frac{(1+g^2-c^2)c-g}{(1+g^2-c^2)c+g})^2)\;\; (\text{根据 }\eta^2=1+g^2-c^2)\\\\  &amp;=0.5*((\frac{c-g}{c+g})^2+(\frac{c-g}{c+g})^2(\frac{1-c(c+g)}{1+c(g-c)})^2)\\\\  &amp;=0.5*(A^2+A^2B^2)=0.5*A^2(1+B^2)\;\; (\text{让 }A=\frac{g-c}{g+c}, B=\frac{c(g+c)-1}{c(g-c)+1})\end{align}\)</li>
    </ul>
  </li>
  <li>blender代码:
    <ul>
      <li><a href="https://projects.blender.org/blender/cycles/src/branch/main/src/kernel/osl/shaders/node_fresnel.osl">cycles/node_fresnel.osl at main</a></li>
      <li><a href="https://projects.blender.org/blender/cycles/src/branch/main/src/kernel/osl/shaders/node_fresnel.h">cycles/node_fresnel.h at main</a></li>
    </ul>
  </li>
</ul>

<h2 id="reference">reference</h2>
<p><span id="ref"></span></p>

<p>[1] https://seblagarde.wordpress.com/2013/04/29/memo-on-fresnel-equations/ 一些版本的公式推导和reference</p>

<p>[2] https://blenderartists.org/t/whats-the-math-behind-fresnel-node/1502809/11 Fensel node讨论</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="shader" /><category term="3d_model" /><category term="shortcut" /><summary type="html"><![CDATA[由cylinder变形得到水杯. 用cycles渲染玻璃材质. 步骤]]></summary></entry><entry><title type="html">stable-diffusion的用法: 用 lora+controlnet做风格转换</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion2/" rel="alternate" type="text/html" title="stable-diffusion的用法: 用 lora+controlnet做风格转换" /><published>2024-02-09T00:00:00+00:00</published><updated>2024-02-16T01:38:07+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion2</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion2/"><![CDATA[<p>尝试只用ipadapter做猫的风格转换, 非常不成功, ipadapter还是无法控制输入的元素. 必须要用多张图片训练的LoRA控制. 
另外, 猫脸上颜色分布的特征, 没有controlnet可以直接表示.</p>

<h2 id="comfyui步骤">ComfyUI步骤</h2>

<ol>
  <li><strong>训练Lora</strong>
    <ul>
      <li>用<a href="https://github.com/bmaltais/kohya_ss">kohya_ss</a> 的gui训练
        <ul>
          <li>network rank设置64</li>
          <li>打开Gradient checkpoint, 不然我16G的显存不够用</li>
          <li>另外, 我的wsl2需要解决一下找不到cuda toolkit的问题
            <ul>
              <li>检查发现是ubuntu的requirement里面指定的torch和bitsandbytes版本不匹配</li>
              <li>在虚拟环境里, 升级到最新版2.2后代码又出问题</li>
              <li>最后参考windows版本的requirement.txt, 改成torch=2.1.0+cu118解决了</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>连上Lora节点</strong>
    <ul>
      <li>ComfyUI里连接顺序是: Checkpoint: model, clip -&gt; Lora</li>
      <li>多个Lora顺序连接就行</li>
      <li>ip的lora的weigt设为1.22, 风格化lora的weight不用设那么大</li>
    </ul>
  </li>
  <li><strong>写text prompt</strong>
    <ul>
      <li>写了包括描述内容的, lora配套的, 描述想要风格的positive prompt</li>
    </ul>
  </li>
  <li><strong>连上Controlnet节点</strong>
    <ul>
      <li>用到了<a href="https://huggingface.co/collections/diffusers/sdxl-controlnets-64f9c35846f3f06f5abe351f">canny模型, depth模型</a>
        <ul>
          <li>下载<a href="https://github.com/kijai/ComfyUI-Marigold">Marigold</a>的深度识别模型节点</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="结果">结果</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240209124721.png" alt="Pasted image 20240209124721.png" width="150" /> -&gt; <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240209124343.png" alt="Pasted image 20240209124343.png" width="600" /></p>

<ul>
  <li><strong>风格:</strong> 3种方法都可以
    <ol>
      <li>text prompt里输入</li>
      <li>风格LoRA
        <ul>
          <li>在prompt也要加上对应风格关键词</li>
        </ul>
      </li>
      <li>用ipadpter输入风格图片控制
        <ul>
          <li>ipadpter的weight需要调整: 不能太低(风格化没用), 也不能太高(和风格图太像)</li>
          <li>一直有和风格图太像, 或者风格图提供我们不想要元素的风险…毕竟一张图片的信息不像文字和lora那样有明确的指向性</li>
          <li>我用的不是换脸模型, 但是模型好像特别执着于换脸? 的确模型本来的目的是换ip…</li>
        </ul>
      </li>
    </ol>
  </li>
  <li><strong>控制:</strong>
    <ul>
      <li>用canny或depth模型都能做到控制猫的位置
        <ul>
          <li>Marigold的识别特别慢, 尝试的时候计算完深度图要先把那个节点断开</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>问题:</strong>
    <ul>
      <li>有些风格单独可以出图, 但是加了我训练的猫的LoRA就没法出对应风格的图了</li>
      <li>用LoRA训练的模型没有完全理解我的猫的所有特征: 尤其是鼻子和嘴附近的毛色
        <ul>
          <li>我用了30多张照片, 也没有改label的caption, 所以可能还有质量增加的空间</li>
        </ul>
      </li>
      <li>用ipadpter的失败经验:
        <ul>
          <li>如果用一张猫的图片和一张风格图
            <ul>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240209133511.png" alt="Pasted image 20240209133511.png" width="100" /></li>
              <li>无法控制输入元素</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="comfyui-workflow">ComfyUI workflow</h2>

<p>用Lora调整风格$\downarrow$ : <a href="https://gist.github.com/roshameow/d952bf0157a25ab3e9e724df1449b160#file-rosha_lora_controlnet_canny_depth_style_change-json"><strong>rosha_lora_controlnet_canny_depth_style_change.json</strong></a></p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-08%20230728.png" alt="屏幕截图 2024-02-08 230728.png" width="800" /></p>

<p>用ipadator调整风格$\downarrow$ : <a href="https://gist.github.com/roshameow/d952bf0157a25ab3e9e724df1449b160#file-rosha_lora_ipadapter_style_tranformation-json"><strong>rosha_lora_ipadapter_style_tranformation.json</strong></a></p>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240209135354.png" alt="Pasted image 20240209135354.png" width="800" /></p>

<h2 id="资源">资源</h2>

<p>艺术风格prompt:</p>

<p>[1] https://medium.com/phygital/top-40-useful-prompts-for-stable-diffusion-xl-008c03dd0557</p>

<p>[2] https://docs.midjourney.com/docs/explore-prompting</p>

<p>[3] https://www.urania.ai/top-sd-artists</p>

<p>[4] https://github.com/SupaGruen/StableDiffusion-CheatSheet 是v1.5插件</p>

<p>Lora训练:</p>

<p>[5]  <a href="https://www.youtube.com/watch?v=NaHtI0u3Am4">https://www.youtube.com/watch?v=NaHtI0u3Am4</a> kohya_ss的参数设置,</p>

<p>[6] https://zhuanlan.zhihu.com/p/654322145.   下面讨论说optimizer还是默认比较好?</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="ComfyUI" /><category term="ipadapter" /><category term="controlnet" /><category term="canny" /><category term="sdxl" /><summary type="html"><![CDATA[尝试只用ipadapter做猫的风格转换, 非常不成功, ipadapter还是无法控制输入的元素. 必须要用多张图片训练的LoRA控制. 另外, 猫脸上颜色分布的特征, 没有controlnet可以直接表示.]]></summary></entry><entry><title type="html">blender学习: 做火焰效果</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning5/" rel="alternate" type="text/html" title="blender学习: 做火焰效果" /><published>2024-02-08T00:00:00+00:00</published><updated>2024-02-12T03:33:52+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning5</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning5/"><![CDATA[<p>火焰的形状用圆形变形一半获得. 用<a href="https://en.wikipedia.org/wiki/Perlin_noise">Perlin noise</a>使坐标变形制作随机抖动. 用Emission node渲染发光效果.</p>

<h2 id="用graph-editor和noise-texture---飞行器火焰">用graph editor和noise texture -&gt; 飞行器火焰</h2>
<h3 id="步骤">步骤</h3>

<p>参考RuiHuang_art在<a href="https://www.bilibili.com/video/BV1HH4y1Y7Vv/">b站的教学视频</a> , 和做车流用到的功能差不多</p>
<ul>
  <li>world property: 加入一个背景的贴图</li>
  <li>制做一个平面的火焰:
    <ul>
      <li>添加一个Plane mesh</li>
      <li>分成两半: 在Edit编辑模式下, 按Ctrl+R加<a href="https://docs.blender.org/manual/en/latest/modeling/meshes/tools/loop.html">loop cut</a> , 在edge中间添加新的顶点,</li>
      <li>把一半拉长: 选中顶点后按G+Y在Y轴拉伸</li>
    </ul>
  </li>
  <li>shader: 目的是制作一个自发光, 半透明, 抖动的效果
    <ul>
      <li>颜色效果:
        <ol>
          <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 生成uv坐标
            <ul>
              <li>在mapping里把x,y的location调到-2, scale调到4</li>
              <li>uv坐标系好像范围是(-scale/2, scale/2)</li>
            </ul>
          </li>
          <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/gradient.html">Gradient Texture</a> 的spherical: 制作从外到内的渐变</li>
          <li>自发光: 用<a href="https://docs.blender.org/manual/en/latest/editors/texture_node/types/converter/color_ramp.html">Color Ramp</a> 做一个 蓝-&gt;白-&gt;红-&gt;黄 的渐变</li>
          <li>调整透明度: 用<a href="https://docs.blender.org/manual/en/latest/editors/texture_node/types/converter/color_ramp.html">Color Ramp</a> 做一个 透明-&gt;半透明-&gt;透明 的渐变</li>
          <li>连接bsdf
            <ul>
              <li>把Emission和transparent bsdf用Mix shader连接在一起</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>抖动效果:
        <ol>
          <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 生成object坐标</li>
          <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/noise.html">Noise Texture</a> 扭曲坐标, 制作抖动效果: noise texture和displacement的cloudy texture效果差不多
            <ul>
              <li>用<a href="https://docs.blender.org/manual/en/latest/compositing/types/color/mix/mix_color.html">Mix Node</a> 的Multiply把两个坐标混合</li>
            </ul>
          </li>
          <li>用<a href="https://docs.blender.org/manual/zh-hans/dev/editors/graph_editor/fcurves/editing.html">Graph Editor</a> 调整mapping的y坐标的location, 形成动态的扭曲</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>把火焰的plane mesh旋转复制出多个绕y轴一圈
    <ul>
      <li>在shader里选中一个materail<a href="https://blender.stackexchange.com/questions/7044/copy-material-to-another-object">复制给所有mesh</a></li>
      <li>复制完想修改所有的mesh形状但是没找到方法</li>
    </ul>
  </li>
  <li>结果: 我复制的次数比较少, 而且颜色也不好看,  形状也拉的不太对
    <ul>
      <li><img src="/personal_homepage/docs/attachment/fire.mp4" alt="fire.mp4" width="320" /></li>
    </ul>
  </li>
</ul>

<h3 id="shader流程">shader流程</h3>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240208164250.png" alt="Pasted image 20240208164250.png" width="600" /></p>

<h2 id="用displacement粒子系统---卡通火焰">用displacement+粒子系统 -&gt; 卡通火焰</h2>
<h3 id="步骤-1">步骤:</h3>

<p>参考小红书<a href="https://www.xiaohongshu.com/explore/658636a9000000003c010c5d">KurTips的教学</a></p>
<ul>
  <li>制作火焰形状
    <ul>
      <li>添加一个cube mesh</li>
      <li>在modifier里加subdivision surface</li>
      <li>在Edit Mode, 打开Propotional Editing(衰减编辑), 选择最上面vertex, 按G+V可以在z轴拉伸</li>
      <li>制作焰心: 复制一个更小的放在前面</li>
      <li>选中两个object, 右键<a href="https://docs.blender.org/manual/en/latest/scene_layout/object/editing/shading.html">shade smooth</a>
        <ul>
          <li>shader计算时, 三角形内的normal vector由三个顶点的normal vector插值得到</li>
        </ul>
      </li>
      <li>合并两个object: <a href="https://docs.blender.org/manual/en/4.2/scene_layout/object/editing/join.html">Ctrl+J</a></li>
    </ul>
  </li>
  <li>shader: 设置<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a>  generate-&gt;Separate XYZ-&gt;Gradient Texture-&gt;ColorRamp-&gt; Emission
    <ul>
      <li>把大小两块用不同的材质
        <ul>
          <li>进入Edit Mode, 随便选中一个点, Ctrl+L可以把原本的大小两个object分别选中</li>
          <li>在Material添加材质</li>
        </ul>
      </li>
      <li>ColorRamp颜色: 外焰: 红-&gt;黄 ; 焰心: 红-&gt;橙红</li>
    </ul>
  </li>
  <li>抖动效果: 用displacement实现
    <ol>
      <li>在Modifier添加displace: 选Clouds材质, 调整Size, Depth=1, displacement的Stength</li>
      <li>让displacement的强度从上到下渐变: 用顶点组实现
        <ol>
          <li>定义顶点组: 在Edit Mode开透视模式, 选中上面一部分顶点; 在Oject的Data里添加vetex group, 把刚才选中的部分顶点assign给这个顶点组</li>
          <li>在<a href="https://docs.blender.org/manual/en/latest/sculpt_paint/weight_paint/index.html">Weight Paint</a>模式, 增加weight-&gt;<a href="https://docs.blender.org/manual/en/2.79/sculpt_paint/painting/weight_paint/weight_tools.html">smooth-&gt;iteration</a>: 让 in Vertex Group-&gt; outside Vertex Group 的渐变更光滑
            <ul>
              <li>smooth操作的每个iteration都是和邻域的顶点做平滑</li>
            </ul>
          </li>
          <li>在displace的vertex group选择顶点组</li>
        </ol>
      </li>
      <li>制作displacement的动态: 通过绑定一个空坐标轴实现
        <ol>
          <li>在displace的Coordinates选择object, 物体选择我们的空坐标轴</li>
          <li>修改空坐标轴的Oject-&gt;Transform的z轴的值, 改为: <code class="language-plaintext highlighter-rouge">#frame/100(帧数/100)</code>
            <ul>
              <li>这样做比用<a href="https://docs.blender.org/manual/zh-hans/dev/editors/graph_editor/fcurves/editing.html">Graph Editor</a> 方便不少👍</li>
            </ul>
          </li>
        </ol>
      </li>
    </ol>
  </li>
  <li>制作火星: 用粒子系统
    <ol>
      <li>在火焰里添加一个圆环mesh</li>
      <li>进入Edit Mode, 填充: 快捷键F</li>
      <li>修改Particles参数:
        <ul>
          <li>Field Weight-&gt; Gravity改为0: 让粒子向上</li>
          <li>Velocity-&gt; normal改为2</li>
          <li>Emission: 调整Frame_start, Frame_end, lifetime(和velocity共同控制粒子移动的距离)</li>
          <li>Physics-&gt; Brownian改为10.5: 让粒子做布朗运动</li>
        </ul>
      </li>
      <li>调整火星材质:
        <ol>
          <li>制作一个多面体mesh, subdivision改成1: 减小计算量</li>
          <li>把多面体的shader改成自发光, 调整color, strength适当增大</li>
          <li><strong>打开eevee渲染器的<a href="https://docs.blender.org/manual/en/latest/render/eevee/render_settings/bloom.html">bloom(辉光)</a> 功能</strong></li>
          <li>制定Particles-&gt;Render参数:
            <ol>
              <li>Render As调成Object模式, Render-&gt;Instance选择我们的制作的多面体mesh</li>
              <li>scale调小, scale Randomness调大: 让粒子大小不一</li>
            </ol>
          </li>
        </ol>
      </li>
    </ol>
  </li>
  <li>结果: 因为焰心的制作方法, 只能在一定角度看.
    <ul>
      <li><img src="/personal_homepage/docs/attachment/fire_cartoon_cut.mp4" alt="fire_cartoon_cut.mp4" width="200" /></li>
    </ul>
  </li>
</ul>

<h2 id="火焰效果的片段">火焰效果的片段</h2>

<p>[1] 冰海战记s2ep5的放火场景</p>

<h2 id="reference">reference</h2>

<p>[1] https://zhuanlan.zhihu.com/p/484222862 辉光效果</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="render" /><category term="shader" /><summary type="html"><![CDATA[火焰的形状用圆形变形一半获得. 用Perlin noise使坐标变形制作随机抖动. 用Emission node渲染发光效果.]]></summary></entry><entry><title type="html">stable-diffusion的用法: 用 ipadatper+controlnet canny做风格转换</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion1/" rel="alternate" type="text/html" title="stable-diffusion的用法: 用 ipadatper+controlnet canny做风格转换" /><published>2024-02-07T00:00:00+00:00</published><updated>2024-02-08T08:58:53+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion1</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/stable-diffusion1/"><![CDATA[<p>用ipadapter和canny做风格转换</p>

<h2 id="comfyui使用">ComfyUI使用</h2>

<ol>
  <li>调用ComfyUI中default的工作流
    <ul>
      <li>下载<a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0">sdxl模型</a></li>
    </ul>
  </li>
  <li><strong>连上IPAdapter节点</strong>
    <ul>
      <li>安装<a href="https://github.com/cubiq/ComfyUI_IPAdapter_plus">IPAdapter_plus插件</a>
        <ul>
          <li>下载需要的ipadater微调模型和clip vision编码器: 把图像用clip vision编码后输入base model的cross-attention层</li>
        </ul>
      </li>
      <li>ComfyUI里连接顺序是: Checkpoint: model-&gt; IPAdapter: model -&gt; KSampler: model</li>
      <li>weigt设为1, text prompt都空着, latent prompt也空着</li>
    </ul>
  </li>
  <li><strong>连上Controlnet节点</strong>
    <ul>
      <li>下载<a href="https://huggingface.co/collections/diffusers/sdxl-controlnets-64f9c35846f3f06f5abe351f">canny模型</a>
        <ul>
          <li><del>找不到其他适合sdxl的controlnet模型</del>因为我们的原图是个线稿适合用canny</li>
        </ul>
      </li>
      <li>ComfyUI里连接顺序是: Checkpoint-&gt;prompt-&gt;controlnet-&gt;Ksampler: text prompt
        <ul>
          <li>controlnet最后是作用在text prompt上的?</li>
        </ul>
      </li>
      <li>调整controlnet权重和影响步数: stength=0.5, start_percent=0, end_percent=0.6
        <ul>
          <li>如果设置过大就只能得到一张有颜色的线稿图</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="结果">结果</h2>

<p>原图: 
<img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-07%20224110.png" alt="屏幕截图 2024-02-07 224110.png" width="600" /> + <img src="/personal_homepage/docs/attachment/2e2b76d160ca4317bb8e095ffd8ff878.jpg.png" alt="2e2b76d160ca4317bb8e095ffd8ff878.jpg.png" width="150" /></p>

<p>合成图: 
<img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-07%20224141.png" alt="屏幕截图 2024-02-07 224141.png" width="600" /></p>

<ul>
  <li>竟然可以识别龙的眼睛啊…有好几幅图都把猫眼替换到了龙眼上
    <ul>
      <li>如果两种图有同样的元素(眼睛之类的), 可能可以比较好的替换</li>
      <li>最后的龙和人, 龙和山, 都不能对应起来</li>
    </ul>
  </li>
  <li>ipadapter没法主动控制合成哪个图像中的哪种元素:
    <ul>
      <li>虽然替换了颜色, 背景, 但是没法替换材质, 笔触</li>
      <li>有几张图还替换了原图的色块分布, 这是我们不想要的</li>
    </ul>
  </li>
  <li>另外, controlnet-canny和ipadapter的龙都不能省略
    <ul>
      <li>如果ipadapter只用风格图:
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240208003655.png" alt="Pasted image 20240208003655.png" width="100" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240208003712.png" alt="Pasted image 20240208003712.png" width="100" /></li>
          <li>增加control-net的权重也是没用的, weight=0.8时出现了噪声图案</li>
        </ul>
      </li>
      <li>如果不加controlnet:
        <ul>
          <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240208003804.png" alt="Pasted image 20240208003804.png" width="100" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240208003819.png" alt="Pasted image 20240208003819.png" width="100" /></li>
        </ul>
      </li>
      <li>看起来controlnet保持了龙的外形结构, ipadpter加龙提高了龙的权重, 不过ipadapter从龙图中究竟学到了什么? 是扁平的画风吗? 只用风格图的情况下, 确实画风更接近风格图, 但是内容也更接近了
        <ul>
          <li>可以通过text prompt控制吗? 但是clip又无法理解简笔画的龙.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="comfyui-workflow">ComfyUI workflow</h2>

<p><a href="https://gist.github.com/roshameow/d952bf0157a25ab3e9e724df1449b160#file-ipadapter_controlnet-canny_loong_style_change-json"><strong>ipadapter_controlnet-canny_loong_style_change.json</strong></a></p>

<p><img src="/personal_homepage/docs/attachment/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-02-07%20224530.png" alt="屏幕截图 2024-02-07 224530.png" width="800" /></p>

<h2 id="comfyui难用的地方">ComfyUI难用的地方</h2>

<ul>
  <li>UI的奇怪地方
    <ul>
      <li>有参数的地方字体相对整个节点特别小, 而且没法调节. 输入text prompt的时候是根本看不清..</li>
      <li>鼠标的十字倒是特别大…</li>
    </ul>
  </li>
  <li>节点连接非常反常识
    <ul>
      <li>load节点
        <ul>
          <li>输入都在右侧, 一般会觉得应该把prompt输入模型</li>
          <li>load节点的存在就很奇怪, 为什么不把load和apply合并到一起? 或者在右侧用菜单栏切换</li>
          <li>model里面还有个model_name? 模型的名字一长全混在一起真的分不清啊…</li>
        </ul>
      </li>
      <li>preview Image节点
        <ul>
          <li>为什么不直接做成一个下拉选项…</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>为什么不能做成一个Chromium内核的本地app..
    <ul>
      <li>据说有一些方法可以打包成一个app?</li>
      <li>凡需要inpaint输入的地方, 输入方式很不方便, 能和其他专门用来绘图的软件结合就好了</li>
    </ul>
  </li>
  <li>虽然如此, 可以用节点和分享工作流就比webui好用太多了</li>
</ul>

<h2 id="其他讨论这个链接">其他讨论这个链接</h2>

<p>[1] https://zhuanlan.zhihu.com/p/664201523 里面介绍了一个换画风的工作流, 不过例子是人像, 可能本身网络对人像的理解能力更强吧?　</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="ComfyUI" /><category term="ipadapter" /><category term="controlnet" /><category term="canny" /><category term="sdxl" /><summary type="html"><![CDATA[用ipadapter和canny做风格转换]]></summary></entry><entry><title type="html">神经网络attention结构理解</title><link href="https://roshameow.github.io//personal_homepage/docs/deeplearning/attention/" rel="alternate" type="text/html" title="神经网络attention结构理解" /><published>2024-02-04T00:00:00+00:00</published><updated>2024-02-08T01:13:42+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/deeplearning/attention</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/deeplearning/attention/"><![CDATA[<p>在网络中, block是把input信息转换成output信息的过程: 一般, output(position, vector)是input(token, embedding vector)的线性组合, 组合的weight (position, token) 由input和output两方关系确定. 把着重强调这种信息交互的模块叫attention.</p>
<h2 id="convolution">convolution</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240207151034.png" alt="Pasted image 20240207151034.png" width="400" /></p>

<p>convolution在神经网络流行之前就已经在图像任务里广泛使用了</p>
<ul>
  <li><strong>目的:</strong>
    <ul>
      <li>对spatial information进行特征的提取和转换</li>
    </ul>
  </li>
  <li><strong>特点:</strong>
    <ul>
      <li>pixel的weight只和(input, output)的相对位置有关, 因此也是平移不变的. 对每个输出像素有影响的只有input里kernel覆盖到的区域, 也就是response field</li>
      <li>每个不同的相对位置对应vector mapping不同
        <ul>
          <li>这个符合图像处理的直观, 左边有条线和右边有条线当然要映射成不同的结果</li>
          <li>有时也会把卷积拆分成1x1 conv和spatial conv(通道无关) 的形式</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="gate-attention">gate attention</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240207151122.png" alt="Pasted image 20240207151122.png" width="400" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240207151136.png" alt="Pasted image 20240207151136.png" width="400" /></p>

<ul>
  <li><strong>目的:</strong>
    <ul>
      <li>提取channel<a href="#ref">1</a>或spatial的权重, 让网络关注更重要的信息</li>
    </ul>
  </li>
  <li><strong>特点:</strong>
    <ul>
      <li>spatial 信息对人类来说更有可读性, 所以可以把spatial weight可视化, 看看图片什么位置更加重要</li>
    </ul>
  </li>
</ul>

<h2 id="self-attention--cross-attention">self-attention &amp; cross-attention</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240207151214.png" alt="Pasted image 20240207151214.png" width="400" /></p>

<ul>
  <li><strong>目的:</strong>
    <ul>
      <li>信息的交互: 在我的图示中, 是把文字信息加入视觉信息</li>
    </ul>
  </li>
  <li><strong>特点:</strong>
    <ul>
      <li>self-attention和cross-attention结构类似, 只是变成了一种输入</li>
      <li>cross-attention是现在常见的把一种信息加入另一种信息的方法
        <ul>
          <li>也用到了图像信息和文字信息的统一形式, 即(position, embedding) , 在图像信息中, position(S=H x W)是像素或patch的位置; 文字信息中, position是token在句中的前后位置</li>
          <li>我们可以对relative weight可视化, 从而知道某个文字token和图像哪个位置最相关</li>
        </ul>
      </li>
      <li>Q,K,V(query, key, value) 的叫法是nlp搜索(匹配)任务的术语, 额, 其实我一直没法对这个望文生义…
        <ul>
          <li>其实从计算过程可以看出, 不管它们的原义, Q, K交换一下也没差</li>
          <li>query和key的embedding channel数应该相同, 为了之后计算他们relation的目的</li>
          <li>和卷积不一样, 放了更大的计算量在交互部分, 相对的, 每个input token对应vector mapping相同, 也就是用”value”部分解决了channel的映射: 这样导致同样的文字信息不论放在前面还是后面, 对应同一种output信息, 区别的只是他们权重可能不同, 或在图像的不同位置</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="attention的一些变形和优化">attention的一些变形和优化</h3>

<ul>
  <li>mulit-head attention: 映射多组QKV, 计算得到的多组output再concat
    <ul>
      <li>在实际实现过程中,  先映射成一个大的QKV, 再把Q, K, V切分是完全等价的</li>
      <li>做mulit-head可以得到多组不同的映射方式, 或减小inner_dimension(T)的大小</li>
    </ul>
  </li>
  <li>分层attention: 在做attention之前对数据排序, 切分
    <ul>
      <li>可能有些pixel之间关联不大, 这样的话把它们分到不同的bucket, 分别做attention, 可以减少计算量<a href="#ref">2</a></li>
    </ul>
  </li>
  <li>多个attention合成:
    <ul>
      <li>在最近流行的ipadapter里面也讨论了多种不同来源的数据在cross-attention 里合成的问题, 结论是分别与原数据做attention最后再合成比较好<a href="#ref">3</a>, 这个也是我们一般naive的想法</li>
    </ul>
  </li>
</ul>

<h2 id="光流估计网络">光流估计网络</h2>

<p>视觉匹配任务</p>

<h2 id="代码">代码</h2>

<p><a href="https://gist.github.com/roshameow/503ec3769d75c47b82f2a7372e8c2dab#file-attention_block-py"><strong>attention_block.py</strong></a></p>

<h2 id="reference">reference</h2>
<p><span id="ref"></span></p>

<p>[1] Woo, Sanghyun, Jongchan Park, Joon-Young Lee, and In So Kweon. “CBAM: Convolutional Block Attention Module.” arXiv, July 18, 2018. <a href="https://doi.org/10.48550/arXiv.1807.06521">https://doi.org/10.48550/arXiv.1807.06521</a>. 介绍gate attention</p>

<p>[2] Cai, Yuanhao, Jing Lin, Xiaowan Hu, Haoqian Wang, Xin Yuan, Yulun Zhang, Radu Timofte, and Luc Van Gool. “Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction.” arXiv, July 10, 2022. <a href="https://doi.org/10.48550/arXiv.2203.04845">https://doi.org/10.48550/arXiv.2203.04845</a>. 介绍了Spectra-aware hashing attention block的结构</p>

<p>[3] https://github.com/tencent-ailab/IP-Adapter</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="deeplearning" /><category term="content" /><category term="network" /><category term="attention" /><category term="block" /><summary type="html"><![CDATA[在网络中, block是把input信息转换成output信息的过程: 一般, output(position, vector)是input(token, embedding vector)的线性组合, 组合的weight (position, token) 由input和output两方关系确定. 把着重强调这种信息交互的模块叫attention. convolution]]></summary></entry><entry><title type="html">常用的图像 reconstruction loss</title><link href="https://roshameow.github.io//personal_homepage/docs/deeplearning/restruction-loss/" rel="alternate" type="text/html" title="常用的图像 reconstruction loss" /><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-02T20:02:40+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/deeplearning/restruction-loss</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/deeplearning/restruction-loss/"><![CDATA[<p>输出为图像的任务, 比如enhance, deblur, super-resolution等用到的loss, 主要分为以下两类</p>
<h2 id="output和label相近">output和label相近</h2>

<table>
  <thead>
    <tr>
      <th>loss</th>
      <th>公式</th>
      <th>目的</th>
      <th>特点<br /></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>L1 loss</td>
      <td>$||I_1-I_2||_1$</td>
      <td>大体相近</td>
      <td>最常用的loss</td>
    </tr>
    <tr>
      <td>L2 loss<br />(MSE)</td>
      <td>$||I_1-I_2||_2$<br />或$MSE=\overline{(I_1-I_2)^2}$</td>
      <td> </td>
      <td>因为导数是线性所以计算最快</td>
    </tr>
    <tr>
      <td><a href="[https://github.com/CVMI-Lab/UHDM/blob/main/utils/common.py](https://github.com/CVMI-Lab/UHDM/blob/main/utils/common.py)">SSIM</a> <br />(stuctural similarity<br /> index measure)</td>
      <td>$\frac{2\mu_1\mu_2+C_1}{\mu_1^2+\mu_2^2+C_1}\cdot \frac{2\sigma_{12}+C_2}{\sigma_1^2+\sigma_2^2+C_2}$ <br />$\mu, \sigma$ 分别为mean, variance<br />$\sigma_{12}$是covariance<br />$C_1, C_2$ 是常数</td>
      <td>纹理相近</td>
      <td>要分patch计算<br />$C_1, C_2$ 的值要根据图像的范围调整</td>
    </tr>
    <tr>
      <td>PSNR<br />(Peak signal-<br />to-noise ratio)</td>
      <td>$-10\log_{10}(MSE(I_1,I_2))$</td>
      <td> </td>
      <td>经常是用来验证</td>
    </tr>
    <tr>
      <td><a href="[https://github.com/varun19299/deep-atrous-guided-filter/tree/master/PerceptualSimilarity](https://github.com/varun19299/deep-atrous-guided-filter/tree/master/PerceptualSimilarity)">PerceptualLoss</a></td>
      <td>一个分类网络</td>
      <td>语义相近</td>
      <td>一般用vgg16, 输入RGB图像<br />一般会用后几层的语义特征对比<br /></td>
    </tr>
    <tr>
      <td><a href="https://github.com/richzhang/PerceptualSimilarity">LPIPS</a> <br />(Learned Perceptual<br />image patch similarity)</td>
      <td> </td>
      <td> </td>
      <td>perceptualLoss+分块</td>
    </tr>
    <tr>
      <td>DeltaE</td>
      <td>转换成Lab空间的MSE</td>
      <td>颜色相近</td>
      <td> </td>
    </tr>
    <tr>
      <td>Gan Loss</td>
      <td>在训练过程中学习到的loss<br />用determinate网络表示<br /></td>
      <td>determinate网络<br />区别不出</td>
      <td> </td>
    </tr>
    <tr>
      <td>KL散度</td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="output图像符合自然图像的性质">output图像符合自然图像的性质</h2>

<ul>
  <li>Total Variant(TV) loss: 图像gradient稀疏性
    <ul>
      <li>anisotropic定义: <code class="language-plaintext highlighter-rouge">$|D_x I|_1+|D_y I|_1$</code></li>
    </ul>
  </li>
</ul>

<h2 id="代码">代码</h2>

<p><a href="https://gist.github.com/roshameow/c59d5708610ae30eb4329b140ccab3a7#file-reconstruction_loss-py"><strong>reconstruction_loss.py</strong></a></p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="deeplearning" /><category term="content" /><category term="loss" /><category term="image" /><summary type="html"><![CDATA[输出为图像的任务, 比如enhance, deblur, super-resolution等用到的loss, 主要分为以下两类 output和label相近]]></summary></entry><entry><title type="html">龙年春联</title><link href="https://roshameow.github.io//personal_homepage/docs/design/spring-couplets/" rel="alternate" type="text/html" title="龙年春联" /><published>2024-01-31T00:00:00+00:00</published><updated>2024-01-31T23:44:44+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/design/spring-couplets</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/design/spring-couplets/"><![CDATA[<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240131145110.png" alt="Pasted image 20240131145110.png" width="400" /></p>

<p>上联是“查找，回退，终止，定义，返回，格式化，删除”<br />
下联是“启动，切换，上一级，根目录，查找，替换，退出”<br />
横批是“全部历史”<br /></p>

<p>本以为会简单的制作过程, 居然感触挺多的</p>

<h2 id="制作时间轴">制作时间轴</h2>

<ul>
  <li>看到小红书上这个<a href="https://www.xiaohongshu.com/explore/65b781c8000000000c00534a">ps春联的帖子</a></li>
  <li>最开始是想做vscode和obsidian的图标</li>
  <li>做着做着, 感觉快捷键更有分享欲; 而且, 图标截图下来有清晰度和大小不一的问题</li>
  <li>直接写在红底黑字的春联底色上, 看起来太单调了
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Screenshot%202024-01-31%20at%2000.55.22.png" alt="Screenshot 2024-01-31 at 00.55.22.png" width="200" /></li>
    </ul>
  </li>
  <li>想用stable diffusion生成个华丽的背景, 但是… 放弃
    <ul>
      <li>基于v1.5的模型没法理解春联, 也没法理解龙
        <ul>
          <li>生成的这种看起来挺奇怪的东西: <img src="/personal_homepage/docs/attachment/00010-3341009059.png" alt="00010-3341009059.png" width="200" /></li>
          <li>canny的controlnet没法保证文字的细节一致: <img src="/personal_homepage/docs/attachment/00008-497390711.png" alt="00008-497390711.png" width="200" /></li>
          <li>生成的龙😮‍💨: <img src="/personal_homepage/docs/attachment/00014-2368775189.png" alt="00014-2368775189.png" width="200" /></li>
        </ul>
      </li>
      <li>SDXL可以生成不错的龙, 虽然细节不对</li>
      <li>ComfyUI的工作流我用的不太熟练, 而且, 我不太了解各种风格的prompt</li>
    </ul>
  </li>
  <li>在小红书上搜索春联的版式, 看到了<a href="https://www.xiaohongshu.com/explore/63c12c19000000001f0223f0">这个帖子</a>
    <ul>
      <li>模仿失败: 卖家秀$\rightarrow$ <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240131150246.png" alt="Pasted image 20240131150246.png" width="200" />  买家秀$\rightarrow$ <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240131150756.png" alt="Pasted image 20240131150756.png" width="200" /></li>
      <li>我的图看起来像东南亚黑帮, 又像个祭坛</li>
      <li>当然我的颜色调的不对, 但是我也明白了这个排版不适合龙(你的内容是现代的, 但是排版却相当古老, 你究竟是什么人😂)</li>
    </ul>
  </li>
  <li>又回归了黑白红配色, 改了版式, 感觉能看了, 蛮喜庆的, 有种过年的气氛了</li>
</ul>

<h2 id="工具">工具</h2>

<ul>
  <li>pinterest搜索, 然后推荐相似风格的图片</li>
  <li>eagle存图</li>
  <li>Freeform排版
    <ul>
      <li>可惜Freeform里面没法改图片整体的颜色, 也没法旋转</li>
    </ul>
  </li>
  <li>preview的魔棒工具
    <ul>
      <li>中间想用photoshop, 但是发现我的photoshop不太熟练, 还是preview简单粗暴</li>
      <li>感慨平时不熟悉的工作流, 一着急起来压根不想用…</li>
    </ul>
  </li>
  <li>写这篇blog的时候发现markdown居然没有官方的时间轴排版, 明明应该很好做的吧</li>
</ul>

<h2 id="资源">资源</h2>

<p>字体<a href="https://www.fontspace.com/category/artistic">OpenseaThecrownismineRegular</a></p>

<p><a href="https://www.pinterest.com/pin/732116483197126476/">龙</a></p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="design" /><category term="content" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">blender学习: 用graph editor做赛博车流</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning4/" rel="alternate" type="text/html" title="blender学习: 用graph editor做赛博车流" /><published>2024-01-30T00:00:00+00:00</published><updated>2024-02-02T06:14:22+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning4</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning4/"><![CDATA[<h2 id="步骤">步骤</h2>

<p>参考RuiHuang_art在<a href="https://www.bilibili.com/video/BV19C4y1S7dL/">b站的教学视频</a></p>
<ul>
  <li>world property: 加入一个CyberPunk背景的贴图
    <ul>
      <li><a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 选择camera坐标</li>
    </ul>
  </li>
  <li>制做车流:
    <ul>
      <li>添加一个Plane mesh</li>
      <li>在Edit编辑模式下, 按A选中, <a href="https://blog.csdn.net/BuladeMian/article/details/79625926">S+X, S+Y</a> 沿X,Y轴双向拉伸, 拉成长条形</li>
    </ul>
  </li>
  <li>shader: 目的是把车流改成带纹理, 自发光, 透明的效果
    <ul>
      <li>color:
        <ul>
          <li>下载一个灯火通明的城市俯瞰图
            <ul>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240201173155.png" alt="Pasted image 20240201173155.png" width="100" /></li>
            </ul>
          </li>
          <li>我们只想要图中亮的地方</li>
        </ul>
      </li>
      <li>emission: 把贴图纹理连到bsdf的<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/shader/emission.html">emission</a>
        <ul>
          <li>需要调整strength: 把strength调大之后好像发的都是白光?</li>
        </ul>
      </li>
      <li>alpha(调整车流的透明度): 除了贴图本身暗的地方转成透明, 我们还想要一个两端完全透明-&gt;中心的渐变
        <ul>
          <li>根据原图亮度设置透明: 暗处透明, 亮处不透明
            <ul>
              <li>给贴图连接一个Color Ramp</li>
            </ul>
          </li>
          <li>设置两端完全透明-&gt;中心的渐变
            <ol>
              <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 的uv生成平面的坐标</li>
              <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/gradient.html">Gradient Texture</a> 提取x方向</li>
              <li>用 <a href="https://docs.blender.org/manual/en/latest/editors/texture_node/types/converter/color_ramp.html">Color Ramp</a> 做一个 暗-&gt;亮-&gt;暗 的渐变</li>
            </ol>
          </li>
          <li>用<a href="https://docs.blender.org/manual/en/latest/compositing/types/color/mix/mix_color.html">Mix Node</a> 把上面两个控制透明度的图融合
            <ul>
              <li>调成Multiply模式: 原视频用的是Mix模式, 把一个设成alpha, 和黑色平均..这应该和直接用Multiply等价..</li>
            </ul>
          </li>
          <li>在Material Properties把blend改成alpha blend</li>
        </ul>
      </li>
      <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/color/hue_saturation.html">Hue/Saturation/Value Node</a> 调颜色</li>
    </ul>
  </li>
  <li>加入动画:
    <ul>
      <li>在shader里给贴图加上mapping</li>
      <li>调整mapping的location
        <ul>
          <li>在Mapping的location插入关键帧</li>
          <li>在<a href="https://docs.blender.org/manual/zh-hans/dev/editors/graph_editor/fcurves/editing.html">Graph Editor</a> 里编辑: 需要快捷键T调出Select Box, 把需要更改的mapping选中</li>
          <li>选中后在Graph Editor的Shader Nodetree里编辑Y Default Value</li>
          <li>添加Modifier, 把x^1改成需要的速度0.05</li>
        </ul>
      </li>
      <li>另外用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/object_info.html">Object Info</a> 获取object的位置加到location里, 给每个不同位置的车流加一个location的变化</li>
    </ul>
  </li>
  <li>复制多个车流组合</li>
  <li>结果: 当然也只能远看
    <ul>
      <li><img src="/personal_homepage/docs/attachment/car_flow.mp4" alt="car_flow.mp4" width="320" /></li>
    </ul>
  </li>
</ul>

<h2 id="shader流程">shader流程</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240201172349.png" alt="Pasted image 20240201172349.png" width="800" /></p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="render" /><category term="shader" /><summary type="html"><![CDATA[步骤]]></summary></entry><entry><title type="html">blender学习: 用volume shader做气态行星</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning3/" rel="alternate" type="text/html" title="blender学习: 用volume shader做气态行星" /><published>2024-01-26T00:00:00+00:00</published><updated>2024-01-30T00:47:25+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning3</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning3/"><![CDATA[<h2 id="步骤">步骤</h2>

<p>参考RuiHuang_art在<a href="https://www.bilibili.com/video/BV1Aj411j7CD">b站的教学视频</a></p>
<ul>
  <li>world property: 加入一个太空背景的贴图</li>
  <li>光源：改成<a href="https://docs.blender.org/manual/en/latest/render/lights/light_object.html#sun-light">sun light</a>
    <ul>
      <li>strength改成12: 单位是 $W/m^2$</li>
      <li>volume改成3: 控制在volume shader时的影响?</li>
    </ul>
  </li>
  <li>render: 用eevee
    <ul>
      <li>设置volumetrics参数
        <ul>
          <li><strong>打开volumetric shadows</strong></li>
          <li>start, end: 相对相机的体积效果范围, 设为(3.3m-&gt;200m)</li>
          <li>tile size: volume块大小</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>shader:
    <ul>
      <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/shader/volume_principled.html">principled volume</a> : 把mesh包含的部分看成volume块
        <ul>
          <li>color:
            <ol>
              <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 生成volume的坐标</li>
              <li><a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/image.html">Image Texture</a> 把2d的木星贴图映射到3d的volume上</li>
              <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/color/hue_saturation.html">Hue/Saturation/Value Node</a> 调颜色</li>
            </ol>
          </li>
          <li>density: 一个从里到外逐渐稀薄的球形+被纹理的影响
            <ol>
              <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 生成volume的坐标
                <ol>
                  <li>object生成一个在中心的坐标系</li>
                  <li>用 <a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/image.html">Image Texture</a> 生成一个按照贴图纹理亮度的scale, 模拟气体的效果
                    <ul>
                      <li>用Mulitiply node的Factor node调整受纹理影响的强度</li>
                      <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/color/invert.html">invert node</a> 调整: 亮的纹理密度低(凹陷), 暗得纹理密度高(突出), 如果Fac设置成1就会反过来
                        <ul>
                          <li>Fac参数:  类似$\alpha \frac{1}{x}+(1-\alpha) x$ ?</li>
                        </ul>
                      </li>
                      <li>这部分应该可以优化, 不是用multiply 而是用其他方式做纹理的distortion?</li>
                    </ul>
                  </li>
                </ol>
              </li>
              <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/gradient.html">gradient texture</a> 设置渐变的密度</li>
              <li>用 <a href="https://docs.blender.org/manual/en/latest/editors/texture_node/types/converter/color_ramp.html">Color Ramp</a> 做一个动态范围的压缩:
                <ul>
                  <li>我们想要一个(实体-&gt;气态-&gt;空) 的渐变, 中间density在0-1之间的部分, 是气态部分</li>
                  <li>调整value参数, 也就是最后输入的密度</li>
                </ul>
              </li>
            </ol>
          </li>
        </ul>
      </li>
      <li>视频里还另外加了一个底色, 但是看起来没什么影响</li>
    </ul>
  </li>
  <li>相机: Camera-&gt; Data
    <ul>
      <li>Focal Length 调大到60mm: 调整物体在镜头内的大小</li>
    </ul>
  </li>
  <li>结果: 和视频里的结果不完全一样, 不清楚是哪里的问题😮‍💨
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240129164109.png" alt="Pasted image 20240129164109.png" width="200" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240129164354.png" alt="Pasted image 20240129164354.png" width="200" /></li>
    </ul>
  </li>
</ul>

<h2 id="shader流程">shader流程</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240129164505.png" alt="Pasted image 20240129164505.png" width="900" /></p>

<h2 id="texture-coordinate-的设置"><a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/input/texture_coordinate.html">texture Coordinate</a> 的设置</h2>

<p>texture coordinate不同模式的区别是坐标系的原点位置不一样: generate模式的原点是在mesh的bounding box一角, 而object模式的原点是在bounding box的中心(从名字是看不出来..也没看源码验证, 都是我猜的)</p>
<ul>
  <li>用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/gradient.html">gradient texture</a> 调整密度时, 输入的是vector的模长
    <ul>
      <li>如果generate模式 , 密度最大的点在box的一角, 得到<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240129151203.png" alt="Pasted image 20240129151203.png" width="120" />;</li>
      <li>用object模式  , 密度最大的点在中心, 得到<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240129151233.png" alt="Pasted image 20240129151233.png" width="150" />, 也就是我们需要的行星的形态</li>
    </ul>
  </li>
  <li>而我们用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/image.html">Image Texture</a> 设置颜色的映射时, Sphere的映射方法默认是围绕点 $(0.5,0.5,0.5)$ 进行映射, 这个时候我们就需要在generate模式的坐标系下映射
    <ul>
      <li>Sphere的映射方法: <img src="https://docs.blender.org/manual/en/latest/_images/render_shader-nodes_textures_image_projection-sphere.png" alt="sphere" /></li>
      <li>把贴图<img src="/personal_homepage/docs/attachment/jupiter_01_pd.png" alt="jupiter_01_pd.png" width="200" /> 映射到<img src="/personal_homepage/docs/attachment/Pasted%20image%2020240129144125.png" alt="Pasted image 20240129144125.png" width="120" /></li>
    </ul>
  </li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil, &quot;links&quot;=&gt;[{&quot;title&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;icon&quot;=&gt;nil}]}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="render" /><category term="shader" /><summary type="html"><![CDATA[步骤]]></summary></entry></feed>