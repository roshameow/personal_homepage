<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://roshameow.github.io//personal_homepage/atom.xml" rel="self" type="application/atom+xml" /><link href="https://roshameow.github.io//personal_homepage/" rel="alternate" type="text/html" /><updated>2024-05-28T04:49:54+00:00</updated><id>https://roshameow.github.io//personal_homepage/atom.xml</id><title type="html">Liu, Wen’s Home Page</title><subtitle>Work, Experiments and Ideas.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><entry><title type="html">blender学习: 冰材质</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning13/" rel="alternate" type="text/html" title="blender学习: 冰材质" /><published>2024-05-27T00:00:00+00:00</published><updated>2024-05-28T20:46:36+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning13</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning13/"><![CDATA[<p>在IOR=1.31的透明材质基础上, 添加表面的凹凸和内部的裂痕, 气泡</p>

<h2 id="制作冰材质">制作冰材质:</h2>

<h3 id="用volume-shader">用volume shader</h3>

<p>参考<a href="https://www.youtube.com/watch?v=EUvNwscez-w">这个教学</a></p>

<ol>
  <li>用Cycles渲染器, 打开Render-&gt;<a href="https://docs.blender.org/manual/en/latest/render/cycles/render_settings/film.html">Film-&gt;Transparent-&gt; Transparent Glass</a>
    <ul>
      <li>但是没有用到composition所以开不开无所谓吧?</li>
    </ul>
  </li>
  <li><strong>表面增加凹凸</strong>: 用Bump节点
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240527221548.png" alt="Pasted image 20240527221548.png" width="100" /></li>
      <li>用<a href="https://docs.blender.org/manual/en/4.1/render/shader_nodes/vector/bump.html">Bump</a> 更改normal的方向: 根据输入的局部高度差
        <ul>
          <li>用noise texture生成纹理, 应用到bump的高度</li>
        </ul>
      </li>
      <li>用相同的noise texture生成纹理, 应用到roughness
        <ul>
          <li>目的是让凸出的地方更粗糙? 感觉和实际不太相符</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>在内部添加crack</strong>: 用<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/textures/voronoi.html">Voronoi Texture</a> 复合Noise Texture的扭曲
    <ul>
      <li></li>
      <li>texture color: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240528093833.png" alt="Pasted image 20240528093833.png" width="100" />  添加到volume后: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240528102634.png" alt="Pasted image 20240528102634.png" width="100" /></li>
      <li>Voronoi Texture由<a href="https://en.wikipedia.org/wiki/Worley_noise">Worley noise</a> 生成
        <ul>
          <li>选择Distance to Edge: 生成distance map</li>
        </ul>
      </li>
      <li>用<a href="https://docs.krita.org/en/reference_manual/blending_modes/lighten.html#bm-linear-light">Linear Light(线性光)</a> 的方式混合: 和add差不多, 但是会对可能saturated的值特殊处理</li>
    </ul>
  </li>
  <li><strong>在内部添加一些雾气</strong>: 用noise texture生成</li>
</ol>

<ul>
  <li>结果: 没太复刻出冰的质感, 还是更像玻璃
    <ul>
      <li><img src="/personal_homepage/docs/attachment/ice_glass_cycle.png" alt="ice_glass_cycle.png" width="480" /></li>
    </ul>
  </li>
</ul>

<h3 id="用粒子系统">用粒子系统</h3>

<p>参考<a href="https://www.bilibili.com/video/BV1i5411e7VZ/">这个教学</a></p>

<h2 id="实物参考">实物参考</h2>

<iframe src="//player.bilibili.com/player.html?isOutside=true&amp;aid=422168352&amp;bvid=BV1a3411477N&amp;cid=458238306&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>

<ul>
  <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240527221116.png" alt="Pasted image 20240527221116.png" width="480" />  <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240527221224.png" alt="Pasted image 20240527221224.png" width="320" /></li>
  <li>冻的漂亮的冰里面本来就不应该有那些crack和气泡嘛</li>
</ul>

<h2 id="blender用法">blender用法</h2>

<ul>
  <li>displacement和noise texture+bump的凹凸效果区别: displacement会确实更改mesh上点的位置, bump不会, bump只是改变表面法线方向来模拟.</li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="shader" /><summary type="html"><![CDATA[在IOR=1.31的透明材质基础上, 添加表面的凹凸和内部的裂痕, 气泡]]></summary></entry><entry><title type="html">阿那亚戏剧节的海报制作</title><link href="https://roshameow.github.io//personal_homepage/docs/design/poster1/" rel="alternate" type="text/html" title="阿那亚戏剧节的海报制作" /><published>2024-05-24T00:00:00+00:00</published><updated>2024-05-27T19:08:11+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/design/poster1</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/design/poster1/"><![CDATA[<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240524215103.png" alt="Pasted image 20240524215103.png" width="300" /></p>

<ul>
  <li>想法:
    <ul>
      <li>想着 🙌没有人👐比我👌更懂☝伽利略 选了这个主题,</li>
      <li>虽然知道戏剧是改编自《伽利略传》, 讲的是伽利略和教廷之间的比较肮脏?的拉扯.</li>
      <li>我希望海报呈现的是他的动机: 希望世界上所有事情都和谐漂亮的执着和品味(我个人理解).</li>
      <li>所以希望海报是抽象的, 现代的, 干净的
        <ul>
          <li>因此 pass掉了非常具象的指代人身份的元素, 比如伽利略头像啊, ❗️没有语境的数学公式啊. 选了伽利略至今仍有影响的工作, 密度天平和潮汐现象</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="制作">制作</h2>

<ul>
  <li>背景
    <ul>
      <li>画了草图后用stable-diffusion的ipadapter做风格转换</li>
    </ul>
  </li>
  <li>前景</li>
</ul>

<h2 id="素材">素材</h2>

<p>[1] https://www.pinterest.com/pin/58546863899073827/  背景风格</p>

<p>[2] https://www.pinterest.com/pin/363102788722082645/ 前景风格</p>

<h2 id="后续">后续</h2>

<p>发了之后完全没有流量, 而且我也看不出其他作品的好坏和点赞的关系, 看来我吃不上这碗饭😮‍💨</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="design" /><category term="content" /><category term="photoshop" /><category term="stable-diffusion" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">FFT计算</title><link href="https://roshameow.github.io//personal_homepage/docs/algorithm/fft/" rel="alternate" type="text/html" title="FFT计算" /><published>2024-05-19T00:00:00+00:00</published><updated>2024-05-20T21:02:00+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/algorithm/fft</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/algorithm/fft/"><![CDATA[<ul>
  <li>fourier Series 定义:
    <ul>
      <li>$F(f)(u)=\int_{-\infty}^{\infty} f(x)e^{-2\pi i x u} dx$</li>
      <li>2维：$G(p,q)=F(g(x,y)) = \int\int^\infty_\infty g(x,y)e^{-i2\pi(px+qy)}dxdy$</li>
    </ul>
  </li>
  <li>离散形式: 信号$x$ 的FFT 信号$X$
    <ul>
      <li>$X_k=\sum_{m=0}^{N-1}x_m\cdot e^{-i\cdot 2\pi km/N}=\sum_{m=0}^{N-1}x_m\cdot TW(N,k)^m$
        <ul>
          <li>$N$ 是信号长度</li>
          <li>$TW(N,k) = e^{-i*2k\pi/N}$ 是<a href="https://en.wikipedia.org/wiki/Twiddle_factor#:~:text=A%20twiddle%20factor%2C%20in%20fast,papers%20of%20the%20FFT%20literature.">FFT 的twiddle factor(旋转因子)</a>
            <ul>
              <li>$TW(N,k)=\cos(-2k\pi/N)+i\cdot \sin(-2k\pi/N)=TW_r(N,k)+i\cdot TW_i(N,k)$</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="butterfly-diagram">butterfly diagram</h3>

<p>利用fft的对称性和周期性</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="algorithm" /><category term="content" /><summary type="html"><![CDATA[fourier Series 定义: $F(f)(u)=\int_{-\infty}^{\infty} f(x)e^{-2\pi i x u} dx$ 2维：$G(p,q)=F(g(x,y)) = \int\int^\infty_\infty g(x,y)e^{-i2\pi(px+qy)}dxdy$ 离散形式: 信号$x$ 的FFT 信号$X$ $X_k=\sum_{m=0}^{N-1}x_m\cdot e^{-i\cdot 2\pi km/N}=\sum_{m=0}^{N-1}x_m\cdot TW(N,k)^m$ $N$ 是信号长度 $TW(N,k) = e^{-i*2k\pi/N}$ 是FFT 的twiddle factor(旋转因子) $TW(N,k)=\cos(-2k\pi/N)+i\cdot \sin(-2k\pi/N)=TW_r(N,k)+i\cdot TW_i(N,k)$]]></summary></entry><entry><title type="html">劳动仲裁流程和资料整理</title><link href="https://roshameow.github.io//personal_homepage/docs/affair/labor-disputes-arbitration/" rel="alternate" type="text/html" title="劳动仲裁流程和资料整理" /><published>2024-05-15T00:00:00+00:00</published><updated>2024-05-21T18:45:39+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/affair/labor-disputes-arbitration</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/affair/labor-disputes-arbitration/"><![CDATA[<h2 id="材料">材料</h2>

<ul>
  <li>信息:
    <ul>
      <li>身份证复印件</li>
      <li>公司注册信息: 在<a href="https://shiming.gsxt.gov.cn/">国家企业信用信息公示系统</a> 查找公司信息并打印</li>
    </ul>
  </li>
  <li>证据清单
    <ul>
      <li>社保缴费记录:  <a href="https://zwdtuser.sh.gov.cn/uc/login/login.jsp?redirect_uri=&amp;type=">一网通办</a> 登陆打印 参保人员城镇职工基本养老保险缴费情况</li>
      <li>银行流水: 在银行app里就可以打印</li>
      <li>劳动合同</li>
      <li>在企业微信里: 企业微信里的内容很难作为证据, 1. 都是聊天格式, 自己重新整理是没有法律效力的, 2. 而且企业微信被人事踢出后backup也没法恢复
        <ul>
          <li>工资条</li>
          <li>聊天记录</li>
          <li>打卡记录: 企业微信可以导出2个月的, 很麻烦</li>
          <li>工时统计表: 没用到, 没研究怎么导出</li>
          <li>周报邮件: 没用到</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>申请书
    <ul>
      <li>申请人信息: (姓名、性别、出生日期、身份证号码、住址、联系方式）</li>
      <li>被申请人信息: (单位名称、统一社会信用代码、法定代表人、单位地址、联系方式）</li>
      <li>仲裁请求(需要计算赔偿)
        <ol>
          <li>裁决劳动关系</li>
          <li>请求被申请人支付拖欠的工资和年终奖 x元（截至申请仲裁之日）；</li>
          <li>请求支付被动解除劳动合同的经济补偿金x元。</li>
        </ol>
      </li>
      <li>事实与理由
        <ul>
          <li>按照模版写</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>地址送达确认书</li>
</ul>

<p>我遇到的情况: 1. 续签劳动合同没给是按照签订了劳动合同处理, 不能索要赔偿, 用社保记录证明劳动关系即可 2. 除了社保记录和银行流水, 其它跟公司的文件都很难作为证据. 但是因为我有收集, 仲裁委的工作人员和调解员迅速的了解了我的情况和薪资结构, 所以应该还算有点用的 3. 在职的情况没法请求经济补偿金, 要先给公司发被动解除劳动合同的通知书 4. 我同意了减少补偿金离职, 所以也就没经历后面的流程了. 工作人员对我的材料给了很具体的指导, 总共一个小时就结束了.</p>

<h2 id="法律依据">法律依据</h2>

<p><a href="https://www.gov.cn/flfg/2007-06/29/content_669394.htm">劳动合同法</a></p>

<p>跟被动离职有关的是: 第38条, 46条, 47条</p>

<h2 id="相关的机构">相关的机构</h2>

<ul>
  <li>xx区劳动仲裁委</li>
  <li>劳动监察大队: 投诉公司欠薪, 处理结果一般比较慢</li>
  <li>地方调解(xx区xx地社区事务受理服务中心): 调解员可以代为联系公司, 同意牺牲一部分补偿金就可以快速结束流程</li>
  <li>工会: 提供法律援助</li>
</ul>

<h2 id="身在其中的感触">身在其中的感触</h2>

<p>公司是15号发工资, 因为公司在工资发放上已经多次食言, 已读不回, 本来已经决定这是最后一次机会, 15号到了一定要去仲裁, 在这之前就应该写好材料.</p>

<p>我对公司产生过侥幸心理: 中间大概10多号的时候, 同事跟我说15号可能会发工资. 虽然我当时有理有据的反驳了, 内心还是松懈了下来, 希望15号可以正常发工资不用去仲裁. 然后15号果然如我本来所料想继续拖欠, 结果还是要临时整理资料.</p>

<p>好在, 资料并不复杂, 只要一鼓作气就可以摆脱和现在公司这种不健康的关系.</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="affair" /><category term="content" /><summary type="html"><![CDATA[材料]]></summary></entry><entry><title type="html">blender学习: 用布料系统做膨胀效果</title><link href="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning12/" rel="alternate" type="text/html" title="blender学习: 用布料系统做膨胀效果" /><published>2024-05-13T00:00:00+00:00</published><updated>2024-05-16T19:48:22+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/blender/blender-learning12</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/blender/blender-learning12/"><![CDATA[<p>参考<a href="https://www.bilibili.com/video/BV13C41177Ze">这个教学</a></p>

<h3 id="建模">建模</h3>

<p>球和boundary两部分</p>

<ul>
  <li>新建一个Ico Sphere(棱角球)</li>
  <li>在Edit Mode选中一些顶点作为boundary, 设为顶点组</li>
  <li>给棱角球做一个表面细分并应用</li>
  <li>在Edit Mode里用Bevel把boundary拉出一点宽度, 把顶点组改为新的boundary
    <ul>
      <li>要先应用表面细分再Bevel? 不然boundary的mesh会变得很复杂</li>
    </ul>
  </li>
  <li>在原位把boundary复制一份(Shift+D), 和球分离(P), 稍微拉大一点(S)</li>
  <li>给boundary添加一个2的表面细分</li>
  <li>设置shade smooth</li>
</ul>

<h3 id="制作膨胀效果">制作膨胀效果:</h3>

<ul>
  <li>选择Physics-&gt;Cloth
    <ul>
      <li>Pressure = 25</li>
      <li><a href="https://docs.blender.org/manual/en/latest/physics/cloth/settings/shape.html">Shape</a>选择boundary的顶点组
        <ul>
          <li>Shrinking Factor = -0.3 负数表示要cloth膨胀</li>
        </ul>
      </li>
      <li>Field Weights-&gt;Gravity=0</li>
    </ul>
  </li>
  <li>结果:
    <ul>
      <li><img src="/personal_homepage/docs/attachment/inhale.mp4" alt="inhale.mp4" width="400" /></li>
    </ul>
  </li>
</ul>

<h3 id="用到的blender的一些快捷键">用到的blender的一些快捷键</h3>

<ul>
  <li>Command+A(应用modifier)</li>
  <li>Shift+D(<a href="https://docs.blender.org/manual/en/2.82/scene_layout/object/editing/duplication.html">Duplication</a>): 复制物体
    <ul>
      <li>RMB(右键): 保留在原来的位置</li>
    </ul>
  </li>
  <li>P(<a href="https://docs.blender.org/manual/en/latest/modeling/meshes/editing/mesh/separate.html">分离</a>)
    <ul>
      <li>把选中的顶点建一个新的object</li>
    </ul>
  </li>
  <li>Command+P(<a href="https://docs.blender.org/manual/en/latest/scene_layout/object/editing/parent.html">Parent</a>)
    <ul>
      <li>把后选中的object设置为先选中的object的parent </li>
    </ul>
  </li>
  <li>Ctrl+B( <a href="https://docs.blender.org/manual/en/2.81/modeling/meshes/editing/subdividing/bevel.html#:~:text=The%20Bevel%20tool%20smooths%20the,above%20to%20run%20the%20tool.">Bevel</a>, 拉伸, 倒角): 把一个edge变成多个edge, 使物体边缘光滑
    <ul>
      <li><img src="https://docs.blender.org/manual/zh-hans/2.81/_images/modeling_meshes_editing_subdividing_bevel_example-4.png" alt="drawing" width="150" /></li>
      <li>按Shift微调: 移动的幅度降1k倍</li>
    </ul>
  </li>
</ul>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="blender" /><category term="content" /><category term="physics" /><category term="shortcut" /><summary type="html"><![CDATA[参考这个教学]]></summary></entry><entry><title type="html">给网页添加 logo</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/jekyll-add-logo/" rel="alternate" type="text/html" title="给网页添加 logo" /><published>2024-05-09T00:00:00+00:00</published><updated>2024-05-10T20:36:50+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/jekyll-add-logo</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/jekyll-add-logo/"><![CDATA[<p><img src="/personal_homepage/docs/attachment/logo.svg" alt="logo.svg" width="200" /></p>

<h2 id="用照片制作svg">用照片制作svg</h2>

<p>这次只描了轮廓</p>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240510121915.png" alt="Pasted image 20240510121915.png" width="200" /></p>

<ul>
  <li>用钢笔工具和选择工具画路径:
    <ul>
      <li>在最凸，最凹的地方加锚点</li>
      <li>添加锚点时拉拽得到切线</li>
      <li>按command 单独调整锚点和切线的端点</li>
      <li>option调整切线</li>
      <li>用直接选择工具(白色箭头)调整锚点位置</li>
      <li>用路径选择工具(黑色箭头)复制路径</li>
      <li>用颜色填充功能实时查看路径闭包</li>
    </ul>
  </li>
  <li>导出:
    <ul>
      <li>选中填充图层复制svg</li>
    </ul>
  </li>
</ul>

<h2 id="设置网页的favicon">设置网页的favicon</h2>

<ul>
  <li>在对应html设置icon:  <code class="language-plaintext highlighter-rouge">&lt;link rel="shortcut icon" type="image/x-icon" href="/personal_homepage/docs/images/logo.ico"&gt;</code>
    <ul>
      <li>我的路径是<code class="language-plaintext highlighter-rouge">head.html-&gt;head-custom.html</code></li>
    </ul>
  </li>
</ul>

<h2 id="资源">资源</h2>

<p>[1]  <a href="https://www.bilibili.com/video/BV1pP4y1R7r6/">https://www.bilibili.com/video/BV1pP4y1R7r6</a> 钢笔工具使用</p>

<p>[2]  <a href="https://www.taoxuemei.com/chuli/ps/754.html">https://www.taoxuemei.com/chuli/ps/754.html</a> 钢笔工具画的形状-&gt;svg</p>

<p>[3]  <a href="https://zhuanlan.zhihu.com/p/446194623">https://zhuanlan.zhihu.com/p/446194623</a> 路径转形状</p>

<p>[4]  https://stackoverflow.com/questions/30551501/unable-to-set-favicon-using-jekyll-and-github-pages  关于icon路径的讨论</p>

<p>[5]  https://convertio.co/download/9dceab468ba01473f3d49fc765b6f73f983c7f/ svg转ico</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="jekyll" /><category term="photoshop" /><category term="logo" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">各种 moving function</title><link href="https://roshameow.github.io//personal_homepage/docs/algorithm/moving_function/" rel="alternate" type="text/html" title="各种 moving function" /><published>2024-05-05T00:00:00+00:00</published><updated>2024-05-16T00:59:20+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/algorithm/moving_function</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/algorithm/moving_function/"><![CDATA[<h2 id="场景">场景</h2>
<h3 id="moving-mean">moving mean</h3>

<p>leetcode 239</p>
<ul>
  <li>用一个queue保存window里面的数据</li>
  <li>每次+新进的数据-出去的数据</li>
</ul>

<h3 id="moving-median">moving median</h3>

<p>leetcode 480</p>

<ul>
  <li>naive: 保存window里的所有数据,排序, 找出median
    <ul>
      <li>每次更新进出data的顺序</li>
    </ul>
  </li>
  <li>优化1: 当进出的data在median同一侧时, 不需要更新median</li>
  <li>优化2: 不需要严格的排序, 只需要维护median两边堆的结构, 就可以找到left的最大值, 和right的最小值
    <ul>
      <li>用window记录进出的data</li>
      <li>同样的data只存一个位置, 通过一个counter记录data的重复次数, 次数=0就是待删除的data</li>
      <li>记录left_heap, right_heap的实际size, 当两边size偏离的时候移动heap</li>
      <li>如果删除/移动的data在堆顶, 需要更新堆(把堆顶待删除的data全部删除)</li>
    </ul>
  </li>
  <li>错误方向:
    <ul>
      <li>本来想像moving max一样只保留时间近的, median附近的data. 但是moving median中, 所有的元素都可能在之后变得重要, 所以要全部保留的
        <ul>
          <li>如果window_size=k, 需要&lt;2/k个更新的data, 或&gt;2/k个更新的data, 才能确定这个data不可能成为median, 这个条件达成的概率很小</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="moving-minmax">moving min/max</h3>

<p>leetcode 239</p>

<p>以max为例</p>
<ul>
  <li>naive: 保存window里的所有数据, 找出max</li>
  <li>优化1: 不需要每次计算min/max, 只需要当前max出window的时候重新计算
    <ul>
      <li>记录当前max的值和index</li>
      <li>con: 这样计算速度不稳定
        <ul>
          <li>比如: window_size较大, 而数据又是降序排列的时候, 每新进一个数据都要计算一次max, 时间是O(k)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>优化2: window里不需要全部保存, 用deque结构, 只需要按顺序保存可能成为local max的data和index (不符合降序的data永远不会成为max)
    <ul>
      <li>当新data进入deque时, 把deque里&lt;=它的data删除</li>
      <li>deque里的当前max生命耗尽时, 需要移出deque
        <ul>
          <li>用保存的index判断生命耗尽</li>
          <li>或保存一份window, 如果window移除data = deque的第一个data, 把data从deque里移除
            <ul>
              <li>deque里不会有重复data</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>deque里的第一个data就是local max</li>
      <li>例子: <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240515165236.png" alt="Pasted image 20240515165236.png" width="300" />
        <ul>
          <li>data6进入window后, 4,5就不可能成为local max了</li>
          <li>data7进入window后, 6也不可能成为local max了</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>应用:
    <ul>
      <li>动态调整画图界面适应data</li>
      <li>mormophic filter去除基线漂移</li>
    </ul>
  </li>
</ul>

<h2 id="结构">结构</h2>

<h3 id="deque双向队列">deque(双向队列)</h3>

<p>支持在两端进出</p>
<ul>
  <li>用途:
    <ul>
      <li>实现LRU缓存(leetcode 146)</li>
    </ul>
  </li>
</ul>

<h3 id="heap优先队列">heap(优先队列)</h3>

<ul>
  <li>priority_queue(C++), heapq(python)</li>
  <li><strong>heap的数据结构</strong>:
    <ul>
      <li><img src="https://upload.wikimedia.org/wikipedia/commons/c/c4/Max-Heap-new.svg" alt="drawing" width="200" /></li>
      <li>parent比children大的完备二叉树(以最大堆为例)
        <ul>
          <li>完备是指, 从上到下每层填满, 最后一层靠左排列</li>
        </ul>
      </li>
      <li>可以用数组表示: 第 $i$个节点的左子节点编号为 $2i+1$，右子节点编号为 $2i+2$，父节点编号为 $⌊\frac{i−1}{2}⌋$
        <ul>
          <li>完备的=可以连续存储, 数组可以在任意位置访问-&gt;可以做swap</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>heap支持的操作</strong>: 都是把中间data和最后data互换, 然后在最后增删, 所以不会破坏完备性
    <ul>
      <li>新插入一个元素(“上浮”操作): 把新data添到heap的尾部, 不断和parent比较, 并swap到合适位置
        <ul>
          <li>只需要O(logk) 的swap(如果要排序就需要O(k)个swap)</li>
        </ul>
      </li>
      <li>移除heap 顶的元素(“下沉”操作): 和其children比较, 跟更大的那个swap, 直到到达底部, 删除</li>
    </ul>
  </li>
  <li><strong>用途</strong>:
    <ul>
      <li>调度器, 用来实时添加任务, 和取出最合适的任务进行执行
        <ul>
          <li>比如优先级最高, 或截止时间最早的任务</li>
        </ul>
      </li>
      <li>堆排序: 每轮找到最小的data排在后面, 时间复杂度是O(nlogn)
        <ul>
          <li>时间稳定, inplace操作, 适合大数据量, 内存有限的场景</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="hashtable">hashtable</h3>

<ul>
  <li>unordered_map(C++), Counter(python), dict, set</li>
</ul>

<h3 id="multiset">multiset</h3>

<ul>
  <li>multiset(C++)
    <ul>
      <li>类似set, 允许重复的data, 可以按顺序遍历</li>
    </ul>
  </li>
</ul>

<h2 id="其它有用的链接">其它有用的链接</h2>

<p>[1]  https://cplusplus.com/reference/unordered_map/unordered_map/</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="algorithm" /><category term="content" /><category term="leetcode" /><category term="basic" /><category term="data_structure" /><summary type="html"><![CDATA[场景 moving mean]]></summary></entry><entry><title type="html">小面积光流传感器算法测试 (三) – 滤波</title><link href="https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train3/" rel="alternate" type="text/html" title="小面积光流传感器算法测试 (三) – 滤波" /><published>2024-04-28T00:00:00+00:00</published><updated>2024-05-05T15:17:18+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train3</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train3/"><![CDATA[<p>在高速场景下, 每次中断收集的数据是光流的累加值, 其实本来就相当于一个滤波…况且在硬件有限的条件下, 复杂的滤波没有什么实用价值.</p>

<h2 id="实验">实验</h2>

<table>
  <thead>
    <tr>
      <th>方法</th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ConfidenceFilter</td>
      <td>输出光流时同时输出一个置信度, 如果置信度较低, 选择历史值而不是测量值</td>
    </tr>
    <tr>
      <td>FIR</td>
      <td>在临近window上的一个线性filter</td>
    </tr>
    <tr>
      <td>Kalman</td>
      <td>在gain值稳定后, kalman滤波其实相当于一个<a href="https://en.wikipedia.org/wiki/Infinite_impulse_response">IIR filter</a></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>对于整像素的光流结果, 相当于Kalman的MeasureNoise有一部分量化噪声, 应该加大MeasureNoiseCov参数的设置, 不过实验中看不出区别</li>
  <li>Kalman在反应速度和平滑度上都要好于FIR的</li>
</ul>

<h2 id="kalman滤波原理"><a href="https://en.wikipedia.org/wiki/Kalman_filter#:~:text=The%20Kalman%20filter%20produces%20an,uncertainty%20are%20%22trusted%22%20more.">Kalman滤波</a>原理</h2>

<h3 id="ssmstate-space-model">SSM(state space model)</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/State-space_representation">状态空间(state space)</a> : 用state vector记录历史的input, 而不是记录所有的历史token
    <ul>
      <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240317183044.png" alt="Pasted image 20240317183044.png" width="200" /></li>
    </ul>
  </li>
  <li>连续表示:
    <ul>
      <li>linear state space model的一般形式:
        <ul>
          <li>$\dot x(t)=A(t)x(t)+B(t)u(t)$ (用input u更新状态 x)</li>
          <li>$y(t)=C(t)x(t)+D(t)u(t)$  (用状态x, 生成output y)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="滤波步骤">滤波步骤</h3>

<table>
  <thead>
    <tr>
      <th>变量</th>
      <th>input</th>
      <th>predict</th>
      <th>correct</th>
      <th>output</th>
      <th>使用</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>state</td>
      <td> </td>
      <td>$\hat x_n$</td>
      <td>$x_n$</td>
      <td> </td>
      <td>[x,y,dx,dy]</td>
    </tr>
    <tr>
      <td>measure</td>
      <td>$u_n$</td>
      <td>$\hat y_n$</td>
      <td> </td>
      <td>$y_n$</td>
      <td>[x, y]</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>参数</th>
      <th> </th>
      <th>使用</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>transition matrix P</td>
      <td>state -&gt; predict state</td>
      <td>\begin{bmatrix}1&amp;0&amp;1&amp;0\\0&amp;1&amp;0&amp;1\\0&amp;0&amp;1&amp;0\\0&amp;0&amp;0&amp;1\end{bmatrix}</td>
    </tr>
    <tr>
      <td>measure matrix $C$</td>
      <td>state -&gt; measure</td>
      <td>\begin{bmatrix}1&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;0\end{bmatrix}</td>
    </tr>
    <tr>
      <td>gain $g_n$</td>
      <td>measure error -&gt; state error</td>
      <td>根据仿真模型和运动模型更新</td>
    </tr>
  </tbody>
</table>

<p>参考<a href="https://github.com/opencv/opencv/blob/4.x/modules/video/src/kalman.cpp">opencv里面的写法</a></p>
<ul>
  <li><strong>predict</strong>:
    <ul>
      <li>$\hat x_n=P(x_{n-1})$ 是state 在当前时间的predict</li>
    </ul>
  </li>
  <li><strong>correct</strong>:
    <ul>
      <li>$x_{n}-\hat x_{n}=g_n\cdot(u_n-\hat y_{n})=g_n\cdot(u_n-C\hat x_n)$
        <ul>
          <li>state的error和measure的error(measure-predict) 是线性关系
            <ul>
              <li><strong>如果measure从predict偏移越少, state越保持predict的结果</strong></li>
            </ul>
          </li>
          <li>写成<strong>SSM</strong>的形式: $x_n=\hat x_{n}+g_n\cdot(u_n-C\hat x_n)=(I-g_n\cdot C)\hat x_n +g_n\cdot u_n=(I-g_n\cdot C)P x_{n-1} +g_n\cdot u_n$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="通过运动模型更新gain---g_n">通过运动模型更新gain   $g_n$</h3>

<table>
  <thead>
    <tr>
      <th>变量</th>
      <th>仿真</th>
      <th>predict</th>
      <th>correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>state</td>
      <td>$x_n^r$</td>
      <td>$\hat x_n^r$</td>
      <td>$\tilde x_n$</td>
    </tr>
    <tr>
      <td>error</td>
      <td> </td>
      <td>$\hat \epsilon_n=x_n^r-\hat x_n^r$</td>
      <td>$\epsilon_n=x_n^r-\tilde x_n$</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>仿真模型:
    <ul>
      <li>$x_n^r$ 是<strong>仿真的state</strong></li>
      <li>$x_{n}^r=P(x_{n-1}^r)+ProcessNoise$(状态转移噪声)</li>
      <li>$u_n^r=C(x_n^r)+MeasureNoise$    测量值仿真结果
        <ul>
          <li>假设ProcessNoise和MeasureNoise都是高斯分布的<a href="https://en.wikipedia.org/wiki/Random_variable">Random Variable</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>计算模型:
    <ul>
      <li>predict:
        <ul>
          <li>$\hat x_n^r=P(\tilde x_{n-1})$  是predict值</li>
          <li>PredictError:
            <ul>
              <li>$\hat \epsilon_n=x_n^r-\hat x_n^r=P(x_{n-1}^r)+ProcessNoise-P(\tilde x_{n-1})=P\epsilon_{n-1}+ProcessNoise$ ①</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>correct:
        <ul>
          <li>$\tilde x_{n}=\hat x_{n}^r+g_n\cdot(u_n^r-C\hat x_n^r)=\hat x_{n}^r+g_n\cdot(C\cdot \hat\epsilon_n+MeasureNoise)$    是<strong>correct之后的state</strong></li>
          <li>CorrectError:
            <ul>
              <li>$\epsilon_n= x_n^r-\tilde x_n =\hat \epsilon_{n}-g_n\cdot( C\cdot \hat \epsilon_{n}+MeasureNoise)$ ②</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Gain: argmin(CorrectError) 
        <ul>
          <li>
\[\begin{align}g_n=\text{argmin} ||x_{n}^r-\tilde x_{n}||&amp;=\text{argmin} ||\hat \epsilon_n-g_n\cdot(C\cdot\hat \epsilon_n + MeasureNoise)||\\&amp;=(\hat \epsilon_n)(C\hat \epsilon_n+MeasureNoise)^T((C\hat \epsilon_n+MeasureNoise)(C\hat \epsilon_n+MeasureNoise)^T)^{-1} &amp; (\text{因为 }\text{argmin}||xA-b||=(bA^T)(AA^T)^{-1})\\&amp;=(\hat \epsilon_n^{cov}C^T)(C\hat \epsilon_n^{cov} C^T+MeasureNoise^{cov})^{-1}&amp;(\text{展开, }mean(MeasureNoise)=0)\end{align}\]
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>特点:
    <ul>
      <li>gain  $g_n$ 和实际采集的数据$u_n$ 无关, 是由仿真过程和计算过程确定的</li>
      <li>① , ② 为$\hat \epsilon_n$ 的更新过程</li>
      <li>在gain的计算中, 每次更新$\hat \epsilon_n^{cov}, \epsilon_n^{cov}$ 就可以了</li>
      <li>gain 在一段时间后会收敛到一个固定的值</li>
    </ul>
  </li>
</ul>

<h3 id="推导least-square">推导(Least Square)</h3>

<p>定义 L2 norm: 
	\(||A|| = ∑_{ij} A_{ij}^2  = trace(A^TA)\)</p>

<ul>
  <li>
    <p>Normal Least Square: 
  \(\min_x ||Ax-b|| = \min_x (Ax-b)^T(Ax-b)= \min_x (x^T(A^TA)x - 2x^T(A^Tb))\)</p>
  </li>
  <li>其中:
    <ul>
      <li>$\partial_x x^T(G)x = 2Gx   \ (\partial_{x_k} \sum G_{ij} x_i\cdot x_j = \sum G_{ik} x_i+\sum G_{kj} x_j\text{ related part are one for k-th row and one for k-th col)}$</li>
      <li>$\partial_x x^T(A^T b) = A^T b$</li>
    </ul>
  </li>
  <li>得到: $(A^TA)^{-1}(A^Tb)$</li>
</ul>

<p>变形:</p>

\[\text{argmin}_x ||xA-b||=\text{argmin}_{x^T} ||A^Tx^T-b^T||=((AA^T)^{-1}(Ab^T))^T=(bA^T)((AA^T)^{-1})^T=(bA^T)(AA^T)^{-1}\]

<h2 id="代码">代码</h2>

<p><a href="https://gist.github.com/roshameow/bee4e4ebe065cc3159094590bd873eb1#file-confidence_filter-py"><strong>confidence_filter.py</strong></a> <a href="https://gist.github.com/roshameow/bee4e4ebe065cc3159094590bd873eb1#file-fir-py"><strong>fir.py</strong></a> <a href="https://gist.github.com/roshameow/bee4e4ebe065cc3159094590bd873eb1#file-kalman-py"><strong>kalman.py</strong></a></p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="algorithm" /><category term="content" /><category term="kalman" /><category term="optical_flow" /><category term="filter" /><category term="norm" /><summary type="html"><![CDATA[在高速场景下, 每次中断收集的数据是光流的累加值, 其实本来就相当于一个滤波…况且在硬件有限的条件下, 复杂的滤波没有什么实用价值.]]></summary></entry><entry><title type="html">小红书学到的几种图片调色 (二)</title><link href="https://roshameow.github.io//personal_homepage/docs/photo/photo-color1/" rel="alternate" type="text/html" title="小红书学到的几种图片调色 (二)" /><published>2024-04-27T00:00:00+00:00</published><updated>2024-05-14T00:21:54+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/photo/photo-color1</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/photo/photo-color1/"><![CDATA[<h2 id="人物美白">人物美白</h2>

<p><a href="https://www.xiaohongshu.com/explore/661ab1fb000000000401bfe2">教程</a></p>

<ul>
  <li>cameraRaw滤镜
    <ul>
      <li>基本:
        <ul>
          <li>
            <ul>
              <li>色温, + 色调</li>
            </ul>
          </li>
          <li>
            <ul>
              <li>曝光, + 对比度, -高光</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>混色器:
        <ul>
          <li>色相: + 红色, -橙色, –蓝色</li>
          <li>明亮度: -红色</li>
        </ul>
      </li>
      <li>校准:
        <ul>
          <li>绿原色: +色相</li>
          <li>蓝原色: +饱和度</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>我明白了这件事的难度, 肤色和环境光的作用太subtle了, 美的定义又太多样了. 难怪现在无论什么滤镜都没法把所有人统一的变漂亮.</p>

<h2 id="梦幻发光">梦幻发光</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240428143139.png" alt="Pasted image 20240428143139.png" width="200" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240428143157.png" alt="Pasted image 20240428143157.png" width="200" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240428143227.png" alt="Pasted image 20240428143227.png" width="200" /></p>

<p><a href="https://www.xiaohongshu.com/explore/660fbca9000000001a014c53">教程</a></p>

<ul>
  <li>调整画面颜色(增加绿色): 可选颜色, 在 <a href="https://en.wikipedia.org/wiki/CMYK_color_model">CMYK 颜色</a> 调整
    <ul>
      <li>黄色: + 青色,黄色,黑色  -洋红</li>
      <li>绿色: + 青色,黄色  -洋红,黑色</li>
    </ul>
  </li>
  <li>给高光部分做高斯模糊</li>
  <li>混合模式改为变亮</li>
  <li>和blender里面的<a href="https://docs.blender.org/manual/en/latest/render/eevee/render_settings/bloom.html">bloom(辉光)</a> 功能原理一样</li>
</ul>

<h2 id="赛博朋克">赛博朋克</h2>

<p><a href="https://www.xiaohongshu.com/explore/65be0795000000002c015bf1">教程</a></p>
<ul>
  <li>增加暗处清晰度</li>
  <li>把整体颜色调成偏蓝, 偏红</li>
  <li>在阴影,高光的地方分别加冷暖色</li>
  <li>在混色器里把所有附近颜色调的偏青色, 洋红</li>
</ul>

<p>这效果并不好看…</p>

<h2 id="eva红色天空">EVA红色天空</h2>

<p><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240513161940.png" alt="Pasted image 20240513161940.png" width="300" /> <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240513161959.png" alt="Pasted image 20240513161959.png" width="300" /></p>

<p><a href="https://www.bilibili.com/video/BV1Xj411r7P5/">教程</a></p>

<ul>
  <li>把颜色调成好看的红橙色</li>
</ul>

<h2 id="photoshop快捷键">photoshop快捷键</h2>

<ul>
  <li>command+alt+shift+E(盖印)
    <ul>
      <li>把效果和图层合并生成一个新图层</li>
    </ul>
  </li>
  <li>command+alt+2(提取高光)
    <ul>
      <li>command+J 可以把高光变成一个新图层</li>
    </ul>
  </li>
</ul>

<h2 id="可选颜色功能">可选颜色功能</h2>

<ul>
  <li>根据选中的颜色设置一个mask, 只调整mask之中的颜色
    <ul>
      <li>颜色容差控制mask边缘的模糊程度</li>
      <li>CMYK调整RGB单个通道对应的互补色</li>
    </ul>
  </li>
  <li>可以用颜色取样工具监测颜色的变化</li>
</ul>

<h2 id="camerarawacr参数理解">CameraRaw(ACR)参数理解</h2>

<ol>
  <li>基本
    <ol>
      <li>色温(Temperature)/色调(Tint): 改变<strong>图片整体</strong>hue
        <ol>
          <li>色温调整蓝/黄, 色调调整洋红/绿</li>
        </ol>
      </li>
      <li>自然饱和度/饱和度: 改变图片的Saturation
        <ol>
          <li>自然饱和度只增加图片饱和度低的地方的饱和度</li>
          <li>饱和度增加图片整体饱和度</li>
        </ol>
      </li>
      <li>亮度(Brightness): 所有像素变亮</li>
      <li>对比度(Contrast): 增加和0.5距离的绝对值</li>
      <li>高光/阴影/白色/黑色: 调整清晰度
        <ol>
          <li>高光/阴影: 只会影响图片的 亮部/暗部</li>
          <li>白色/黑色: 影响图片整体</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>混色器: <a href="https://www.bilibili.com/video/BV1584y1C7nP/">教程</a>
    <ul>
      <li>HSL(Hue, Saturation, Lightness) 调整:
        <ol>
          <li>对图片上颜色归类(按红,橙,黄,绿,青,蓝,紫,洋红分为8类)</li>
          <li>调整<strong>所选颜色附近45度的颜色</strong>mask, 颜色拉到最右侧是变成下一级
            <ul>
              <li>比如红色hue拉到100, 会把红色调成橙色</li>
            </ul>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li>颜色分级: <a href="https://www.bilibili.com/video/BV1zQ4y1R7J2/">教程</a>
    <ol>
      <li>把图片分为高光,中间调, 阴影</li>
      <li><strong>在对应亮度的像素位置增加颜色</strong>
        <ol>
          <li>调整颜色面板和下面的(色相,饱和度,明亮度)是一样效果: 都是选颜色</li>
        </ol>
      </li>
      <li>平衡: 控制偏高光还是偏阴影</li>
    </ol>
  </li>
  <li>校准: <a href="https://www.bilibili.com/video/BV1JK411d7ed/">教程</a>
    <ol>
      <li>调整图片上所有颜色, 把所有颜色顺时针旋转, <strong>原色附近权重更大</strong></li>
    </ol>
  </li>
</ol>

<ul>
  <li>颜色调整的精细度: 混色器 &gt; 校准的原色 &gt; 基本的色温/色调</li>
  <li>测试:
    <ul>
      <li>用色环测试颜色调整的效果</li>
      <li>用灰度卡测试亮度变化效果</li>
    </ul>
  </li>
  <li>photoshop找不到功能的具体公式, 只能靠一些网络教程, 有些功能实在没法一下明白…</li>
  <li>一般需要想好要什么颜色, 然后看着调…</li>
</ul>

<h2 id="reference">reference</h2>

<p>[1]  https://www.zhihu.com/question/54879117#:~:text=高光和白色滑块,的保护更好一些%E3%80%82    高光/阴影/白色/黑色讨论, 看完还是没懂</p>

<p>[2] Paris, Sylvain, Samuel W Hasinoff, and Jan Kautz. “Local Laplacian Filters: Edge-Aware Image Processing with a Laplacian Pyramid,” n.d.      据说可能是高光/阴影的公式</p>

<p>[3] https://lab.magiconch.com/eva-title/?layout=e10 EVA字体生成器</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="photo" /><category term="content" /><category term="photoshop" /><category term="shortcut" /><category term="filter" /><category term="color" /><category term="camera_raw" /><summary type="html"><![CDATA[人物美白]]></summary></entry><entry><title type="html">小面积光流传感器算法测试 (二) – 特征训练</title><link href="https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train2/" rel="alternate" type="text/html" title="小面积光流传感器算法测试 (二) – 特征训练" /><published>2024-04-25T00:00:00+00:00</published><updated>2024-04-28T23:30:43+00:00</updated><id>https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train2</id><content type="html" xml:base="https://roshameow.github.io//personal_homepage/docs/algorithm/optical_flow_train2/"><![CDATA[<h2 id="数据">数据</h2>

<p>① ② :  <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240426065333.png" alt="Pasted image 20240426065333.png" width="150" />    ③ : <img src="/personal_homepage/docs/attachment/Pasted%20image%2020240426065926.png" alt="Pasted image 20240426065926.png" width="330" /></p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>采样方式</th>
      <th>具体说明</th>
      <th>特点</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>①</td>
      <td>仿真图像+仿真采样<br />Sample</td>
      <td>在16x16的图像上随机crop得到8x8的patch, <br />再随机用grid_sample提取8x8的patch比对<br /><br />正样本: 和patch距离&lt;0.5的patch<br /></td>
      <td>从采样方法来说, 当前像素只和周围3x3邻域像素相关<br /><br /></td>
    </tr>
    <tr>
      <td>②</td>
      <td>真实图像+仿真采样<br />SampleFromFrame</td>
      <td>用实际sensor提供的图片</td>
      <td> </td>
    </tr>
    <tr>
      <td>③</td>
      <td>真实图像+真实采样<br />SampleFromVideo</td>
      <td>筛选实际sensor提供的图片前后帧,<br />用其他算法确定光流已知的图片对,<br />在图片的其他区域采样</td>
      <td>这是图像配准特征训练中的一般做法</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>代码: <a href="https://gist.github.com/roshameow/a56eaeff6cc8c84aacfce28ba17be0bf#file-local_binary-py"><strong>local_binary.py</strong></a></li>
  <li>结果: 对于究竟学到了哪方面特征, 我很疑惑
    <ul>
      <li>出乎我意料的, 是①  &gt; ② &gt; ③
        <ul>
          <li>可能是我加噪声的方式和真实情况有差距?</li>
          <li>可能是我数据采样中的光流不可靠?</li>
          <li>可能是产生了我不清楚的过拟合?</li>
        </ul>
      </li>
      <li>adaboost的方法比神经网络训练效果好(或者差不多?)</li>
      <li>“最好”的训练结果也没比不训练的结果(sad-mean(diff)的版本)好.
        <ul>
          <li>可能通过匹配patch计算光流的准确度本来已经达到饱和, 再训练patch的描述也没法提升?</li>
        </ul>
      </li>
      <li>用真实数据的loss比仿真数据要大
        <ul>
          <li>说明真实数据更难</li>
          <li>用真实图像插值时, 结果变得超差, 改成crop好了一些</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="torch-grid-sample">torch grid sample</h3>

<p>torch grid 的采样方式有align_corners=True和align_cornes=False两种</p>
<ul>
  <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240415160510.png" alt="Pasted image 20240415160510.png" width="250" /></li>
  <li>转换关系: 一般需要对齐的时候选align_corner=True
    <ul>
      <li>pixel -&gt; grid(align_corner=True): <code class="language-plaintext highlighter-rouge">x=x/(n-1)*2-1</code></li>
      <li>x和y的dim可能和crop也不一致, 需要注意</li>
      <li>可以先按转换关系使grid_sample和crop完全对齐, 测试sample代码位置上是否正确</li>
    </ul>
  </li>
</ul>

<h2 id="gradient-descent训练">gradient descent训练</h2>

<p>用对比学习的模式, 输入相同size的dist(N x M: batch_size x compared_sample_num)和 label.</p>
<ul>
  <li>label = 1, 对应match pair, 我们想要使其dist更小(相关性的话更大)</li>
  <li>对batch的dim做平均要在最后, 因为不同sample应该分别排序</li>
</ul>

<h3 id="几种contrastive-loss">几种contrastive loss</h3>

<table>
  <thead>
    <tr>
      <th>loss</th>
      <th>公式</th>
      <th>目的</th>
      <th>特点</th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://github.com/naver/r2d2/blob/master/nets/ap_loss.py">AP Loss</a> <br />(Average Precision)<br /><br />按照R2D2<a href="#ref">2</a>的写法</td>
      <td>1. 把dist量化, 变为N x Q x M 的binary tensor<br />2. 和label比对, 统计每个sample对应的match/miss的hist: N x Q<br />3. 对于hist的每个bin, 计算前面k个bin的precision<br /><code class="language-plaintext highlighter-rouge">prec@k=cumsum_k match/(match+miss)</code> <br />4. 对每个bin位置的prec@k 做关于match hist的加权平均, 得到AP<br />5. AP loss = 1-mean(AP)<br /></td>
      <td>减小miss hist排在match hist前面的情况<br />用prec@K 表示混合程度<br /><br />名称里的average, 是对match sample的average<br /><br />说是<a href="https://en.wikipedia.org/wiki/Precision_and_recall#:~:text=Precision%20can%20be%20seen%20as,irrelevant%20ones%20are%20also%20returned">precision</a>, <br />代码里实际写的是accuracy<br /></td>
      <td>要根据dist范围调整量化的min/max<br /><br />量化的过程用到了clamp截断<br /><br />因为所有的正样本都参与了训练<br />这个loss会比较稳定<br /><br />在训练过程中, hist本身就是一个很直观观测分布的指标</td>
      <td> </td>
    </tr>
    <tr>
      <td>InfoNCE<br />(Noise-Contrastive Estimation)</td>
      <td>1. 对dist做softmax<br />2. 计算dist和label的<a href="https://en.wikipedia.org/wiki/Cross-entropy">cross entropy loss</a></td>
      <td>让match dist=0, miss dist = 1</td>
      <td>要保证batch的每个sample只对应一个正样本<br />(因为softmax)</td>
      <td> </td>
    </tr>
    <tr>
      <td>triple loss</td>
      <td>1. 每个batch sample, 分别选取match sample里dist最大(ap), <br />和miss sample里dist最小的(an)<br />2. 计算这两者的ranking loss<br /><br />即 $dist_{ap}-dist_{an}-m$ <br />(m是boundary, 即允许最大的match dist比最小的miss dist稍大一点)</td>
      <td>让match dist尽量小, miss dist尽量大</td>
      <td>只有最极端的正负样本参与了训练</td>
      <td> </td>
    </tr>
    <tr>
      <td>Circle Loss</td>
      <td>1. 对match sample(sp), 和miss sample(sn)做logsumexp<br />2. 对这两个加和做soft_plus<br /><br />参数$\gamma$ 控制logsumexp的光滑度, 参数m还是控制match/miss的dist界限值</td>
      <td>和triple loss差不多, 但是是连续形式</td>
      <td>其他正负样本也参与训练, 越是bad case权重越高</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<ul>
  <li>代码: <a href="https://gist.github.com/roshameow/4ef59b0173b9489c2caa9c0e4712137b#file-loss-py"><strong>loss.py</strong></a>
    <ul>
      <li>当时写的时候我用的是相关性而不是dist(但是变量名写的是dist…), 可能是改r2d2代码的时候糊涂了 💔(代码里在量化的时候把相关性转成了dist)</li>
      <li>AP_loss的中间结果(dist的平均分布): <img src="/personal_homepage/docs/attachment/hist.png" alt="hist.png" width="100" /> 其中蓝色是match, 红色是miss</li>
    </ul>
  </li>
  <li><strong>光流任务</strong> :
    <ul>
      <li>尝试了两种descriptor:
        <ul>
          <li>只用AP loss和64dim的 linear特征loss比较正常</li>
          <li>如果用grid-sample 选一些pixel pair的差值(类似<a href="https://docs.opencv.org/3.4/dc/d7d/tutorial_py_brief.html">BRIEF</a> ), loss完全没有下降</li>
        </ul>
      </li>
      <li>dist计算中, 如果是用内积计算两组sample(N x V, M x V)的相关性(N x M), 只需要用矩阵乘法就可以. 但是如果用其他自定义的dist, 需要先extend到(N x M x V, N x M x V), 去计算距离.</li>
    </ul>
  </li>
</ul>

<h2 id="adaboost训练"><a href="https://en.wikipedia.org/wiki/AdaBoost#:~:text=AdaBoost%20refers%20to%20a%20particular,the%20class%20of%20the%20object.">Adaboost</a>训练</h2>

<p>如果特征是离散的, gradient没有指导意义的时候, 可以用sample+选择的方式训练</p>

<ul>
  <li>特征采用<a href="https://docs.opencv.org/3.4/dc/d7d/tutorial_py_brief.html">BRIEF</a> binary特征, 每个pixel pair做为一个weak-learner
    <ul>
      <li>$h = sign(p_1-p_2)$</li>
    </ul>
  </li>
  <li>步骤是重复: 选特征-&gt; 更新sample权重 -&gt; 计算weighted error 的过程</li>
  <li>代码: <a href="https://gist.github.com/roshameow/4d0792f08724f0bda880b564db04530f#file-boosting_train-py"><strong>boosting_train.py</strong></a></li>
</ul>

<h3 id="adaboost的一个改进">adaboost的一个改进</h3>

<p>在beblid<a href="#ref">2</a>中介绍了<strong>给每个weak-learner加一个boundary的方法</strong>: 当weak-learner结果在boundary的同侧视为匹配(比如 $h_1&lt;T, h_2&lt;T$ ), 异侧视为不匹配</p>
<ul>
  <li><strong>步骤</strong>: 对于每个weak-learner
    <ul>
      <li>给当前weak-learner的结果<strong>排序</strong></li>
      <li>先确定当前weak-learner所对应的可能的boundaries ${T_j}$
        <ul>
          <li>$T_{j-1}$ 到 $T_j$ error的改变有以下几种可能: 假设$(v_1,v_2)$ 是当前weak-learner sample pair的结果
            <ul>
              <li><img src="/personal_homepage/docs/attachment/Pasted%20image%2020240426173943.png" alt="Pasted image 20240426173943.png" width="150" /></li>
              <li>$v_1&lt; T_{j-1}&lt;v_2&lt; T_{j}$ , $v_1, v_2$ 从$T_{j-1}$ 的异侧变为了$T_j$ 的同侧 (1)
                <ul>
                  <li>如果$(v_1, v_2)$ label为1, match, error -1</li>
                  <li>如果$(v_1, v_2)$ label为-1, miss, error +1</li>
                </ul>
              </li>
              <li>$T_{j-1}&lt;v_1&lt; T_{j}&lt;v_2$ , $v_1, v_2$ 从$T_{j-1}$ 的同侧变为了$T_j$ 的异侧 (2)
                <ul>
                  <li>如果$(v_1, v_2)$ label为1, match, error +1</li>
                  <li>如果$(v_1, v_2)$ label为-1, miss, error -1</li>
                </ul>
              </li>
              <li>$v_2&lt; T_{j-1}&lt;v_1&lt; T_{j}$ , $v_1, v_2$ 从$T_{j-1}$ 的异侧变为了$T_j$ 的同侧 (3)
                <ul>
                  <li>如果$(v_1, v_2)$ label为1, match, error -1</li>
                  <li>如果$(v_1, v_2)$ label为-1, miss, error +1</li>
                </ul>
              </li>
              <li>$T_{j-1}&lt;v_2&lt; T_{j}&lt;v_1$ , $v_1, v_2$ 从$T_{j-1}$ 的同侧变为了$T_j$ 的异侧 (4)
                <ul>
                  <li>如果$(v_1, v_2)$ label为1, match, error +1</li>
                  <li>如果$(v_1, v_2)$ label为-1, miss, error -1</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>用 $d_1$ 收集case 2,3, $d_2$ 收集case 1,4.
            <ul>
              <li>当$v_1$ 经过$T_{j-1}\rightarrow T_j$ 就会触发$d_1$,  当$v_2$ 经过$T_{j-1}\rightarrow T_j$ 就会触发$d_2$</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>遍历</strong>boundrary $T_j$ 和其中的sample即可计算出全部带boundary的weak-learner的error</li>
    </ul>
  </li>
  <li><strong>计算量</strong>:
    <ul>
      <li>如果是plain的adaboost, 每个weak-learner的迭代只需要更新weight, 计算量只有O(N)</li>
      <li>如果weak-learner总数很多, 每次迭代只sample一部分weak-learner, 就没法复用weak-learner的结果, 要重新计算O(N x W)
        <ul>
          <li>W 是本轮重新sample出的weak-learner</li>
        </ul>
      </li>
      <li>如果给weak-learner附上boundary, 还要
        <ul>
          <li>对每个weak-learner的结果排序O(PlogP), P=2N 是sample pair里结果的个数, 即O(W x PlogP)</li>
          <li>对每个weak-learner遍历sample 的结果 O(N), 即O(W x N)
            <ul>
              <li>如果不是采用这种遍历sample的方式, 虽然不需要排序了, 但是需要O(T x N)的error计算, 即总共O(W x T x N), 考虑到sample数N是比较大的, 这没法接受</li>
              <li>考虑在boundary同侧的结果本来就没影响, 所以拆成排序+遍历应该是boundary训练的一个常见的方法🤔️</li>
            </ul>
          </li>
          <li>因为每个weak-learner的结果和boundary的选择不一样, 似乎没法在weak-learner那边并行❓</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>opencv的人脸检测分类器也是这种加boundary(threshold)的形式</p>

<h2 id="reference">reference</h2>
<p><span id="ref"></span>
[1]  He, Kun, Yan Lu, and Stan Sclaroff. “Local Descriptors Optimized for <strong>Average Precision</strong>.” arXiv, April 17, 2018. <a href="http://arxiv.org/abs/1804.05312">http://arxiv.org/abs/1804.05312</a>.</p>

<p>[2] Revaud, Jerome, Philippe Weinzaepfel, César De Souza, Noe Pion, Gabriela Csurka, Yohann Cabon, and Martin Humenberger. “<strong>R2D2</strong>: Repeatable and Reliable Detector and Descriptor.” arXiv, June 17, 2019. <a href="https://doi.org/10.48550/arXiv.1906.06195">https://doi.org/10.48550/arXiv.1906.06195</a>.</p>

<p>[3] Suárez, Iago, Ghesn Sfeir, José M. Buenaposada, and Luis Baumela. “<strong>BEBLID</strong>: Boosted Efficient Binary Local Image Descriptor.” <em>Pattern Recognition Letters</em> 133 (May 2020): 366–72. <a href="https://doi.org/10.1016/j.patrec.2020.04.005">https://doi.org/10.1016/j.patrec.2020.04.005</a>.</p>
<h2 id="其他资源">其他资源</h2>

<p>[1] https://www.htmlsymbols.xyz/number-symbols/circled-numbers html特殊list符号</p>

<p>[2] https://www.zhihu.com/question/382802283 很好的对于Circle loss的解释</p>]]></content><author><name>{&quot;name&quot;=&gt;nil, &quot;picture&quot;=&gt;&quot;/docs/images/logo.svg&quot;, &quot;email&quot;=&gt;&quot;w.liuatnk@gmail.com&quot;, &quot;twitter&quot;=&gt;nil}</name><email>w.liuatnk@gmail.com</email></author><category term="docs" /><category term="algorithm" /><category term="content" /><category term="optical_flow" /><category term="deeplearning" /><category term="adaboost" /><category term="contrastive_learning" /><category term="grid_sample" /><summary type="html"><![CDATA[数据]]></summary></entry></feed>